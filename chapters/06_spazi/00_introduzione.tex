\begin{figure}
  \centering
  \begin{tikzpicture}[node distance=2cm]
    \draw node at (0,0)[name=insieme]{insieme};
    \draw node at (-1,-1)[name=sv]{sp. vettoriale};
    \draw node at (-1,-3)[name=sn]{sp. normato};
    \draw node at (-1,-5)[name=euclideo]{sp. euclideo};
    \draw node at (2,-1)[name=st]{sp. topologico};
    \draw node at (2,-2)[name=sm]{sp. metrico};
    \draw node at (2,-3.5)[name=completo]{sp. completo};
    \draw node at (1,-4.5)[name=banach]{Banach};
    \draw node at (1,-6)[name=hilbert]{Hilbert};
    \draw[->](sv) -- (insieme);
    \draw[->](st) -- (insieme);
    \draw[->](sn) -- (sv);
    \draw[->](sm) -- (st);
    \draw[->](euclideo) -- (sn);
    \draw[->](hilbert) -- (euclideo);
    \draw[->](hilbert) -- (banach);
    \draw[->](banach) -- (completo);
    \draw[->](completo) -- (sm);
    \draw[->](sn) -- (sm);
    \draw[->](banach) -- (sn);

    \begin{scope}[black!40]
    \draw node at (-2,0)[name=insiemeT]{$\in,\subset,\cup$};
    \draw (insiemeT) -- (insieme);
    \draw node at (-3,-1)[name=svT]{$+,\cdot$};
    \draw (svT) -- (sv);
    \draw node at (-3,-3)[name=snT]{$\abs{v}$};
    \draw (snT) -- (sn);
    \draw node at (-3,---5)[name=euclideoT]{$\langle v,w\rangle$};
    \draw (euclideoT) -- (euclideo);
    \draw node at (5,0)[name=stT]{$\lim, \stackrel\circ A, \bar A$};
    \draw (stT) -- (st);
    \draw node at (5,-1.75)[name=smT]{$d(x,y)$, Lip};
    \draw (smT) -- (sm);
    \end{scope}

    \begin{scope}[black!75]
    \draw node at (5,-1)[name=Rbar,left]{$\bar \RR$};
    \draw[->](Rbar) -- (st);
      \draw node at (5,-2.5)[name=Q,left]{$\QQ$};
      \draw[->](Q) -- (sm);
      \draw node at (5,-4)[name=Sn,left]{$\mathbb S^n$};
      \draw[->](Sn) -- (completo);
      \draw node at (4.5,-5)[name=Cn,left]{$\mathcal C^n$, $L^p$, $\ell^p$};
      \draw[->](Cn) -- (banach);
      \draw node at (4,-6.5)[name=L2,left]{$L^2$, $\ell^2$};
      \draw[->](L2) -- (hilbert);
      \draw node at (1,-7)[name=Rn]{$\RR^n$};
      \draw[->](Rn) -- (hilbert);
    \end{scope}
  \end{tikzpicture}
\caption{Strutture matematiche che astraggono lo spazio $\RR^n$.
La freccia nera significa: ``è un'',
la freccia scura: ``è un esempio di'',
la linea chiara: ``è una operazione tipica di''.}
\label{fig:spazi}
\end{figure}

L'astrazione è una attività tipica della matematica. I risultati che abbiamo
visto fin'ora riguardano per lo più lo spazio $\RR$ dei numeri reali
e in parte lo spazio $\CC$ dei numeri complessi.
E' però evidente che molti di questi risultati si estendono ad altre situazioni
più generali. Identificare le proprietà fondamentali che stanno alla base
di un teorema è forse l'attività più importante svolta dalla matematica.
Tipicamente l'identificazione di queste proprietà oltre a generalizzare
un risultato ne rende anche più semplice la dimostrazione.
Infatti una volta identificate le ipotesi minime del teorema
gli strumenti a nostra disposizione pure si riducono e sarà più facile
capire quali andranno utilizzati.
D'altra parte non potremo portare all'estremo questo tentativo di generalizzazione
in quanto ci si accorge presto che la fauna composta dagli spazi che vanno via
via a coprire tutte le possibili tipologie diventa subito enorme e avere
in mente tutte le definizioni diventa troppo oneroso.

Si veda la figura~\ref{fig:spazi} per avere un quadro relazionale
degli spazi che andremo ora ad introdurre.
Gli spazi vettoriali (algebra lineare) li diamo per noti, 
in quanto sono usualmente oggetto
del corso di geometria.
Gli spazi topologici verranno solamente accennati in quanto non saranno direttamente
utili ai nostri scopi e una trattazione completa richiederebbe molto tempo.
Per lo stesso motivo mancano completamente da questa classificazione anche altri
spazi molto rilevanti (ad esempio i gruppi e le varietà differenziali).


\begin{definition}[spazio metrico]
\mymark{**}
\label{def:distanza}
Diremo che $d\colon X\times X\to\RR$ è una \emph{distanza}%
\mymargin{distanza}%
\index{distanza} su $X$
se per ogni $x,y,z\in X$ valgono le seguenti proprietà
\begin{enumerate}
\item
  $d(x,y)\ge 0$ (positività);
\item
  $d(x,y)\le d(x,z) + d(z,y)$ (disuguaglianza triangolare);
\item
  $d(x,y)=0$ se e solo se $x=y$ (separazione);
\item
  $d(x,y) = d(y,x)$ (simmetria).
\end{enumerate}

Se $d$ è una distanza
diremo che $X$ è uno
\emph{spazio metrico}
\mymargin{spazio metrico}%
\index{spazio!metrico}%
(con distanza $d$).
\end{definition}

Osserviamo che dalle disuguaglianze triangolari:
\[
  d(x,z) \le d(x,y) + d(y,z), \qquad
  d(y,z) \le d(x,y) + d(x,z)
\]
si ottiene la \emph{disuguaglianza triangolare inversa}:
\mymargin{disuguaglianza triangolare inversa}
\index{disuguaglianza!triangolare!inversa}
\[
  d(x,y) \ge \abs{d(x,z) - d(y,z)}.
\]

\begin{definition}[convergenza]%
  \label{def:convergenza_metrica}%
\mymark{*}%
Se $x_n \in X$ è una successione di punti di uno spazio metrico $X$
e $x\in X$ diremo che $x_n$ converge a $x$ e scriveremo
\[
  x_n \to x
\]
se $d(x_n,x)\to 0$ per $n\to +\infty$.
\end{definition}

Si noti che l'usuale convergenza in $\RR$ non è altro
che la convergenza di $\RR$
visto come spazio metrico con la distanza euclidea $d(x,y) = \abs{x-y}$.

Con l'artificio $d(x_n,y_n) - d(x,y) = d(x_n,y_n) - d(x_n,y) + d(x_n,y) - d(x,y)$
e utilizzando la disuguaglianza triangolare inversa si può
facilmente risolvere il seguente.

\begin{exercise}[continuità della distanza]
Dimostrare che se $x_n\to x$ e $y_n\to y$
allora $d(x_n,y_n) \to d(x,y)$.
\end{exercise}

Se vogliamo definire una distanza su uno spazio vettoriale $V$
sarà naturale richiedere che la distanza sia compatibile con la struttura
di spazio vettoriale, e dunque che sia invariante per traslazioni 
e omogenea rispetto alle dilatazioni.
Con questa richiesta la distanza $d(x,y)$ tra due punti dovrà essere 
uguale alla distanza di $x-y$ dall'origine.
La distanza dall'origine viene chiamata \emph{norma} ed è alla base 
della seguente definizione.

\begin{definition}[spazio normato]
\mymark{*}
\label{def:norma}
Sia $V$ uno spazio vettoriale sul campo $\RR$.
Una funzione $\phi \colon V\to \RR$ si
dice essere una \emph{norma}%
\mymargin{norma}%
\index{norma} su $V$ se
per ogni $v,w\in V$ e per ogni $\lambda \in \RR$
valgono le seguenti proprietà:
\begin{enumerate}
\item
  $\phi(v) \ge 0$ (positività);
\item
  $\phi(\lambda v) = \abs{\lambda} \cdot \phi(v)$ (omogeneità e simmetria);
\item
  $\phi(v+w) \le \phi(v) + \phi(w)$
  (disuguaglianza triangolare);
\item
  $\phi(v)=0$ se e solo se $v=0$ (separazione).
\end{enumerate}

Se $\phi$ è una norma su $V$ diremo che
$V$
è uno spazio vettoriale \emph{normato}%
\mymargin{normato}%
\index{normato} da $\phi$.

Se $\phi$ è una norma la funzione $d(v,w) = \phi(v-w)$
è chiaramente una distanza che si chiama
\emph{distanza indotta}
\mymargin{distanza indotta}%
\index{distanza!indotta}%
da $\phi$.
In particolare ogni spazio normato è anche uno spazio metrico rispetto alla
distanza indotta dalla norma.
%Inoltre la disuguaglianza triangolare
%assicura che la norma $\phi\colon V\to \RR$ risulta essere una %+funzione continua.
\end{definition}

Usualmente si utilizzano le notazioni $\abs{v}$ o $\Abs{v}$ per indicare
una norma $\phi(v)$.

Visto che uno spazio normato è anche uno spazio metrico, negli spazi
normati è definita una convergenza. E' facile verificare che la norma risulta
essere continua rispetto a tale convergenza, nel senso che se $v_k \to v$
(ovvero $\phi(v_k-v)\to 0$) allora $\phi(v_k)\to \phi(v)$.

\begin{definition}[spazio euclideo]
\label{def:prodotto_scalare}%
Sia $V$ uno spazio vettoriale sul campo $\RR$.
Una funzione $b\colon V\times V \to \RR$ si dice
essere un \emph{prodotto scalare definito positivo}%
\mymargin{prodotto scalare definito positivo}%
\index{prodotto!scalare}%
\index{definito!positivo}
su $V$ se
$b$ è una forma bilineare, simmetrica e definita
positiva, ovvero se
per ogni $u,v,w\in V$ e per ogni $\lambda, \mu \in \RR$
valgono le seguenti proprietà:
\begin{enumerate}
\item $b(v,v) \ge 0$ (positività);
\item $b(\lambda u + \mu v, w) = \lambda b(u,w) + \mu b(v,w)$
e $b(u,\lambda v+ \mu w) = \lambda b(u,v) + \mu b(u,w)$
(bilinearità);
\item $b(v,w) = b(w,v)$ (simmetria);
\item $b(v,v) = 0$ se e solo se $v=0$ (non degenerazione).
\end{enumerate}

Se $b$ è un prodotto scalare definito positivo su $V$ diremo che $V$ è uno
spazio \emph{euclideo} (con prodotto scalare $b$).

Usualmente si utilizzano le notazioni $v\cdot w$, $(v,w)$, $\langle v,w\rangle$
o $\langle v \vert w\rangle$ per denotare un prodotto scalare $b(v,w)$.
\end{definition}

Se $b$ è un prodotto scalare definito positivo su $V$ il teorema seguente ci garantisce che
che la funzione $\phi(v) = \sqrt{\langle v,v\rangle}$ è una norma su $V$.

Dunque uno spazio euclideo ha, in modo naturale, una struttura di spazio
normato e di spazio metrico.

\begin{theorem}[proprietà del prodotto scalare]
\label{th:spazio_euclideo}%
Sia $V$ uno spazio euclideo con prodotto scalare (definito positivo) $\langle v, w\rangle$.
Si definisca $\abs{v} = \sqrt{\langle v,v\rangle}$.
Allora $\abs{v}$ è una norma su $V$
e per ogni $v,w\in V$ valgono le seguenti proprietà:
\begin{enumerate}
\item \emph{sviluppo del binomio}%
\mymargin{sviluppo del binomio}%
\index{sviluppo!del binomio}
\begin{equation}\label{eq:binomio_vettoriale}%
  \abs{v+w}^2 = \abs{v}^2 + 2 \langle v,w\rangle + \abs{w}^2;
\end{equation}
\item \emph{teorema di Pitagora}%
\mymargin{teorema di Pitagora}%
\index{teorema!di Pitagora}
\index{Pitagora!teorema}%
\begin{equation}\label{eq:Pitagora}
  \langle v,w\rangle=0 \implies \abs{v-w}^2 = \abs{v}^2 + \abs{w}^2;
\end{equation}
\item \emph{disuguaglianza di Young}%
\mymargin{disuguaglianza di Young}%
\index{disuguagliana!di Young}
\index{Young!disuguaglianza di}%
\begin{equation}\label{eq:Young}
  \langle v,w\rangle \le \frac{\abs{v}^2 + \abs{w}^2}{2};
\end{equation}
\item \emph{disuguaglianza di Cauchy-Schwarz}%
\mymargin{disuguaglianza di Cauchy-Schwarz}%
\index{disuguaglianza!di Cauchy-Schwarz}%
\index{Cauchy-Schwarz!disuguaglianza di}%
\begin{equation}\label{eq:Cauchy_Schwarz}
   \langle v,w \rangle \le \abs{v} \cdot \abs{w};
\end{equation}
\item \emph{proprietà del parallelogramma}%
\mymargin{proprietà del parallelogramma}%
\index{proprietà!del parallelogramma}
\index{parallelogramma!proprietà del}
\begin{equation}\label{eq:parallelogramma}
  \abs{v+w}^2 + \abs{v-w}^2 = 2 \abs{v}^2 + 2\abs{w}^2;
\end{equation}
\item \emph{continuità}
\[
  \text{se $v_k\to v$ e $w_k\to w$ allora
  $\langle v_k,w_k\rangle \to \langle v,w \rangle$}.
\]
\end{enumerate}
\end{theorem}
%
\begin{proof}
Osserviamo innanzitutto che $\abs{v}$ è ben definita per ogni $v\in V$
in quanto il prodotto scalare $\langle v,v\rangle$ per definizione non è mai negativo.
Allora in generale si ha, sfruttando la bilinearità,
l'usuale sviluppo del quadrato del binomio:
\begin{align*}
  \abs{v+w}^2
  &= \langle v+w, v+w\rangle
  = \langle v+w, v\rangle + \langle v+w, w\rangle \\
  &= \langle v,v\rangle + 2\langle v,w \rangle + \langle w,w\rangle
  = \abs{v}^2 + 2\langle v,w \rangle + \abs{w}^2.
\end{align*}
Il teorema di Pitagora segue immediatamente.
Ma allora si ottiene facilmente la disuguaglianza di Young:
\[
  0 \le \abs{v-w}^2 = \abs{v}^2 + \abs{w}^2 - 2 \langle v,w\rangle
\]
e la proprietà del parallelogramma:
\[
  \abs{v+w}^2 + \abs{v-w}^2
  = \abs{v}^2 + 2\langle v,w \rangle + \abs {w}^2
    + \abs{v}^2 - 2\langle v,w\rangle + \abs{w}^2.
\]
Ora se $\abs{v}=\abs{w}=1$ la disuguaglianza di Young ci dice che
\[
  \langle v,w \rangle \le 1.
\]
Ma allora per ogni $v\neq 0$ e $w \neq 0$ si ottiene
la disuguaglianza di Cauchy-Schwarz:
\[
\frac{\langle v,w\rangle}{\abs{v}\cdot \abs{w}}
 = \left\langle \frac{v}{\abs{v}} , \frac{w}{\abs{w}}\right\rangle
 \le 1.
\]
Se invece $v=0$ o $w=0$ la disuguaglianza di Cauchy-Schwarz è ovvia in quanto
per ogni $u\in V$ si ha
$\langle 0, u\rangle = \langle u,0\rangle = 0$ per bilinearità.

Le proprietà di positività, omogeneità, simmetria e separazione della 
norma $\abs{v}$ seguono direttamente dalle proprietà analoghe 
del prodotto scalare $\langle v,w\rangle$.  
La disuguaglianza triangolare segue invece dalla 
disuguaglianza di Schwarz,
infatti:
\[
 \abs{v+w}^2 = \langle v+w, v+w\rangle 
 = \abs{v}^2 + \abs{w}^2 + 2 \langle v,w\rangle 
 \le \abs v^2 + \abs w^2 + 2 \abs{v}\cdot \abs{w}
 = \enclose{\abs{v} + \abs{w}}^2
\]
da cui $\abs{v+w} \le \abs{v} + \abs{w}$.


Per quanto riguarda la continuità
ricordiamoci che $v_k \to v$ significa $\abs{v_k-v}\to 0$.
Possiamo allora scrivere
\begin{align*}
  \langle v_k,w_k\rangle - \langle v,w\rangle
&= \langle v_k,w_k\rangle - \langle v, w_k\rangle +  \langle v,w_k\rangle - \langle v,w\rangle \\
&= \langle v_k - v, w_k\rangle + \langle v, w_k -w\rangle
\end{align*}
e, utilizzando Cauchy-Schwarz se $v_k\to v$ e $w_k\to w$ otteniamo
\begin{align*}
\abs{\langle v_k,w_k\rangle - \langle v,w\rangle}
&\le \abs{v_k-v}\cdot \abs{w_k} + \abs{v}\cdot \abs{w_k-w}\\
&\to 0\cdot \abs{w} + \abs{v}\cdot 0 = 0.
\end{align*}
\end{proof}

Lo spazio vettoriale $\RR^n$ ha una struttura euclidea canonica,
come nella seguente.

\begin{definition}[struttura euclidea di $\RR^n$]%
\label{def:124124}%
\mymark{*}%
Un vettore $\vec x\in \RR^n$ è definito come una $n$-upla di numeri reali:
\[
  \vec x = (x_1, \dots, x_n).
\]
Su $\RR^n$ possiamo allora definire il prodotto scalare:
\index{prodotto scalare!di $\RR^n$}
\[
  \vec x\cdot \vec y
   = \sum_{k=1}^n x_k y_k
   = x_1 y_1 + \dots + x_n y_n
\]
Questo prodotto scalare induce la norma euclidea:
\index{norma!euclidea di $\RR^n$}%
\[
  \abs{\vec x} = \sqrt{\vec x \cdot \vec x}
  = \sqrt{x_1^2 + x_2^2+ \dots + x_n^2}.
\]
La distanza indotta da tale norma si chiama \emph{distanza euclidea}%
\mymargin{distanza euclidea}%
\index{distanza!euclidea}:
\[
  d(\vec x, \vec y)
  = \abs{\vec x-\vec y}
  = \sqrt{(x_1-y_1)^2 + \dots + (x_n-y_n)^2}.
\]

Nel caso $n=1$ la norma coincide con il valore assoluto e questo
giustifica l'aver utilizzato la stessa notazione.

Se identifichiamo $\CC$ con $\RR^2$ associando al numero complesso $z=x+iy$
il punto $(x,y)\in \RR^2$ possiamo osservare che la norma euclidea
coincide con il modulo del numero complesso:
\[
  \abs{z} = \sqrt{x^2 + y^2} = \abs{(x,y)}.
\]

Dunque $\RR$, $\CC$, $\RR^n$,
sono spazi euclidei, spazi normati e spazi metrici rispetto alla struttura
euclidea canonica.
\end{definition}

\begin{example}[distanza Manhattan]
Su $\RR^2$ possiamo definire una norma, chiamata \emph{norma Manhattan}%
\mymargin{norma Manhattan}%
\index{norma!Manhattan},
\index{Manhattan!norma}
come segue:
\[
  \phi(\vec x) = \abs{x_1} + \abs{x_2}.
\]
La distanza indotta $d(p,q)$
\index{distanza!Manhattan}%
\index{Manhattan!distanza}%
rappresenta la lunghezza del percorso più breve per
andare da $p$ a $q$ muovendosi solamente in orizzontale o verticale
(come se fossimo sulle strade di Manhattan).

La norma Manhattan non è euclidea nel senso che non è possibile definire
un prodotto scalare che induca tale norma. Infatti se esistesse un
tale prodotto scalare dovrebbe essere valida la proprietà del parallelogramma
\eqref{eq:parallelogramma} e invece osserviamo che scelto $v=(1,0)$ e $w=(0,1)$
si ha
\[
  \phi(v+w)^2 + \phi(v-w)^2
  = 8
  \neq 4
  = 2\phi(v)^2 + 2\phi(w)^2.
\]

L'insieme $B_R(\vec x_0) = \ENCLOSE{\vec x \in \RR^2\colon \phi(\vec x-\vec x_0) < R}$
dei punti di $\RR^2$ che distano meno di $R$ dal  punto $\vec x_0$
(si veda la definizione~\ref{def:palla})
è un quadrato
con le diagonali, di lunghezza $2R$, parallele agli assi coordinati.
Se come norma $\phi$ avessimo scelto la norma euclidea canonica di $\RR^2$
l'insieme $B_R(\vec x_0)$ sarebbe risultato essere un cerchio di raggio $R$
centrato in $\vec x_0$.
In generale le norme indotte da un prodotto scalare si riconoscono
dalla forma di questi insiemi: solo quando si ottengono ellissi
(o ellissoidi se siamo in dimensione più alta) la norma è euclidea.
Per le altre norme si potranno ottenere dei generici insiemi convessi simmetrici
rispetto al centro $\vec x_0$.
\end{example}

\begin{example}[norma $p$]
\label{ex:norma_p}%
Per ogni $p\ge 1$ si può definire su $\RR^n$ la norma
\mymargin{norma $p$}%
\index{norma $p$}%
\index{norma!$p$ in $\RR^n$}%
\[
  \abs{\vec x}_p = \sqrt[p]{\abs{x_1}^p + \abs{x_2}^p + \dots + \abs{x_n}^p}.
\]

Si può inoltre definire
\[
  \abs{\vec x}_\infty = \lim_{p\to +\infty} \abs{\vec x}_p
   = \max\ENCLOSE{\abs{x_1}, \abs{x_2}, \dots, \abs{x_n}}.
\]

Per $p=2$ si ottiene la norma euclidea della definizione~\ref{def:124124}
$\abs{v}_2=\abs{v}$.
Per $p=1$
su $\RR^2$ si ottiene la norma Manhattan.
Per $p=+\infty$ si ottiene di nuovo
la norma Manhattan a meno di una rotazione di 45 gradi e di un riscalamento
di fattore $\sqrt 2$:
\[
  \abs{(x_1,x_2)}_\infty
  = \abs{\enclose{\frac{x_1-x_2} 2, \frac {x_1+x_2}2}}_1
\]

Si potrebbe dimostrare che solo per $p=2$ la norma $\abs{\vec x}_p$ è indotta
da un prodotto scalare in quanto solo per $p=2$ è valida
la proprietà del parallelogramma~\eqref{eq:parallelogramma}.
\end{example}


