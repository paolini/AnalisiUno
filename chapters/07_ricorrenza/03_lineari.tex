\section{equazioni ricorsive lineari}
\label{sec:ricorrenza_lineare}

Fissate le costanti $c_0, c_1, \dots, c_n$,
con $c_n \neq 0$,
diremo che l'equazione ricorsiva:
\begin{equation}\label{eq:ricorsione_lineare}
  c_n \cdot a_{k+n} + c_{n-1} \cdot a_{k+n-1} + \dots
    + c_1 \cdot a_{k+1} + c_0 \cdot a_k = 0
\end{equation}
è una \emph{equazione ricorsiva lineare}%
\mymargin{equazione ricorsiva lineare}\index{equazione!ricorsiva!lineare} (omogenea) di ordine $n$.
Il polinomio $P$ con gli stessi coefficienti:
\[
  P(\lambda) = c_n \cdot \lambda^n + c_{n-1}\cdot \lambda^{n-1} + \dots + c_1 \cdot \lambda + c_0
\]
si chiama \emph{polinomio caratteristico}%
\mymargin{polinomio caratteristico}\index{polinomio!caratteristico}
\index{equazione!ricorsiva!lineare!polinomio caratteristico}%
\index{polinomio!caratteristico!di una equazione ricorsiva lineare}%
associato all'equazione
lineare~\eqref{eq:ricorsione_lineare}.

Ad esempio la successione di Fibonacci $F_k$ definita da~\eqref{eq:Fibonacci}
è una soluzione dell'equazione ricorsiva lineare del secondo ordine:
\[
   a_{k+2} - a_{k+1} - a_{k} = 0
\]
il cui polinomio caratteristico è
\[
  P(\lambda) = \lambda^2 - \lambda - 1.
\]

\begin{theorem}[indipendenza delle successioni esponenziali]
\label{th:indipendenza_successioni_esponenziali}
Siano $\lambda_1, \dots, \lambda_n$ numeri complessi distinti. 
Allora le successioni $\vec a_j$ definite da
\[
  \vec a_j (k) = \lambda_j^k
\]
sono vettori indipendenti nello spazio vettoriale complesso $\CC^\NN$ di tutte le
successioni a valori complessi.
\end{theorem}
%
\begin{proof}
Dobbiamo mostrare che se una combinazione lineare delle
successioni $\vec a_j$ è nulla allora tutti i coefficienti
sono nulli. 
Lo dimostriamo per induzione sul numero $n$. 
Se $n=1$ il risultato è banale. 
Supponiamo allora di sapere che $a_1,\dots, a_{n-1}$ sono indipendenti 
e dimostriamo che allora anche $a_1,\dots, a_n$ lo sono.

Supponiamo quindi di avere $c_1, \dots, c_n\in \CC$ tali che
\[
  \sum_{j=1}^n c_j \vec a_j = \vec 0 \in \CC^\NN.
\]
Significa che per ogni $k\in \NN$ si ha
\begin{equation}\label{eq:47862}
  \sum_{j=1}^n c_j \lambda_j^k = 0.
\end{equation}
Se al posto di $k$ mettiamo $k+1$ si ha
\[
  \sum_{j=1}^n c_j \lambda_j^{k+1} = 0.
\]
Se ora moltiplichiamo \eqref{eq:47862} per $\lambda_n$ e
sottraiamo l'equazione precedente si ottiene:
\[
  \sum_{j=1}^n c_j \lambda_j^k(\lambda_n - \lambda_j) = 0.   
\]
Posto $b_j = c_j (\lambda_n - \lambda_j)$ si ottiene dunque,
per ogni $k\in \NN$
\[
 \sum_{j=1}^{n-1}  b_j \lambda_j^k = 0.
\]
Per ipotesi induttiva sappiamo che i coefficienti $b_1,\dots, b_{n-1}$ 
devono essere tutti nulli che significa, 
essendo $\lambda_n-\lambda_j\neq 0$ che anche $c_1,\dots, c_{n-1}$ 
sono tutti nulli. 
Ma allora \eqref{eq:47862} diventa 
\[
  c_n \lambda_n^k = 0  
\]
che per $k=0$ implica che anche $c_n=0$.
\end{proof}

\begin{proof}[dimostrazione alternativa]
Valutando l'equazione~\eqref{eq:47862} per $k=0,\dots, n-1$ si ottiene
\begin{align*}
  c_1 + c_2 + \dots + c_n & = 0 \\
  c_1 \lambda_1 + c_2 \lambda_2 + \dots + c_n \lambda_n & = 0 \\
  &\quad \vdots\\
  c_1 \lambda_1^{n-1} + c_2 \lambda_2^{n-1} + \dots + c_n \lambda_n^{n-1} & = 0
\end{align*}
che è un sistema lineare la cui matrice associata è
la matrice di \emph{Vandermonde}%
\mymargin{Vandermonde}\index{Vandermonde}
\index{matrice!di Vandermonde}%
\[
V =
\begin{pmatrix}
  1 & 1 &  \dots & 1 \\
  \lambda_1 & \lambda_2 & \dots & \lambda_n \\
  \lambda_1^2 & \lambda_2^2 & \dots & \lambda_n^2 \\
  \vdots & \vdots & \vdots & \vdots \\
  \lambda_1^{n-1} & \lambda_2^{n-1} & \dots & \lambda_n^{n-1}
\end{pmatrix}
\]
che notoriamente (lo si può dimostrare per induzione)
ha determinante
\[
  \det V = \prod_{j=2}^{n} \prod_{k=1}^{j-1}(\lambda_j-\lambda_k)
\]
e dunque
è invertibile se e solo se
i $\lambda_j$ sono tra loro distinti.

Dunque $c_1 = c_2 = \dots = c_n = 0$ è l'unica soluzione
del sistema lineare.
\end{proof}

\begin{theorem}[dimensione delle soluzioni]
\label{th:dimensione_ricorsione_lineare}
L'insieme $W$ di tutte le successioni soluzioni dell'equazione~\eqref{eq:ricorsione_lineare}
di ordine $n$
è un sottospazio vettoriale di dimensione $n$
dello spazio $\CC^\NN$ di tutte le successioni.
\end{theorem}
%
\begin{proof}
Denotiamo con $\vec a \in \CC^\NN$ la successione $a_k = \vec a(k)$.
L'insieme $W$ delle soluzioni dell'equazione~\eqref{eq:ricorsione_lineare}
è un sottospazio vettoriale di $\CC^\NN$ in quanto se $\vec a$
e $\vec b$ sono soluzioni anche $\vec a + \vec b$ è soluzione e se $\vec a$
è soluzione anche $t \vec a$ è soluzione per ogni $t\in \CC$
(si faccia la verifica).

Consideriamo allora l'operatore (chiamato \emph{jet}%
\mymargin{jet}\index{jet}) $J\colon W \to \CC^n$
definito da
\[
  J(\vec a) = \enclose{\vec a(0), \vec a(1), \dots, \vec a(n-1)}.
\]
E' facile verificare che $J$ è un operatore lineare in quanto la valutazione
di una funzione in un punto è una operazione lineare.

Vogliamo ora determinare
\[
  \ker J = \ENCLOSE{\vec a \in W \colon J(\vec a)=0}.
\]
Se $\vec a\in \ker J$ significa che i primi $n$ termini
della successione
$a_0, a_1, \dots, a_{n-1}$ sono tutti nulli.
Ma se $\vec a\in W$ sappiamo che vale~\eqref{eq:ricorsione_lineare} e dunque
anche $a_n$ è nullo. Applicando~\eqref{eq:ricorsione_lineare} ricorsivamente
otteniamo che $a_{n+k}=0$ per ogni $k\in \NN$ e dunque $\vec a = 0$.
Dunque $\ker J = \ENCLOSE{\vec 0}$
e per le note proprietà degli operatori lineari possiamo
affermare che $J\colon W \to \CC^n$ è iniettivo.
Dunque $\dim W \le \dim \CC^n = n$.

Ma possiamo anche osservare che $J$ è suriettivo in quanto
fissati i valori di $a_0,a_1, \dots, a_{n-1}$ l'equazione
~\eqref{eq:ricorsione_lineare} ci permette di determinare,
induttivamente, tutti i termini successivi. Dunque
fissato $\vec y = (y_0, \dots, y_{n-1}) \in \CC^n$
è possibile trovare $\vec a \in W$ tale che $J(\vec a) = \vec y$.

Visto che $J\colon W\to\CC^n$ è iniettivo e suriettivo
concludiamo che $\dim W = \dim \CC^n = n$.
\end{proof}

\begin{theorem}[caratterizzazione delle soluzioni]
Se il polinomio caratteristico dell'equazione~\eqref{eq:ricorsione_lineare}
ha $n$ zeri distinti $\lambda_1, \dots, \lambda_n$
allora
ogni soluzione dell'equazione si scrive nella forma
\[
  a_k = c_1 \lambda_1^k + c_2 \lambda_2^k + \dots + c_n \lambda_n^k
\]
dove $c_1, \dots, c_n$ sono costanti arbitrarie.
\end{theorem}
%
\begin{proof}
Sia $V=\CC^\NN$ lo spazio vettoriale di tutte le successioni.
Possiamo definire l'operatore di \emph{shift} $\sigma\colon V\to V$
\[
  (\sigma \vec a)(k) = \vec a(k+1).
\]
Risulta quindi che $a_{k+n} = (\sigma^n \vec a)(k)$ dove
$\sigma^n = \sigma \circ \sigma \circ \dots \circ \sigma$
è la composizione di $\sigma$ con se stesso per $n$ volte.
Possiamo quindi riscrivere l'equazione~\eqref{eq:ricorsione_lineare} nella forma
\[
  c_n \sigma^n \vec a + \dots + c_0 \sigma^0 \vec a = 0
\]
ovvero
\[
  P(\sigma)\vec a = 0
\]
dove con $P(\sigma)$ si intende l'operatore $P(\sigma)\colon V\to V$
ottenuto applicando il polinomio caratteristico $P$ all'operatore $\sigma$.

Se $\lambda_1,\dots,\lambda_n$ sono le $n$ radici del polinomio $P$ si può
decomporre il polinomio $P$ tramite il teorema~\ref{th:Ruffini} di Ruffini
\begin{equation}\label{eq:375628}
  P(\lambda)
  = a_n (\lambda -\lambda_1)(\lambda- \lambda_2)\cdots (\lambda - \lambda_n).
\end{equation}
la stessa decomposizione può essere fatta per $P(\sigma)$
e quindi l'equazione~\eqref{eq:ricorsione_lineare}
può essere scritta nella forma:
\begin{equation}\label{eq:437343}
(\sigma - \lambda_1 I)\circ (\sigma-\lambda_2 I)\circ \dots \circ (\sigma -\lambda_n I) \vec a = 0
\end{equation}
dove $I\colon V\to V$ è l'operatore identità $I\vec a = \vec a$.
Visto che nella decomposizione~\eqref{eq:375628}
l'ordine in cui vengono moltiplicati i fattori non conta,
anche nell'equazione~\eqref{eq:437343} possiamo applicare gli operatori
$(\sigma -\lambda_j I)$ in qualunque ordine (gli operatori commutano).
Dunque è immediato accorgersi che se $\vec a$ risolve
\[
  (\sigma - \lambda_j I) \vec a = 0
\]
per un qualunque $j=1,\dots, n$ allora $\vec a\in W$.
Ma quest'ultima equazione è facile da risolvere in quanto
ponendo $a_k = \vec a(k)$ si esplicita nella forma:
\[
  a_{k+1} - \lambda_j a_k = 0
\]
che è soddisfatta se
se si sceglie $a_k = \lambda_j^k$.

Dunque la successione $\vec a_j$ definita da
\[
  \vec a_j(k) = \lambda_j^k
\]
è un elemento di $W$.
Per $j=1,\dots, n$ abbiamo trovato $n$ soluzioni distinte
$\vec a_1, \dots, \vec a_n$. Queste soluzioni sono
indipendenti grazie al teorema~\ref{th:indipendenza_successioni_esponenziali}
e quindi essendo $\dim W = n$ per il teorema~\ref{th:dimensione_ricorsione_lineare}
possiamo affermare che queste soluzioni formano una base di $W$
che è esattamente quanto volevamo dimostrare.
\end{proof}

\begin{example}[formula esplicita per la successione di Fibonacci]
\index{successione!di Fibonacci}%
\index{Fibonacci!formula esplicita}%
La successione di Fibonacci $F_k$ definita da~\eqref{eq:Fibonacci}
soddisfa una equazione ricorsiva lineare del secondo ordine con polinomio associato
$P(\lambda) = \lambda^2 - \lambda - 1$. Risolvendo l'equazione $P(\lambda)=0$
si trovano le due radici distinte:
\[
  \lambda_{1,2} = \frac{1 \pm \sqrt{5}}{2}.
\]
La radice più grande, $\lambda_2$, corrisponde al
\emph{rapporto aureo}%
\mymargin{rapporto aureo}\index{rapporto!aureo} che usualmente viene chiamato $\phi$.
\index{$\phi$}%
Visto che $\lambda_1 \lambda_2 = -1$ si trova $\lambda_1 = -1/\phi$.
Dunque, per il teorema precedente, sappiamo che esistono due costanti $c_1$ e
$c_2$ tali che
\[
  F_k = c_1 \frac{(-1)^k}{\phi^k} + c_2 \phi^k .
\]
Imponendo le condizioni $F_0=0$, $F_1=1$ (imporre $F_2 = 1$ è equivalente a $F_0=0$)
si ottiene
\[
  c_1 + c_2 = 0, \qquad - \frac{c_1}{\phi} + c_2 \phi  = 1
\]
da cui è possibile trovare $c_1 = - c_2 = 1/\sqrt{5}$ e ottenere
così la formula di Binet per il $k$-esimo numero di Fibonacci:
\mymargin{Formula di Binet}%
\index{Fibonacci}%
\index{successione!di Fibonacci}%
\index{formula!di Binet}%
\index{Binet!formula di}%
\[
  F_k = \frac{\phi^k}{\sqrt 5} + \frac{(-1)^{k+1}}{\sqrt 5\phi^k}.
\]
Risulta piuttosto sorprendente osservare che i valori $F_k$ ottenuti
con questa espressione siano tutti numeri interi.
\end{example}

