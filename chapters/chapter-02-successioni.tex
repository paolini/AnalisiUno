\chapter{continuità e limiti}
\label{ch:successioni}

%\subsection{assiomatica dei reali}

Nel capitolo precedente abbiamo costruito l'insieme numerico $\RR$ dei numeri reali, e abbiamo 
messo in evidenza il fatto che si tratta di un campo ordinato e continuo
(definizione~\ref{def:campo_ordinato}). 
Abbiamo anche visto che la proprietà di essere un campo ordinato e continuo caratterizza univocamente $\RR$.
Dunque, in effetti, non sarà più necessario fare riferimento alla costruzione di $\RR$ ma potremo 
d'ora in poi semplicemente pensare che $\RR$ è un dato campo ordinato e continuo.
Tale proprietà caratterizza $\RR$ ed è quindi una informazione sufficiente per poter dedurre 
qualunque altra sua proprietà. 

A questo punto possiamo identificare anche gli insiemi $\NN$, $\ZZ$ e $\QQ$ come particolari sottoinsiemi 
dell'insieme $\RR$, senza doverli costruire esplicitamente.

Per identificare $\NN$ l'idea è quella di considerare il più piccolo sottoinsieme di $\RR$ che 
contiene $0$ e che se contiene $n$ contiene anche $n+1$. 
Per formalizzare questa idea diremo che
$X\subset \RR$ è \emph{induttivo} se $0\in X$ e se $n\in X$ implica $n+1\in X$. 
Definiamo quindi $\NN$ come l'intersezione di tutti gli insiemi induttivi:
\[
 \NN = \cap\ENCLOSE{X\subset \RR\colon X \text{ induttivo}}.
\]
Chiaramente $\NN$ è esso stesso induttivo. Ed è facile dimostrare che soddisfa 
gli assiomi di Peano (def~\ref{def:assiomi_peano}).

Si osserva poi che $\NN$ è superiormente illimitato perché se esistesse $x\in \RR$ maggiorante di 
$\NN$ allora per assurdo anche $x-1$ sarebbe un maggiorante, 
contro l'ipotesi di continuità di $\RR$ che garantisce l'esistenza di un minimo dei maggioranti.
Da questo si ricava la proprietà archimedea: per ogni $x>0$ e $y>0$ esiste $n \in \NN$ tale che $nx>y$.
%E tramite la proprietà archimedea si deduce la densità di $\QQ$ in $\RR$: se $x<y$ posto $\eps=y-x>0$
%si trova $q\in \NN$ tale che $\frac{1}{q}<\eps$ e dunque si trova $p\in \ZZ$ tale che $x<\frac{p}{q}<y$.

Dopodiché si definisce $\ZZ$ come l'insieme di tutte le differenze tra coppie di numeri naturali: 
$\ZZ = \NN - \NN = \ENCLOSE{n-m\colon n,m\in \NN}$.

Infine si definisce $\QQ$ come l'insieme di tutti i quozienti $\frac{p}{q}$ con $p\in \ZZ$ e $q\in \NN$, 
$q\neq 0$.

\subsection{valore assoluto}

\begin{definition}[valore assoluto]
\mymark{***}
Definiamo il \emph{valore assoluto}%
\mymargin{valore assoluto}%
\index{valore!assoluto} $\abs{x}$ di un numero $x\in \RR$ nel seguente modo:
\[
\abs{x} =
\begin{cases}
  x & \text{se $x\ge 0$}, \\
  -x & \text{se $x<0 $}.
\end{cases}
\]
\end{definition}
  
\begin{proposition}[proprietà del valore assoluto]
\mymark{**}
Si ha
\begin{enumerate}
\item $\abs{x}\ge 0$ (positività)
\item $\big\lvert\abs{x}\big\rvert = \abs{x}$ (idempotenza)
\item $\abs{-x} = \abs{x}$ (simmetria)
\item $\abs{x\cdot y} = \abs{x}\cdot \abs{y}$ (omogenità)
\item $\abs{x+y} \le \abs{x} + \abs{y}$ (convessità)
\item $\abs{x-y} \le \abs{x-z} + \abs{z-y}$ (disuguaglianza triangolare)
\item $\big\lvert\abs{x}-\abs{y}\big\rvert \le \abs{x-y}$ (disuguaglianza triangolare inversa)
\end{enumerate}
Useremo inoltre spesso la seguente equivalenza (valida
anche con $<$ al posto di $\le$). Se $r\ge 0$ allora
\[
  \abs{x-y} \le r
  \iff
  y - r \le x \le y + r.
\]
\end{proposition}
%
\begin{proof}
\mymark{*}
Positività, idempotenza, simmetria e omogenità sono immediate conseguenze della definizione.

Dimostriamo ora l'ultima osservazione.
Se $x\ge y$ allora $x-y\ge 0$ e quindi $\abs{x-y} \le r$ è
equivalente a $x-y\le r$ cioè $x\le y+r$.
Se $x<y$ allora $x-y<0$ e quindi $\abs{x-y} \le r$ è
equivalente a $y-x \le r$ cioè $x\ge y-r$.
Viceversa se $y-r \le x \le y+r$ allora vale sia $x-y \le r$ che $y-x \le r$ e 
dunque $\abs{x-y}\le r$.

Osserviamo allora che per la precedente osservazione applicata
a $\abs{x-0} \le \abs{x}$ si ottiene
\[
  -\abs{x} \le x \le \abs{x}
\]
e sommando la stessa disuguaglianza con $y$ al posto di $x$ si
ottiene
\[
  -(\abs{x} + \abs{y}) \le x + y \le \abs{x} + \abs{y}
\]
che è equivalente alla proprietà di convessità:
\[
  \abs{x+y} \le \big\lvert\abs{x} + \abs{y}\big\rvert = \abs{x} + \abs{y}.
\]

Ponendo $y=z-x$ nella disuguaglianza precedente, si ottiene
\[
  \abs{z} \le \abs{x} + \abs{z-x}
\]
da cui
\[
  \abs{z} - \abs{x} \le \abs{z-x}.
\]
Scambiando $z$ con $x$ si ottiene la disuguaglianza opposta
e mettendole assieme si ottiene
la disuguaglianza triangolare inversa:
\[
\big\lvert \abs{z}-\abs{x} \big\rvert  \le \abs{z-x}.
\]

La disuguaglianza triangolare segue dalla convessità:
\[
  \abs{x-y} = \abs{x-z + z-y} \le \abs{x-z} + \abs{z-y}.
\]
\end{proof}

Osserviamo che dal punto di vista geometrico
$\abs{x-y}$ rappresenta la \emph{distanza} tra i punti
$x$ e $y$.

\subsubsection{parte intera}

\begin{theorem}[parte intera]
\mymark{*}%
  Dato $x\in \RR$ esiste un unico $m\in \ZZ$ tale che $m-1 < x \le m$.
\end{theorem}
%
\begin{proof}
  Supponiamo per un attimo che sia $x > 0$
  e consideriamo l'insieme $A=\ENCLOSE{n \in \NN \colon n\ge x}$.
  Tale insieme non è vuoto per la proprietà archimedea 
  e dunque ammette minimo per il principio del buon ordinamento.
  Se $m=\min A$ risulta quindi $m\in \NN$ e $m-1< x \le m$.

  Se $x\le 0$ per la proprietà archimedea esiste $k\in \NN$ tale che 
  $k>-x$. Allora applichiamo il risultato precedente a $x+k$ e consideriamo 
  $m-k$ al posto di $m$.
\end{proof}

\begin{definition}[parte intera]
  \mymark{**}%
  \mymargin{parte intera}%
\index{parte!intera}%
  Dato $x\in \RR$ denotiamo con $\lfloor x\rfloor$ l'unico intero
  che soddisfa
  \mymargin{$\lfloor\cdot\rfloor$} %% *** non viene bene nell'indice!
  \[
    x - 1 < \lfloor x \rfloor \le x
  \]
  e denotiamo con $\lceil x \rceil = - \lfloor -x \rfloor$ l'unico intero che soddisfa (verificare!)
  \mymargin{$\lceil\cdot\rceil$} %% *** non viene bene nell'indice!
  \[
    x \le \lceil x \rceil < x + 1.
  \]
  Si ha dunque
  \[
    \lfloor x \rfloor \le x \le \lceil x \rceil
  \]
  con entrambe le uguaglianze che si realizzano quando $x\in \ZZ$.
  I due interi $\lfloor x \rfloor$ e $\lceil x \rceil$
  sono la migliore approssimazione intera di $x$ rispettivamente
  per difetto e per eccesso.
  L'intero più vicino ad $x$ (approssimazione per \emph{arrotondamento}%
\mymargin{arrotondamento}%
\index{arrotondamento})
  è
  \[
    \left\lfloor x + \frac 1 2 \right\rfloor
  \quad \text{ossia} \quad
    \left\lceil x-\frac 1 2 \right\rceil
  \]
  (le due espressioni differiscono solamente quando $x$ si trova nel punto medio tra 
  due interi consecutivi, nel qual caso la prima approssima per eccesso e la seconda 
  per difetto).
\end{definition}

In alcuni testi si usa la notazione $[x]$ per denotare la parte intera $\lfloor x \rfloor$ e si definisce
anche la \emph{parte frazionaria}
\[
  \ENCLOSE{x} = x - [x].
\]
Per evitare ambiguità con il normale utilizzo delle parentesi
non useremo queste notazioni.

\subsection{potenza e radice $n$-esima}
%
%
\label{sec:potenza}%
\label{sec:radice}%

Se $n \in \NN$ è un numero naturale possiamo definire 
l'elevamento a potenza $x^n$ induttivamente, come moltiplicazione 
ripetuta, ad esempio: $x^3 = x\cdot x \cdot x$
(si veda il teorema~\ref{th:operazione_ripetuta}).

Si osservi anche che abbiamo definito $0^0=1$ dove lo $0$ 
alla base è un numero reale e lo $0$ all'esponente 
è un numero naturale.

% Il teorema~\ref{th:divisibile}
% ci garantiva l'esistenza della frazione $\frac x n$ come operazione inversa 
% della somma ripetuta: $n\cdot x$. 
% Lo stesso teorema, applicato alla struttura moltiplicativa, può essere utilizzato 
% per definire la radice $n$-esima: $\sqrt[n]{x}$.

Definiamo l'insieme dei \emph{reali positivi}:
\[
\RR_+ = \ENCLOSE{x\in \RR\colon x>0}
\]
e su di esso consideriamo l'operazione di moltiplicazione.

\begin{theorem}[$\RR_+$ è un gruppo moltiplicativo]
  \label{th:gruppo_moltiplicativo}%
  \index{gruppo!moltiplicativo}%
  \index{reali!positivi}%
L'insieme $\RR_+$ dei reali positivi con l'operazione di moltiplicazione 
e l'ordinamento usuale ereditato da $\RR$ risulta essere 
un gruppo totalmente ordinato, denso e continuo.
\end{theorem}
%
\begin{proof}
Sappiamo che il prodotto di due numeri positivi 
è un numero positivo. Anche il reciproco di un numero positivo
esiste sempre (perché escludiamo $0$) ed è positivo. 
L'elemento neutro $1$ è anch'esso positivo. 
Dunque risulta che $\RR_+$ è un gruppo moltiplicativo.
Non solo, l'ordinamento di $\RR$ è ovviamente un ordinamento anche su $\RR_+$
e mantiene le proprietà di essere un ordinamento totale 
denso e continuo visto che queste proprietà sono indipendenti dalla struttura di gruppo.
La compatibilità dell'ordinamento con la moltiplicazione 
è data dalla proprietà di monotonia della moltiplicazione.
\end{proof}

\begin{theorem}[radice $n$-esima]
  \label{radice!$n$-esima}%
Sia $n\in \NN$, $n\ge 1$ fissato.
Dato $y\in \RR$, $y \ge 0$, esiste un unico $x\in \RR$, $x\ge 0$ tale che $x^n = y$.
Tale numero $x$ si chiama \emph{radice} $n$-esima di $y$ e si 
denota con questo simbolo:
\[
  x = \sqrt[n]{y}.
\]

Se $n$ è pari e $y>0$ l'equazione $x^n=y$ ha due soluzioni, oltre alla soluzione positiva 
$\sqrt[n]{y}$ c'è anche una soluzione negativa $-\sqrt[n]{y}$.
Se $y=0$ l'equazione $x^n=0$ ha come unica soluzione $x=\sqrt[n]{0}=0$.
E se $y<0$ (sempre nel caso $n$ pari) l'equazione $x^n = y$ non ha soluzioni.

Se $n$ è dispari l'equazione $x^n=y$ ha una unica soluzione per ogni $y\in \RR$.
Se $y<0$ la soluzione è negativa ed è $x=-\sqrt[n]{\abs y}$.
Per comodità, se $n$ è dispari, definiamo la radice $n$-esima anche sui numeri negativi 
ponendo appunto 
\[
  \sqrt[n]{-y} \defeq  -\sqrt[n]{y}\qquad\text{(se $n$ è dispari).}
\]
\end{theorem}
\begin{proof}
Il teorema~\ref{th:divisibile} (divisibilità) può essere applicato al gruppo moltiplicativo 
$\RR_+$ e ci dice che se $n\neq 0$ dato $y\in \RR_+$ esiste un unico $x\in \RR_+$ tale 
che $x^n = y$. Se $y=0$ chiaramente solo $x=0$ è soluzione di $x^n= y$ per la regola 
di annullamento del prodotto. 

Le altre proprietà si deducono per simmetria osservando che $(-x)^n = (-1)^n\cdot x^n$
e $(-1)^n$ vale $1$ se $n$ è pari e $-1$ se $n$ è dispari per la regola del segno 
del prodotto.
\end{proof}

\index{radice!quadrata}%
\index{radice!cubica}%
Per $n=2$ si omette l'indicazione dell'esponente scrivendo $\sqrt y$ al posto di $\sqrt[2] y$.
La $\sqrt y$ si chiama \emph{radice quadrata} di $y$.
Per $n=3$ la radice $\sqrt[3]{y}$ si chiama \emph{radice cubica} di $y$.

\begin{figure}
  \begin{center}
    \begin{tikzpicture}[x=1.0cm,y=1.0cm]
      \clip(-3,-2) rectangle (4,3);
    	\draw[->] (-3,0) -- (4,0);
      \draw[->] (0,-2) -- (0,3);
      \draw[dotted] (1,0) -- (1,1) -- (0,1);
%      \draw[domain=0.2:4,samples=50,variable=\x,dashed,color=gray] plot
%        ({\x}, {1/(\x))});
%      \draw[domain=-3:-0.5,samples=50,variable=\x,dashed,color=gray] plot
%        ({\x}, {1/(\x))});
      \draw[domain=-2.0:2.0,smooth,variable=\x,thick,color=gray] plot
        ({\x}, {\x*\x*\x)});
      \draw[domain=-3.1:4.0,samples=200,variable=\x,color=gray] plot
        ({\x}, {pow(abs(\x),1/3)*\x / abs(\x)});
      \draw[domain=-3.0:3.0,smooth,variable=\x,thick] plot
        ({\x}, {\x*\x});
      \draw[domain=0.0:4.0,samples=200,variable=\x] plot
      ({\x}, {pow(\x,1/2)});
      \node at (-2.0,1.8) {$y=x^2$};
      \node at (3,2) {$y=\sqrt{x}$};
      \node[color=gray] at (-1.7,-1.8) {$y=x^{3}$};
      \node[color=gray] at (-2.0,-1) {$y=\sqrt[3]{x}$};
      \fill (1,0) node[below]{$1$} circle[radius=1.5pt];
      \fill (0,1) node[left]{$1$} circle[radius=1.5pt];
    \end{tikzpicture}
  \end{center}
  \caption{Grafici delle potenze $x^2$, $x^3$ e radici
  $\sqrt x$, $\sqrt[3] x$.}
  \label{fig:potenza_intera_radice}
\end{figure}

%\subsubsection{numeri irrazionali}
%
%
%Abbiamo quindi dimostrato che $\QQ$ non può essere continuo (altrimenti 
%sarebbe isomorfo a $\RR$ dove l'equazione $x^2=2$ ha soluzione). 
%Utilizzando l'irrazionalità di $\sqrt 2$ 
%possiamo ora esibire un esempio di sottoinsiemi di $\QQ$ che sono 
%\emph{separati} (nel senso della definizione~\ref{def:ordinamento_continuo})
%ma non hanno elemento di separazione in $\QQ$:
%\[
%A= \ENCLOSE{x\in\QQ\colon x^2< 2},
%\qquad
%B = \ENCLOSE{x\in \QQ\colon x<0, x^2>2}.  
%\]
%Chiaramente $A\le B$ ma in $\RR$ questi due insiemi 
%hanno come unico elemento di separazione $\sqrt 2$ che non è elemento di
%$\QQ$.
%
%% Abbiamo appena verificato che esistono numeri irrazionali. 
%% Può però essere sorprendente scoprire che non solo i numeri irrazionali 
%% sono infiniti (chiaramente se $x$ è irrazionale anche $n\cdot x$ è irrazionale 
%% se $n$ è intero o razionale) ma addirittura la cardinalità 
%% dei numeri irrazionali è maggiore di quella dei numeri razionali 
%% $\# (\RR\setminus \QQ) > \# \QQ$ (teorema~\ref{th:cantor_secondo}).
%
%Ogni numero razionale ha una rappresentazione finita. 
%Se $x=\frac p q$ possiamo scrivere $p$ e $q$ nella loro rappresentazione 
%decimale utilizzando una sequenza finita di cifre.
%Possiamo dare \emph{un nome} anche a molti
%numeri irrazionali. 
%Ad esempio $\sqrt 2$, $e$, $\pi$, $\sin 1$, $\ln 2$ identificheranno 
%alcuni numeri irrazionali. 
%Ma non è possibile dare una rappresentazione \emph{finita} di ogni numero reale.
%Per questo motivo è rilevante il fatto che i numeri razionali siano \emph{densi}
%nei numeri reali perché questo significa che ogni numero reale può essere 
%approssimato, con un errore piccolo a piacere, tramite un numero razionale.
%
\begin{theorem}[densità di $\QQ$ in $\RR$]
\label{th:densita_frazioni}%
\index{densità!frazioni}%
\index{approssimazioni!decimali}%
Dati $a,b\in \RR$ se $a<b$ esiste $q\in \QQ$ tale che $a< q < b$.

Equivalentemente dato $x\in \RR$ e dato $\eps>0$ esiste $q\in \QQ$ 
tale che $\abs{x-q} < \eps$.

Inoltre la frazione $q= \frac{p}{n}$ può essere scelta 
in modo tale che il denominatore sia una potenza di $10$: $n=10^k$.
\end{theorem}
\begin{proof}
La prima parte è conseguenza della seconda perché 
dati $a<b$
se scegliamo 
$x= \frac{a+b}{2}$ ed $\eps = \frac{b-a} 2$ se 
esiste $q$ tale che $\abs{x-q}< \eps$ 
allora 
\[
   a = \frac{a+b}{2} - \eps < q < \frac{a+b}{2} + \eps = b.
\]

Per dimostrare la seconda parte dati $x$ e $\eps$ basterà scegliere 
$n\in \NN$ tale che $\frac 1 n < \eps$ (l'esistenza di $n$ è garantita 
dal teorema~\ref{th:archimede}, proprietà archimedea) e predere $q = \frac{\lfloor nx\rfloor}{n}$
cosicché, per le proprietà della parte intera, si ha:
\[
  nx-1\le \lfloor nx\rfloor \le nx 
  \qquad\text{e quindi}\qquad
  x - \frac 1 n \le q \le x
\]
da cui $0 \le x-q < \frac 1 n < \eps$ come volevamo dimostrare.

Per avere una frazione con denominatore potenza di $10$ basta osservare 
che se aumentiamo $n$ la precisione della approssimazione aumenta. 
Dunque basta osservare che per ogni $n\in \NN$ esiste $d\in \NN$
tale che $10^d \ge n$ (basta scegliere $d=n$ e dimostrare per induzione 
che $10^n\ge n$).
\end{proof}

\begin{exercise}\label{ex:densita_irrazionali}
  Dimostrare che anche gli irrazionali 
  sono densi in $\RR$ cioè che se $a<b$ allora esiste 
  $x \in \openinterval{a}{b}$, $x\not \in \QQ$.
\end{exercise}

\subsubsection{frazioni decimali}
%
Le frazioni il cui denominatore è una potenza
di $10$ si chiamano frazioni decimali:
\[
  x = \frac{p}{10^d}, \qquad p\in \ZZ, d\in \NN.
\]
Tali frazioni si possono rappresentare
scrivendo il numero
intero $p$ e segnando un punto
\mynote{%
in Italia si preferisce utilizzare la virgola, ma
ci rassegnamo alla notazione anglosassone che ormai è
ubiqua in tutta la strumentazione elettronica.
}%
di separazione
prima della $d$-esima cifra a partire da destra.
Ad esempio scriveremo:
\[
  1.4142 = \frac{14142}{10^4}.
\]
In generale una frazione $\frac{p}{q}\in \QQ$
può essere scritta in forma decimale solamente
se, quando ridotta ai minimi termini,
risulta che $q$ non ha fattori primi diversi
da $2$ e $5$ (in quanto le potenze di dieci
hanno solo questi fattori).

Anche se non tutte le frazioni hanno una rappresentazione 
decimale finita, in ogni caso le frazioni decimali 
sono dense in $\RR$ (come dimostrato nel teorema~\ref{th:densita_frazioni})
e quindi ogni numero reale può essere approssimato, con errore piccolo a piacere,
mediante una frazione decimale.

Scriveremo
\mymargin{$\approx$}%
\index{$\approx$}%
\[
  x \approx \frac{p}{10^d}
\]
(si può leggere: ``$x$ è approssimativamente uguale a\dots'')
se
\[
    \frac{p-1}{10^d} < x < \frac{p+1}{10^d}.
\]

Ad esempio possiamo scrivere
\[
  \sqrt 2 \approx 1.41 = \frac{141}{10^2}
\]
per intendere%
\mynote{%
Si osservi che in base alla definizione data sarebbe anche corretto 
scrivere $\sqrt 2 \approx 1.42$ che però è una approssimazione 
peggiore. 
Questa ambiguità è necessaria se vogliamo evitare i casi 
limite in cui bisogna conoscere molte più cifre decimali di quelle richieste 
per capire qual è la migliore approssimazione.
}%
\begin{equation}\label{eq:approx_sqrt2}
\frac{140}{100} < \sqrt 2 < \frac{142}{100}.
\end{equation}
Nel calcolo numerico scientifico ogni uguaglianza numerica è intesa nel 
senso precedente, se non specificato diversamente. 

\begin{exercise}
Dimostrare \ref{eq:approx_sqrt2} senza 
utilizzare la calcolatrice.
\end{exercise}

Osserviamo infine che anche i calcolatori utilizzano una rappresentazione frazionaria, 
nel caso specifico \emph{binaria}, dei numeri.
I numeri frazionari su cui opera un calcolatore sono tutti della forma $\frac{p}{2^d}$.
Visto che $2$ divide $10$, le frazioni binarie sono anche sempre frazioni decimali, 
in particolare anche questi numeri sono densi in $\RR$.
\mynote{In un moderno calcolatore a 64 bit la rappresentazione binaria (float64) 
utilizza frazioni binarie con esponente $d\le 1024$. 
Questo permette di rappresentare numeri con una precisione non superiore alle 
$308$ cifre decimali. 
La rappresentazione è a virgola mobile e quindi questa precisione si può raggiungere 
solamente con numeri vicini allo zero, per numeri vicini a $1$ 
si ha invece $d\le 53$ che corrisponde ad una precisione di quasi $16$ cifre decimali.}

\subsubsection{frazioni decimali periodiche}

Le frazioni non decimali si possono scrivere con uno sviluppo
decimale \emph{periodico}. 
Non useremo mai questa notazione
che ricordiamo solamente con un esempio.
Il numero
\[
  x = 12.34\overline{567}
    = 12.34567\overline{567}
\]
è la frazione $x$ che risolve l'equazione
\[
  \frac{100x - 1234}{1000}
  = 100x-1234.567
  \qquad
\enclose
{\frac{0.\overline{567}}{1000}
= 0.000\overline{567} }
\]
ovvero
\[
  1234567 - 1234 = 99900 \cdot x,
  \qquad x = \frac{1234567-1234}{99900}.
\]

\begin{exercise}
Si verifichi che $0.\overline 9 = 1$.
\end{exercise}
    
Per passare dalla rappresentazione frazionaria alla rappresentazione 
decimale periodica basta svolgere la divisione in colonna.
Se l'algoritmo termina la frazione era decimale, altrimenti l'algoritmo 
diventa periodico e le cifre decimali si ripetono indefinitamente.


\subsection{punti all'infinito}
\label{sec:reali_estesi}
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%

\begin{definition}[reali estesi]
\mymargin{$\bar\RR$}%
\index{$\bar{\RR}$}
Denotiamo con $\bar \RR=\RR \cup \ENCLOSE{+\infty, -\infty}$ l'insieme dei numeri reali
\mymargin{$+\infty$, $-\infty$}%
\index{$+\infty$, $-\infty$}
a cui vengono aggiunti due ulteriori \emph{quantità} che chiameremo
\emph{infinite} e che denotiamo con $+\infty$ e $-\infty$.
Diremo che $x\in \bar \RR$ è \emph{finito} se $x\in \RR$.
\end{definition}


Estendiamo la relazione d'ordine imponendo che valga
\[
  -\infty \le x \le +\infty, \qquad \forall x \in \bar\RR.
\]

Estendiamo anche la addizione e moltiplicazione
tra reali estesi imponendo che valga per ogni $x\in \bar \RR$
\begin{gather*}
  x + (+\infty) = +\infty, \qquad \text{se $x\neq -\infty$}\\
  x + (-\infty) = -\infty, \qquad \text{se $x\neq +\infty$}\\
  x \cdot (+\infty) = +\infty, \qquad
  x \cdot (-\infty) = -\infty, \qquad \text{se $x>0$} \\
  x \cdot (+\infty) = -\infty, \qquad
  x \cdot (-\infty) = +\infty, \qquad \text{se $x<0$}.
\end{gather*}

Si definiscono anche:
\[
 -(+\infty) = -\infty, \qquad
 -(-\infty) = +\infty, \qquad
 \frac{1}{+\infty} = \frac{1}{-\infty}=0
\]
facendo però attenzione che
questi formalmente non sono \emph{opposto}
e \emph{reciproco} in quanto
su $\bar \RR$ non sono più garantite
le regole: $x + (-x) = 0$ e $x \cdot (1/x) = 1$.
Infatti
le operazioni $(+\infty) + (-\infty)$ e $+\infty \cdot 0$ vengono
lasciate indefinite.

Definiamo anche il valore assoluto: $\abs{+\infty} = \abs{-\infty} = +\infty$.

Possiamo infine definire la sottrazione e la divisione tramite
addizione e moltiplicazione:
\[
  x - y = x + (-y), \qquad \frac{x}{y} = x \cdot \frac{1}{y}.
\]

Osserviamo che rispetto all'ordinamento di $\bar \RR$ tutti 
i sottoinsiemi sono limitati in quanto $+\infty = \max \bar \RR$ e  
$-\infty = \min \bar \RR$.
Dunque se diciamo che $A\subset \RR \subset \bar \RR$ è limitato 
(o illimitato) stiamo sempre facendo riferimento all'ordinamento di $\RR$ 
per il semplice fatto che la limitatezza in $\bar \RR$ è banale.
Diremo quindi sempre che $\NN$ è superiormente illimitato anche se
in $\bar \RR$ esiste il maggiorante $+\infty$.

D'altro canto è utile osservare che $\bar \RR$ ha un ordinamento 
continuo, come quello di $\RR$ e dunque, per il Teorema~\ref{th:sup}
sappiamo che ogni sottoinsieme di $\bar \RR$ ha sempre 
estremo superiore ed estremo inferiore anche se è vuoto o illimitato.

Dunque è consuetudine estendere gli operatori $\sup$ e $\inf$
a tutti i sottoinsiemi di $\RR$ ponendo 
\begin{align*}
  \sup A &= +\infty \quad \text{se $A$ non è superiormente limitato},\\
  \inf A &= -\infty \quad \text{se $A$ non è inferiormente limitato},\\
  \sup \emptyset &= -\infty, \\ 
  \inf \emptyset &= +\infty.
\end{align*}

\subsection{intervalli}

\begin{definition}[intervallo]
\label{def:intervallo}%
\mymargin{intervallo}%
\index{intervallo}%
Un insieme $I\subset \bar\RR$ si dice essere un \emph{intervallo}
se contiene tutti i punti intermedi:
\[
  \text{se $x, y \in I$ e $x<z<y$ allora $z \in I$.}
\]
\end{definition}
%
\begin{theorem}[caratterizzazione intervalli di $\RR$]
Sia $I\subset \RR$ e siano $a=\inf I$, $b=\sup I$,
$a,b\in \bar \RR$,
i suoi estremi. 
Allora $I$ è un intervallo se e solo se per ogni $x$ tale 
che $a<x<b$ si ha $x\in I$
\end{theorem}
%
\begin{proof}
Supponiamo che $I$ sia un intervallo.
Se $I=\emptyset$ si ha $a>b$ e quindi nessun $c$ verifica $a<x<b$.
Supponiamo $I\neq \emptyset$ e
sia $a < x < b$.
Visto che $a$ è il massimo dei minoranti di $I$
il numero $x$ non è un minorante dunque
deve esistere $y \in I$ tale
che $y < x$. 
Analogamente dovrebbe esistere $z\in I$
con $x < z$.
Ma allora, per definizione di intervallo, anche $x\in I$.

Viceversa supponiamo di avere $y,z\in I$ e $x\in \RR$ con $y<x<z$.
Visto che $y\ge a$ e $z\le b$ si ha $a<x<b$ e dunque, per ipotesi, 
$x\in I$, come richiesto dalla definizione di intervallo.
\end{proof}

Il teorema precedente ci dice che un intervallo contiene tutti i punti intermedi 
ai propri estremi. 
Gli estremi, tuttavia, possono essere o non essere inclusi nell'intervallo.
Punti esterni agli estremi non possono invece essere elementi dell'intervallo.
Possiamo quindi caratterizzare tutti gli intervalli di $\bar \RR$
introducendo le seguenti notazioni. Dati $a,b\in \bar \RR$ con $a\le b$
tutti i possibili intervalli con estremi $a$ e $b$ sono i seguenti:
\begin{equation}\label{eq:499494}
\begin{aligned}
\closeinterval{a}{b} &= \ENCLOSE{x\in \bar \RR\colon a \le x \le b} \\
\closeopeninterval{a}{b} &= \ENCLOSE{x\in \bar \RR\colon a \le x < b} \\
\opencloseinterval{a}{b} &= \ENCLOSE{x\in \bar \RR\colon a < x \le b}\\
\openinterval{a}{b} &= \ENCLOSE{x\in \bar \RR\colon a < x < b}.
\end{aligned}
\end{equation}
Abbiamo utilizzato le parentesi quadre per indicare che gli estremi
sono inclusi e le parentesi tonde per indicare che gli estremi sono esclusi.
Osserviamo che in alcuni testi si usano le parentesi quadre rovesciate al posto
delle parentesi tonde.

Se $a>b$ potremmo definire per convenzione:
\begin{equation}\label{eq:488364}
  [a,b] = [b,a], \quad
  [a,b) = (b,a], \quad
  (a,b] = [b,a), \quad
  (a,b) = (b,a).
\end{equation}
Si faccia però attenzione che in altri testi gli intervalli con gli estremi
scambiati non vengono definiti oppure vengono considerati vuoti.

La convenzione può essere utile perché in generale se $\vec a, \vec b$ sono
elementi di uno spazio vettoriale reale $V$ allora ha senso
definire:
\begin{align*}
    [\vec a,\vec b] &= \ENCLOSE{(1-t)\vec a + t \vec b\colon t\in [0,1]},\\
    [\vec a,\vec b) &= \ENCLOSE{(1-t)\vec a + t \vec b\colon t\in [0,1)},\\
    (\vec a,\vec b] &= \ENCLOSE{(1-t)\vec a + t \vec b\colon t\in (0,1]},\\
    (\vec a,\vec b) &= \ENCLOSE{(1-t)\vec a + t \vec b\colon t\in (0,1)}.
\end{align*}
L'intervallo $[\vec a,\vec b]$ è quindi il segmento di estremi
$\vec a$ e $\vec b$ e può essere definito anche se sullo spazio
vettoriale non è dato un ordinamento.
Questo rimane coerente con la definizione~\eqref{eq:499494}
data sopra solamente se adottiamo la convenzione~\eqref{eq:488364}.

Noi considereremo per lo più intervalli di $\RR$ (non di $\bar \RR$): in tal
caso gli estremi infiniti saranno quindi sempre esclusi dall'intervallo.

\subsection{andamento del grafico di una funzione}
%
Se $f\colon A \subset \RR\to \RR$ è una funzione, un modo molto
utile di rappresentarla graficamente è quello di disegnarne il
grafico, ovvero la curva del piano cartesiano:
\[
   G_f = \ENCLOSE{(x,y)\in A\times \RR\colon y = f(x)}.
\]
Molte proprietà della funzione potranno essere riconosciute
geometricamente guardandone il grafico.

\begin{definition}[simmetrie]
Sia $f\colon A \subset \RR \to \RR$ una funzione.
Diremo che $f$ è:
\begin{enumerate}
\item \emph{pari}%
\mymargin{pari}%
\index{pari}
\index{funzione!pari}%
se $A=-A$ (significa che se $x\in A$ allora anche $-x\in A$) e
\[
  f(-x) = f(x);
\]
\item \emph{dispari}%
\mymargin{dispari}%
\index{dispari}
\index{funzione!dispari}%
se $A=-A$ e
\[
  f(-x) = -f(x);
\]
\item \emph{periodica}%
\mymargin{periodica}%
\index{periodico}
\index{funzione!periodica}%
di periodo $T$ se $A+T=A$
(significa che $x\in A \iff x+T \in A$)
e se per ogni $x\in A$ si ha
\[
  f(x+T)=f(x)
\]
\end{enumerate}
\end{definition}

Ad esempio se $n\in \ZZ$ la funzione $f(x)=x^n$
è pari se $n$ è pari ed è dispari se $n$ è dispari.
Il grafico di una funzione dispari ha una simmetria
centrale, in quanto se $(x,f(x))\in G_f$ allora
anche $(-x,-f(x)) = (-x,f(-x))\in G_f$.
Il grafico di una funzione pari ha invece una
simmetria rispetto all'asse delle ordinate $x=0$
infatti se $(x,f(x))\in G_f$ allora $(-x,f(x)) = (-x,f(-x)) \in G_f$.

La funzione $f(x) = x - \lfloor x\rfloor$ (la parte frazionaria di $x$)
è un esempio di funzione periodica di periodo $T=1$. Infatti
è chiaro che $\lfloor x+1\rfloor = \lfloor x \rfloor +1$ e quindi
$f(x+1)=f(x)$.

Si osservi che \emph{dispari}, per le funzioni, non è la negazione
di \emph{pari}.
La funzione $f(x) = x+1$ non è né pari, né dispari, né periodica
(verificare).


\begin{definition}[zeri]
  Se $f\colon A\subset \RR \to \RR$ è una funzione diremo che
  $x\in A$ è uno \emph{zero} di $f$ se $f(x)=0$.
  L'\emph{insieme degli zeri}%
\mymargin{insieme degli zeri}%
\index{insieme!degli zeri}
  \index{zero!di una funzione}%
  è quindi dato da
  \[
    f^{-1}(\ENCLOSE{0}) = \ENCLOSE{x\in \RR\colon f(x) = 0}.
  \]
\end{definition}

Abbiamo già accennato al fatto che uno dei problemi più comuni in
matematica è quello di invertire una funzione. In particolare 
dato $y\in \RR$ ci si chiede quali siano gli $x\in \RR$ 
tali che $f(x)=y$. 
Questo problema si riconduce
a trovare gli zeri della funzione $f(x)-y$ e per questo motivo 
siamo interessati allo studio degli zeri.

Riprendiamo ora la definizione~\ref{def:monotonia} (monotonia) che da ora in avanti 
potrà essere applicata alle funzioni $f\colon A \to \RR$ definite 
su un insieme $A\subset \RR$.

Dal punto di vista grafico una funzione $f$ è crescente
se preso qualunque punto $(x,f(x))$ sul grafico della funzione
e tracciati gli assi paralleli agli assi cartesiani, passanti
per il punto fissato, si osserva che il grafico della funzione
è tutto contenuto nel primo e terzo quadrante determinati
dagli assi traslati.

E' facile verificare che la funzione $f\colon [0,+\infty)\to \RR$
definita da $f(x)=x^n$
è strettamente crescente se $n$ è un intero positivo.
Se però consideriamo la funzione definita su tutto
$\RR$: $f\colon \RR \to \RR$,
$f(x)=x^n$ allora solo se $n$ è dispari la funzione rimane
strettamente crescente
(le funzioni pari non possono mai essere strettamente crescenti se
il loro dominio contiene almeno tre punti).

Se una funzione non è monotona è piuttosto comune studiare 
la monotonia della funzione ristretta a particolari intervalli: 
su alcuni intervalli la funzione (ristretta) potrà essere crescente e su altri 
intervalli potrà essere decrescente.

\begin{exercise}
Verificare che la composizione di funzioni monotone è una
funzione monotona e la composizione di funzioni strettamente
monotone è strettamente monotona.
Quando è che la funzione composta risulta crescente?
Quando decrescente?
\end{exercise}

\begin{exercise}
Si dimostri che applicando una funzione strettamente crescente ai due
membri di una equazione o disequazione (stretta o larga che sia)
si ottiene una equazione o disequazione equivalente.
Ovviamente è necessario che la funzione sia definita dove viene applicata.

Lo stesso vale per le funzioni strettamente decrescenti 
se però si cambia il verso della disequazione.
\end{exercise}

\begin{definition}[funzioni limitate, massimo/minimo]
\label{def:funzione_limitata}%
Se $f\colon A \to \RR$ è una funzione allora definiamo
l'estremo superiore di $f$ come l'estremo superiore
dell'immagine di $f$:
\[
  \sup f = \sup_{x\in A} f(x) = \sup f(A).
\]
In maniera analoga si definiscono l'estremo inferiore $\inf f$,
il massimo $\max f$ e il minimo $\min f$.

Dunque il massimo di una funzione è (se esiste) il valore massimo
che la funzione può assumere. I punti $x$ in cui
la funzione assume il valore massimo $f(x)$ vengono chiamati
\emph{punti di massimo}.
\mymargin{punto di massimo/minimo}%
\index{punto di massimo/minimo}%
\index{punto!di massimo}%
\index{punto!di minimo}%
Analogamente i punti in cui la funzione
assume il valore minimo (sempre che esistano) vengono
chiamati \emph{punti di minimo}.

Diremo che la funzione $f$ è
\emph{superiormente limitata}%
\mymargin{funzione superiormente limitata}%
\index{superiormente limitata}
se $\sup f<+\infty$
ovvero se esiste $M\in \RR$ tale che
\[
\forall x\in A \colon f(x) \le M.
\]
Diremo che la funzione $f$ è
\emph{inferiormente limitata}%
\mymargin{funzione inferiormente limitata}%
\index{inferiormente!limitato}
se $\inf f > -\infty$ ovvero se esiste $M\in \RR$ tale che
\[
 \forall x \in A \colon f(x) \ge M.
\]
Diremo che la funzione $f$ è \emph{limitata}%
\mymargin{funzione limitata}%
\index{limitata}
se è sia superiormente che inferiormente limitata ovvero
se $\sup\abs{f}<+\infty$ cioè se esiste $M\in \RR$ tale che
\[
\forall x \in A \colon \abs{f(x)}\le M.
\]
\end{definition}

Nel seguente esercizio abbiamo un esempio di funzione limitata.
\begin{exercise}
Si consideri la funzione $f\colon \RR\to\RR$
\[
 f(x) = \frac{1}{1+x^2}.
\]
Verificare che $f$ è pari, che $\max f = \sup f = 1$, che $0$ è l'unico punto di massimo,
che $\inf f = 0$ e che $\min f$ non esiste.
\end{exercise}

\subsection{funzioni lineari}

\begin{figure}
  \begin{center}
    \begin{tikzpicture}[x=1.0cm,y=1.0cm]
    	\draw[->] (-1,0) -- (4,0);
      \draw[->] (0,-1) -- (0,3);
      % y = (3/5)*x + 1/5
      \fill[fill=lightgray,draw] (1,0.8) -- (2,0.8) node [midway,below]{$\Delta x$} -- (2,1.4) node [midway,right]{$\Delta f(x)$};
      \draw[thick] (-1,-0.4) -- (4,2.6);
      \draw[->] (1,0) node[below]{$x_1$} -- (1,0.8)
      -- (0,0.8) node[left]{$f(x_1)$};
      \draw[->] (2,0) node[below]{$x_2$} -- (2,1.4)
      -- (0,1.4) node[left]{$f(x_2)$};
      \fill (1,0.8) circle[radius=1.5pt];
      \fill (2,1.4) circle[radius=1.5pt];
      \node[left] at (3.0,2.5) {$y=mx+q$};
    \end{tikzpicture}
  \end{center}
  \caption{Il grafico di una funzione lineare.}
  \label{fig:funzione_lineare}
\end{figure}

Le \emph{funzioni lineari}%
\mymargin{funzione lineare}%
\index{funzioni lineari}
$f\colon \RR \to \RR$ sono le funzioni per le quali
esistono $m,q\in\RR$ tali che%
\mynote{%
Attenzione: nell'ambito dell'algebra lineare queste
funzioni verrebbero chiamate \emph{lineari affini}, mentre
le funzioni lineari dovrebbero sempre avere $q=0$.
Noi invece (come spesso accade nell'ambito dell'analisi)
chiameremo lineari queste funzioni e chiameremo
\emph{lineari omogenee} quelle con $q=0$.
Il termine \emph{lineare} pervade tutta la matematica 
e si applica in particolare alle equazioni che si ottengono 
tramite le funzioni lineari.
Purtroppo il nome scelto è fuorviante: la parola \emph{linea} viene 
usata a volte come abbreviazione di \emph{linea retta}, quando 
invece sarebbe più giusto utilizzare l'abbreviazione \emph{retta}
in quanto una linea può benissimo essere curva.
In altri contesti (come ad esempio nell'ambito degli ordinamenti)
il termine \emph{lineare} rappresenta un oggetto unidimensionale
senza ramificazioni ed è quindi maggiormente aderente 
al significato originale della parola.
} % marginnote
\[
  f(x) = mx + q.
\]

Se prendiamo due punti $(x_1,f(x_1))$
e $(x_2,f(x_2))$ sul grafico di una funzione lineare
possiamo osservare che si ha
\[
  \frac{f(x_2) - f(x_1)}{x_2 - x_1} = m.
\]
Il coefficiente $m$, dunque, rappresenta la pendenza del
grafico di $f$, ovvero il rapporto tra la variazione
dei valori della funzione $\Delta f = f(x_2) - f(x_1)$
e la variazione della variabile in ingresso
$\Delta x = x_2 - x_1$.
Geometricamente questo è il rapporto tra i due cateti
(base e altezza) che formano un triangolo rettangolo la
cui ipotenusa è il segmento che congiunge i due punti sul grafico.
Il fatto che questo rapporto sia costante significa,
in base al teorema di Talete, che i punti del grafico sono
allineati ovvero che il grafico di una funzione lineare è,
dal punto di vista geometrico, una retta.

\begin{definition}[retta]
  \index{retta}%
  \index{linea!retta}%
  Una \emph{linea retta} (più semplicemente: \emph{retta}) in uno spazio affine
  è un sottospazio affine di dimensione 1 
  ovvero la traslazione di un sottospazio vettoriale di dimensione 1
  (si rimanda al corso di geometria).
\end{definition}

Tutte le rette del piano, 
tranne quelle parallele all'asse delle ordinate,
sono grafico di una funzione lineare.

Si osservi che per $m>0$ la funzione è strettamente crescente,
per $m=0$ la funzione è costante e per $m<0$ la funzione è
strettamente decrescente.

\subsection{funzioni quadratiche}
\label{sec:funzioni_quadratiche}

\begin{figure}
  \begin{center}
    \begin{tikzpicture}[x=1.0cm,y=1.0cm]
      \clip(-1,-1) rectangle (4,3);
    	\draw[->] (-1,0) -- (4,0);
      \draw[->] (0,-1) -- (0,3);
      % y = (3/5)*x + 1/5
      \draw[dashed] (1.75,-1) -- (1.75,4);
      \node[right] at (1.75,2.5){$x=-\frac b {2a}$};
      \draw[domain=-1.0:4.0,smooth,variable=\x,thick] plot
      ({\x}, {0.5*(\x-0.5)*(\x-3.0)});
      \fill (0.5,0.0) node[below]{$x_1$} circle[radius=1.5pt];
      \fill (3,0.0) node[below]{$x_2$} circle[radius=1.5pt];
      \node at (1.8,1) {$y=ax^2+bx+c$};
    \end{tikzpicture}
  \end{center}
  \caption{Il grafico di una funzione quadratica.}
  \label{fig:funzione_quadratica}
\end{figure}

Le funzioni espresse mediante un \emph{polinomio di secondo grado}%
\mymargin{polinomio di secondo grado}%
\index{polinomio!di secondo grado}
\begin{equation}\label{eq:funzione_quadratica}
  f(x) = ax^2 + bx +c
\end{equation}
con $a,b,c\in \RR$, $a\neq 0$, si possono chiamare
\emph{funzioni quadratiche}%
\mymargin{funzioni quadratiche}%
\index{funzione!quadratica}.

Il modello di funzione quadratica è la funzione
$f(x) = x^2$ che (come tutte le potenze di esponente positivo e pari)
risulta essere una funzione pari, strettamente crescente
sull'intervallo $[0,+\infty)$ e strettamente decrescente
su $(-\infty,0]$. La funzione assume solamente valori non negativi
e si annulla solo per $x=0$.
Dunque l'equazione
\[
  x^2 = b
\]
non ha soluzione se $b<0$ ed ha come unica soluzione $x=0$ se $b=0$.
Se $b>0$ sappiamo che
questa equazione ha una unica soluzione positiva $x_1 = \sqrt{b}$
e, per simmetria, ha anche una soluzione negativa $x_2 = -\sqrt{b}$.
Sintetizzando si usa scrivere $x_{1,2} = \pm \sqrt{b}$
per condensare in una unica riga le due definizioni.

La generica funzione quadratica~\eqref{eq:funzione_quadratica}
può essere ricondotta al caso modello tramite un cambio
di variabile lineare. In pratica si cerca di comporre il quadrato
di un binomio con un procedimento chiamato
\emph{completamento del quadrato}%
\mymargin{completamento del quadrato}%
\index{completamento del quadrato}:
\begin{equation}\label{eq:24589}
\begin{aligned}
f(x) = ax^2+bx+c
  &= a \Enclose{x^2+\frac b a x + \frac c a}\\
  &= a \Enclose{x^2+2 \frac{b}{2a} x + \frac{b^2}{4a^2} - \frac{b^2}{4a^2} + \frac c a}\\
  &= a \Enclose{\enclose{x+\frac{b}{2a}}^2 - \frac{b^2-4ac}{4a^2}} \\
  &= a\enclose{x+\frac b{2a}}^2  - \frac{b^2-4ac}{4a}.
\end{aligned}
\end{equation}

Ponendo $X=x+\frac b{2a}$ e $Y=y+\frac{b^2-4ac}{4a}$
l'equazione $y=ax^2+bx+c$ diventa quindi $Y=aX^2$. 
Significa
che il grafico della funzione quadratica~\eqref{eq:funzione_quadratica}
si ottiene traslando la curva $y = a x^2$ che, 
dal punto di vista geometrico, si può facilmente
dimostrare essere una parabola con fuoco
nel punto di coordinate $\enclose{0,\frac 1 {4a}}$
e asse la retta di equazione $x=0$.
Dunque il grafico di ogni funzione quadratica è una parabola, 
e più precisamente: ogni parabola con direttrice parallela all'asse delle
ascisse è il grafico di una funzione quadratica.

\begin{definition}[parabola]
  \index{parabola}%
  \index{fuoco!parabola}%
  \index{direttrice!parabola}%
  La parabola $P_{\vec F,r}$ con \emph{fuoco} nel punto $\vec F=(F_1,F_2)\in \RR\times \RR$ 
  e retta \emph{direttrice}
  la retta $r \subset \RR\times\RR$ 
  è l'insieme dei punti  $\vec x = (x_1,x_2)\in \RR\times\RR$ 
  equidistanti da $\vec F$ e da $r$:
  \[
  P_{\vec F,r} = \ENCLOSE{\vec x\in \RR\times\RR\colon 
  \sqrt{(x_1-F_1)^2 + (x_2-F_2)^2} 
  = \inf_{\vec P\in r}\sqrt{(x_1-P_1)^2+(y_1-P_1)^2}
  }.
  \]
\end{definition}

\begin{exercise}
  Si dimostri che per ogni $a\neq 0$ esiste $s\neq 0$ 
  per cui il riscalamento $X=sx$, $Y=sy$ porta il grafico della 
  parabola $y=ax^2$ nel grafico della parabola $Y=X^2$.
  Significa che 
  c'è una unica parabola 
  a meno di isometrie e riscalamenti.
\end{exercise}

Ricordando le proprietà di monotonia della funzione $X\mapsto X^2$
possiamo dedurre che se $a>0$ la funzione $f(x)$ è strettamente
decrescente se ristretta all'intervallo 
$\left(-\infty,-\frac b {2a}\right]$ ed è invece strettamente crescente 
sull'intervallo $\left[-\frac b{2a},+\infty\right)$. 
Ha dunque un punto di minimo in $x=-\frac{b}{2a}$.
Inoltre (sempre se $a>0$) la funzione è superiormente illimitata.
Viceversa se $a<0$ la funzione è inferiormente illimitata ed ha 
un massimo nel punto $x=-\frac{b}{2a}$.

E' molto importante saper risolvere equazioni e disequazioni
quadratiche. Grazie a~\eqref{eq:24589} l'equazione
\[
 a x^2 + bx + c = 0
\]
risulta equivalente a
\[
  \enclose{x+\frac{b}{2a}}^2 = \frac{b^2-4ac}{4a^2}.
\]
Dunque se $b^2-4ac<0$ l'equazione $ax^2+bx+c=0$ non ha soluzioni.
Se $b^2-4ac=0$ l'equazione ha una unica soluzione $x=-\frac{b}{2a}$.
Infine se $b^2-4ac>0$ si ottiene
\[
  x+\frac b{2a} = \pm \frac{\sqrt{b^2-4ac}}{2a}
\]
da cui la famosa formula risolutiva
\mymark{***}
\begin{equation}\label{eq:secondo_grado}
  x_{1,2} = \frac{-b \pm \sqrt{b^2-4ac}}{2a}.
\end{equation}

Risolvendo le disequazioni allo stesso modo, si trova
che la funzione $ax^2+bx+c$, quando $a>0$ è positiva
nei punti esterni alle soluzioni dell'equazione
(in tutti i punti se le soluzioni non esistono) ed
è negativa nei punti interni alle due soluzioni.
Viceversa se $a<0$ la funzione è positiva all'interno
delle due soluzioni e negativa all'esterno.


\subsection{funzioni esponenziali}
%
%
\label{sec:esponenziale}%

Il teorema di isomorfismo ci ha permesso di definire la moltiplicazione sui 
numeri reali. 
Lo stesso identico metodo ci permetterà di definire la funzione esponenziale
ovvero la potenza $a^x$ con base $a>0$ fissata ed esponente variabile $x\in \RR$.
Abbiamo infatti già osservato che l'insieme $\RR_+$ dei reali positivi
risulta essere un gruppo moltiplicativo totalmente ordinato, denso e continuo 
(teorema~\ref{th:gruppo_moltiplicativo}).

\begin{theorem}[funzione esponenziale]
  \label{th:esponenziale}%
Dato $a\in \RR$, $a\ge 1$ per ogni $x\in \RR$ si può definire in modo unico 
la funzione esponenziale $x\mapsto a^x$ con le seguenti proprietà:
\begin{enumerate}
  \item $a^1=a$;
  \item $a^{x+y} = a^x \cdot a^y$;
  \item $a^x\ge 1$ se $x\ge 0$.
\end{enumerate}
Se $0<a \le 1$ si può definire in modo unico l'esponenziale $x\mapsto a^x$ 
con le stesse proprietà, salvo che per ogni $x\ge 0$ si ha $a^x\le 1$.

Inoltre l'esponenziale ha le seguenti proprietà, 
valide per $a,b>0$, $x,y\in \RR$:
\begin{enumerate}
  \item $a^0=1$;
  \item $a^{-1} = \frac{1}{a}$;
  \item $(a\cdot b)^x = a^x\cdot b^x$;
  \item $(a^x)^y = a^{x\cdot y}$;
  \item $a^x \le a^y$ se $a\ge 1$ e $x\le y$;
  \item $1^x=1$.
\end{enumerate}
\end{theorem}
%
\begin{proof}
Fissato $a>0$ possiamo applicare il teorema~\ref{th:isomorfismo} (isomorfismo)
con $R=\RR$ gruppo additivo e $S=\RR_+$ gruppo moltiplicativo.
Se $a\ge 1$ si ottiene l'esistenza di una, unica, funzione $\phi_a\colon \RR \to \RR_+$ 
che soddisfa le seguenti proprietà:
$\phi_a(1)=a$, $\phi_a(x+y) = \phi_a(x)\cdot \phi_a(y)$, 
$\phi_a(x)\ge 1$ se $x\ge 0$. 
Se $0<a\le 1$ otteniamo una unica funzione con le stesse proprietà 
ma $\phi_a(x) \le 1$ se $x\ge 0$.

Definiamo $a^x = \phi_a(x)$ e la chiamiamo \emph{funzione esponenziale}
con \emph{base} $a>0$ ed esponente $x\in \RR$.
  
L'omomorfismo manda sempre l'elemento neutro nell'elemento 
neutro dunque $a^0 = 1$.
\mynote{Ricordiamo che in partenza abbiamo il gruppo additivo $\RR$
con elemento neutro $0$ mentre in arrivo 
abbiamo il gruppo moltiplicativo $\RR_+$ con elemento neutro $1$.}

\mymargin{$a^{-1}=\frac 1 a$}
Per la proprietà di omomorfismo si ha $a^{x-x} = a^x \cdot a^{-x}$
da cui $a^{-x}$ risulta essere il reciproco di $a^x$ cioè 
$a^{-x}= 1/a^x$.

Per la potenza del prodotto fissati $a,b\ge 1$ basta considerare la 
funzione $f(x) = a^x\cdot b^x$. 
\mymargin{$(a\cdot b)^x = a^x\cdot b^x$}
Chiaramente $f$ è un omomorfismo in quanto $a^x$ e $a^y$ lo sono 
(e il prodotto è commutativo): 
$a^{x+y}\cdot b^{x+y} = a^x \cdot b^x\cdot a^yb^y$.
Inoltre se $x\ge 0$ si ha $a^x\ge1$ e $b^x\ge 1$ da cui $f_(x)\ge 1$.
Essendo $f(1) = a^1\cdot b^1 = a\cdot b$ 
per l'unicità dell'omomorfismo positivo concludiamo che $f = \phi_{a\cdot b}$
cioè $a^x\cdot b^x = (a\cdot b)^x$.
Usando la regola del reciproco possiamo estendere questa proprietà 
quando $a<1$ e/o $b<1$ (ma sempre $a,b\ge 0$).

\mymargin{$(a^x)^y = a^{x\cdot y}$}
Infine per la potenza di potenza fissato $a\ge 1$ e $x\ge 0$ 
consideriamo la funzione $f(y) = a^{x\cdot y}$.
Per le proprietà precedenti si verifica facilmente che  
$f(y+z) = f(x)\cdot f(z)$. 
Inoltre se $a\ge 1$, $x\ge 0$ e $y\ge 0$ si ha 
$f(y)\ge 1$ che è la positività. 
Dunque per il teorema di isomorfismo,
essendo $f(1)=a^x$, si ottiene $f(y) = (a^x)^y$
che è quanto volevamo dimostrare.
La regola del reciproco estende questa proprietà 
ai casi $x\le 0$ e $a\le 1$ (sempre con $a\ge 0$).

Se $a\ge 1$ e $x\le y$ allora $a^{y-x}\ge 1$.
\mymargin{monotonia}
Ma $a^{y-x} = \frac{a^y}{a^x}$ e dunque $a^y\ge a^x$.

Se $a=1$ per $x\ge 0$ si ha contemporaneamente $1^x\ge 1$ e $1^x\le 1$
dunque $1^x=1$. 
Lo stesso vale se $x\le 0$ in quanto $1^{-x}=\frac 1{1^x}$.
\mymargin{$1^x=1$}
\end{proof}

\begin{figure}
  \begin{center}
    \begin{tikzpicture}[x=1.0cm,y=1.0cm]
      \clip(-4,-2) rectangle (4,3);
    	\draw[->] (-4,0) -- (4,0);
      \draw[->] (0,-2) -- (0,3);
      % y = (3/5)*x + 1/5
      \draw[dotted] (1,0) -- (1,2) -- (0,2);
      \draw[dotted] (2,0) -- (2,1) -- (0,1);
%      \node[right] at (1.75,2.5){$x=-\frac b {2a}$};
      \draw[domain=-2.0:4.0,smooth,variable=\x,dashed] plot
        ({\x}, {pow(2,-\x)});
      \draw[domain=0.1:4.0,smooth,variable=\x,dashed] plot
        ({\x}, {-ln(\x) / ln(2)});
      \draw[domain=-4.0:2.0,smooth,variable=\x,thick] plot
        ({\x}, {pow(2,\x)});
      \node at (2,2.5) {$y=a^x$};
      \node at (-2,2.1) {$y=\enclose{\frac 1 a}^x$};
      \fill (0,1.0) node[left]{\!\!$1$} circle[radius=1.5pt];
      \draw[domain=0.1:4.0,smooth,variable=\x,thick] plot
        ({\x}, {ln(\x) / ln(2)});
      \node at (3.2,1.1) {$y=\log_a x$};
      \node at (3.2,-1.1) {$y=\log_{\frac 1 a} x$};
      \fill (1,0) node[below]{$1$} circle[radius=1.5pt];
      \fill (0,2) node[left]{$a$} circle[radius=1.5pt];
      \fill (2,0) node[below]{$a$} circle[radius=1.5pt];
      \fill (2,1) circle[radius=1.5pt];
      \fill (1,2) circle[radius=1.5pt];
    \end{tikzpicture}
  \end{center}
  \caption{Il grafico della funzione esponenziale e logaritmo 
  in base $a>1$ e $\frac 1 a < 1$ ($a=2$ in figura).}
  \label{fig:esponenziale_logaritmo}
\end{figure}




%
\subsection{logaritmo}
%
%
%

\label{sec:logaritmo}
\index{logaritmo}%

Il teorema di isomorfismo ci dice che fissato $a\in \RR_+$, $a\neq 1$ 
la funzione $\phi_a\colon \RR\to\RR_+$ definita nel paragrafo 
precedente ($\phi_a(x)=a^x$) è bigettiva.
La funzione inversa si chiama \emph{logaritmo in base $a$}
e si denota con $\log_a\colon \RR_+ \to \RR$.

Grazie alle proprietà della funzione esponenziale, già dimostrate
nel teorema~\ref{th:esponenziale} possiamo ottenere 
le proprietà del logaritmo.

\begin{theorem}[proprietà del logaritmo]
Per ogni $a>1$
esiste una unica funzione $\log_a\colon \RR_+\to \RR$ 
tale che 
\begin{enumerate}
  \item $\log_a(a) = 1$;
  \item $\log_a(x\cdot y) =\log_a x + \log_a y$;
  \item $\log_a x \ge 0$ se $x\ge 1$. 
\end{enumerate}
Se $0<a<1$ 
esiste una unica funzione $\log_a$ con le stesse proprietà 
salvo che $\log_a x \le 0$ se $x\ge 1$.

La funzione $\log_a$ viene chiamata \emph{logaritmo in base $a$}
ed ha inoltre le seguenti proprietà valide 
per ogni $a>0$, $a\neq 1$, $x,y\in \RR$, $b>0$, $c>0$, $c\neq 1$:
\begin{enumerate}
  \item $\log_a x = y$ se e solo se $a^y = x$;
  \item $\log_a 1 = 0$;
  \item $\log_a (b^x) = x\log_a b$;
  \item $\log_a x = \frac{\log_c x}{\log_c a}$.
\end{enumerate}
\end{theorem}

\subsection{potenze con esponente reale}

Nel capitolo~\ref{sec:potenza} abbiamo definito 
la funzione potenza $x^n$ con base $x\in \RR$ 
ed esponente $n\in \NN$. 
Invertendo la fuzione $x^n$ 
(solo per $x\ge 0$ quando $n$ è pari e positivo, per ogni $x\in \RR$ se 
$n$ è dispari) abbiamo definito la radice $n$-esima 
$\sqrt[n]{x}$.
Nel capitolo~\ref{sec:esponenziale} abbiamo 
definito la funzione esponenziale $a^x$ con 
base $a\in \RR_+$ ed esponente $x\in \RR$.
La funzione inversa dell'esponenziale 
è il logaritmo $\log_a x$ definito per $x>0$.

Quando $a>0$ 
e $b\in \NN$,
abbiamo formalmente due diverse definizioni 
dell'operazione \emph{potenza} $a^b$ ma, 
ovviamente, queste due definizioni 
coincidono in quanto il teorema di isomorfismo 
ci garantisce che la funzione esponenziale 
$a^x$ coincide con la moltiplicazione ripetuta 
quando $x$ è un numero naturale.
Grazie a questa osservazione possiamo osservare 
che se $x>0$, $p\in \NN$ e $q\in \NN$, $q\neq 0$ si ha 
\begin{equation}
\label{eq:9783023}
  x^{\frac p q} = \sqrt[q]{x^p}, 
  \qquad 
  x^{-\frac p q} = \frac{1}{\sqrt[q]{x^p}}
\end{equation}
in quanto 
\[
  \enclose{x^{\frac p q}}^q = x^p,
  \qquad
  x^{-y} = \frac{1}{x^y}.
\]
Se ripercorriamo la dimostrazione del teorema di isomorfismo 
usando in arrivo il gruppo additivo (è così che abbiamo 
definito la funzione esponenziale) ci accorgiamo 
che la funzione $a^x$ viene dapprima definita sugli $x$
naturali come moltiplicazione ripetuta, 
poi sugli $x$ razionali 
positivi tramite la radice $n$-esima e poi sugli 
$x$ negativi passando al reciproco.

Senz'altro potrà essere utile definire 
$a^{-n} = \frac 1 {a^n}$ avendo quindi una definizione 
di potenza $a^n$ valida per ogni $a$ se $n\in \NN$ 
e per ogni $a\neq 0$ se $n\in \ZZ$.
In alcuni testi si va oltre e si considera $a^b$ 
definito anche quando $a<0$ e $b$ è razionale
utilizzando il lato destro delle equazioni 
in~\eqref{eq:9783023}.
Ognuno può scegliere le definizioni che preferisce 
ed è bene ricordare che le definizioni si scelgono, 
non si dimostrano. 
E' però anche bene sapere che certe definizioni 
possono essere fuorvianti.

Ci sono buoni motivi per pensare che la funzione 
esponenziale $a^x$ ($a>0$) e la funzione potenza $x^n$ 
con $n\in \NN$ siano funzioni sostanzialmente diverse.
Si noti ad esempio che le regole delle potenze sono 
soddisfatte da entrambe le definizioni, separatamente, 
ma se mescoliamo le due definizioni le proprietà 
possono cadere. Ad esempio:
\[
  \enclose{(-2)^6}^{\frac 1 2} 
  \neq \enclose{-2}^{6\cdot \frac 1 2}.
\]

Anche il fatto che abbiamo definito $0^0=1$ andrebbe 
interpretato nel senso che lo $0$ all'esponente 
è un numero naturale, non un numero reale:
La funzione esponenziale $a^x$ è definita 
solo per $a>0$ mentre la funzione $x^n$ è definita anche 
per $x=0$ ma solo per $n\in \NN$.


% \begin{figure}
%   \begin{center}
%     \begin{tikzpicture}[x=1.0cm,y=1.0cm]
%       \clip(-3,-2) rectangle (4,3);
%     	\draw[->] (-3,0) -- (4,0);
%       \draw[->] (0,-2) -- (0,3);
%       \draw[dotted] (1,0) -- (1,1) -- (0,1);
%       % \draw[dotted] (2,0) -- (2,1) -- (0,1);
%       \draw[domain=0.5:4,samples=50,variable=\x,thick,dashed] plot
%         ({\x}, {1/(\x*\x))});
%       \draw[domain=-3:-0.5,samples=50,variable=\x,thick,dashed] plot
%         ({\x}, {1/(\x*\x))});
%       \draw[domain=0.2:4,samples=50,variable=\x,dashed,color=gray] plot
%         ({\x}, {1/(\x))});
%       \draw[domain=-3:-0.5,samples=50,variable=\x,dashed,color=gray] plot
%         ({\x}, {1/(\x))});
%       \draw[domain=-2.0:2.0,smooth,variable=\x,thick,color=gray] plot
%         ({\x}, {\x*\x*\x)});
%       \draw[domain=-3.1:4.0,samples=200,variable=\x,color=gray] plot
%         ({\x}, {pow(abs(\x),1/3)*\x / abs(\x)});
%       \draw[domain=-3.0:3.0,smooth,variable=\x,thick] plot
%         ({\x}, {\x*\x});
%       \draw[domain=0.0:4.0,samples=200,variable=\x] plot
%       ({\x}, {pow(\x,1/2)});
%       \node at (-2.0,1.8) {$y=x^2$};
%       \node at (3,2) {$y=\sqrt{x}$};
%       \node[color=gray] at (-1.7,-1.8) {$y=x^{3}$};
%       \node[color=gray] at (-2.0,-1) {$y=\sqrt[3]{x}$};
%       \node[color=gray] at (-1.7,-0.3) {$y=\frac 1 x$};
%       \node at (-2.5,0.6) {$y=\frac 1 {x^2}$};
%       \fill (1,0) node[below]{$1$} circle[radius=1.5pt];
%       \fill (0,1) node[left]{$1$} circle[radius=1.5pt];
%     \end{tikzpicture}
%   \end{center}
%   \caption{Grafici tipici di potenze e radici.}
%   \label{fig:potenza_radice}
% \end{figure}


\subsection{equazioni e disequazioni}

Un problema matematico molto comune è quello di dover risolvere 
equazioni e disequazioni del tipo:
\begin{equation}\label{eq:573197}
  f(x) = b, \quad f(x) \ge b, \quad f(x) > b, 
  \quad f(x) \le b, \quad f(x) < b
\end{equation}
dove $f\colon A \subset \RR \to\RR$ è una funzione data e 
$b\in \RR$ è fissato.

Quando $f$ è strettamente crescente e $b\in f(A)$ 
la soluzione può essere 
scritta banalmente: 
ovviamente deve essere $x\in A$
e ogni equazione o disequazione in~\eqref{eq:573197}
avrà la corrispondente soluzione:
\[
  x= f^{-1}(b), \quad x \ge f^{-1}(b), \quad x>f^{-1}(b),
  \quad x \le f^{-1}(b), \quad x < f^{-1}(b).
\]
Se la funzione fosse strettamente decrescente 
si può procedere allo stesso modo, ma le disuguaglianze si invertono.
Se la funzione fosse strettamente crescente su alcuni intervalli 
e strettamente decrescente su altri si potranno separare i diversi 
casi e si otterranno più soluzioni espresse da uguaglianze
o disuguaglianze.

\begin{example}
  Si risolva la disequazione 
  \[
   \log_2\Enclose{\sqrt[3]{(x+1)^4-3}-2} \le 3. 
  \]
\end{example}%
\begin{proof}[Svolgimento.]
La funzione logaritmo è strettamente crescente ed è definita 
quando l'argomento è positivo. 
Dunque la disequazione data 
è equivalente al sistema di disequazioni:
\[
0 < \sqrt[3]{(x+1)^4 - 3} - 2 \le 8.  
\]
Possiamo sommare $2$ per ottenere 
\[
  2 < \sqrt[3]{(x+1)^4 - 3} \le 10.  
\]
La funzione radice cubica è strettamente crescente 
su tutto $\RR$ quindi possiamo invertirla elevando 
tutto al cubo:
\[
 8 < (x+1)^4 - 3 \le 1000.
\]
Sommiamo $3$:
\[
11 < (x+1)^4 \le 1003.  
\]
L'elevamento alla quarta potenza è strettamente crescente 
solo quando l'argomento è positivo, ed è una funzione pari.
Possiamo quindi affermare che le nostre disequazioni sono 
equivalenti all'unione delle soluzioni di due sistemi:
\[
  \sqrt[4]{11} < x+1 \le \sqrt[4]{1003}
  \qquad\text{o}\qquad 
  -\sqrt[4]{1003} \le x+1 < -\sqrt[4]{11}.
\]
Sottraendo $1$ otteniamo infine 
\[
  \sqrt[4]{11} -1 < x \le \sqrt[4]{1003} - 1
  \qquad\text{o}\qquad 
  -\sqrt[4]{1003} -1 \le x < -\sqrt[4]{11} -1.
\]
In definitiva l'insieme delle soluzioni è 
\[
\left[-\sqrt[4]{1003} - 1, -\sqrt[4]{11}-1\right)
\cup \left(\sqrt[4]{11}-1 , \sqrt[4]{1003} -1\right].  
\]
\end{proof}

Nell'esempio precedente la funzione 
$f(x) = \log_2\Enclose{\sqrt[3]{(x+1)^4-3}-2}$
è ottenuta mediante composizione di funzioni elementari:
\begin{align*}
f &= (x\mapsto \log_2 x)\circ(x\mapsto x-2)\circ (x \mapsto \sqrt[3]{x})\\
  &\quad \circ (x \mapsto x-3) \circ (x\mapsto x^4) \circ (x\mapsto x+1).
\end{align*}
Negli intervalli in cui tutte queste funzioni sono invertibili 
la funzione inversa si ottiene componendo, in ordine opposto,
tutte le inverse:
\begin{align*}
  f^{-1} &= (x\mapsto x-1) \circ (x\mapsto \sqrt[4]{x}) \circ (x \mapsto x+3) \\
    &\quad \circ (x \mapsto x^3) \circ (x \mapsto x+2) \circ (x\mapsto 2^x).
\end{align*}
In effetti il caposaldo $\sqrt[4]{1003}-1$ è proprio tale 
funzione valutata in $b=3$.

Il metodo precedente è puramente algebrico e 
si applica alle equazioni 
come la~\eqref{eq:573197} dove la variabile $x$ 
compare una sola volta e dove la funzione $f$ si esprime 
come composizione di funzioni elementari di cui sappiamo 
scrivere la funzione inversa. 

Ben diverso è il caso in cui nell'equazione la variabile $x$ 
compare più di una volta.
In alcuni casi, come ad esempio,
\[
  x^2 > 2x - 1  
\]
queste equazioni 
possono essere ricondotte al caso precedente tramite 
opportune manipolazioni algebriche.
Il caso delle equazioni quadratiche lo abbiamo 
fatto nel paragrafo precedente utilizzato il completamento 
del quadrato: $x^2-2x = (x-1)^2-1$. 
In altri casi, come ad esempio l'equazione
\[
  2^x = x^2
\]  
le manipolazioni algebriche non sono utili.
Nel capitolo sul calcolo differenziale svilupperemo degli strumenti 
che ci permetteranno di determinare l'andamento di molte di queste 
di funzioni. 
Nel capitolo sulle successioni svilupperemo invece gli strumenti 
che ci permetteranno di determinare le soluzioni mediante 
algoritmi di approssimazione.
Questi strumenti presuppongono il concetto 
di limite e continuità: è sostanzialmente questo che identifica 
la materia chiamata analisi matematica.

\section{i numeri complessi}
%
%
%
\label{sec:complessi}

Dal punto di vista geometrico l'insieme $\CC$ dei \emph{numeri complessi}%
\mymargin{numeri complessi}%
\index{numeri!complessi}
\index{$\CC$}
può essere visto come una rappresentazione cartesiana 
del piano euclideo.
Sul piano fissiamo arbitrarimente un punto $0$ (l'origine) 
e fissiamo, arbitrariamente, una base $e_1$, $e_2$ di vettori ortonormali.
Identifichiamo ogni punto del piano con i corrispondenti vettori
applicati in $0$. La retta generata dal vettore $e_1$ la identifichiamo
con la retta $\RR$ dei numeri reali e quindi poniamo $1=e_1$.
La retta ortogonale generata dal vettore $e_2$ verrà chiamata
retta dei \emph{numeri immaginari} e definiamo $i=e_2$.

Un generico punto $z$ del piano $\CC$ potrà essere scritto in
maniera univoca nella base scelta: $z = x e_1 + y e_2$ ovvero,
per come abbiamo chiamato $e_1$ ed $e_2$:
\[
z = x + i y.
\]
Tale $z$ viene chiamato
\emph{numero complesso} con parte reale $x$ e parte immaginaria $y$.
Questa rappresentazione del numero complesso $z$ viene
chiamata \emph{rappresentazione cartesiana}%
\mymargin{rappresentazione cartesiana}%
\index{rappresentazione!cartesiana} in quanto definisce
il punto $z$ del piano complesso tramite le sue coordinate cartesiane
$x$ e $y$.
I numeri reali sono \emph{immersi} nei complessi, nel senso che se
$x\in \RR$ allora $z= x + i\cdot 0 = x$ è anche un numero complesso.
Il numero complesso $i = 0 + i\cdot 1$ viene chiamata \emph{unità immaginaria}%
\mymargin{unità immaginaria}%
\index{unità!immaginaria}
e i numeri complessi della forma $iy$ sono chiamati \emph{immaginari}.
\index{numeri!immaginari}
\index{immaginario}
Un numero
complesso $z = x+iy$ è quindi una somma tra un numero reale ed un numero
immaginario. Il numero reale $x$ viene chiamato \emph{parte reale}
\index{parte!reale}
di $z$ e
si denota con $x=\Re z$.
\mymargin{$\Re z$}%
\index{$\Re z$}
Il numero reale $y$ viene chiamato
\emph{parte immaginaria}
\index{parte!immaginaria}
di $z$ e si denota con $y=\Im z$
\mymargin{$\Im z$}%
\index{$\Im z$}
(osserviamo che la parte immaginaria di un numero complesso è un numero
reale, non immaginario). Dunque $z= \Re z + i \Im z$.

L'insieme $\CC$, per come
è stato costruito, è uno spazio vettoriale reale di dimensione $2$.
Abbiamo quindi già definite la \emph{addizione}%
\mymargin{addizione}%
\index{addizione}
\index{complessi!addizione}
tra elementi di $\CC$ e la moltiplicazione
tra elementi di $\CC$ ed elementi di $\RR$.
Se $a,b,c,d,t\in \RR$ si ha:
\begin{gather*}
 (a+ib) + (c+id) = (a+c) + i (b+d), \\
 t(a+ib) = ta + itb.
\end{gather*}

Vogliamo estendere la \emph{moltiplicazione}%
\mymargin{moltiplicazione}%
\index{moltiplicazione} a tutte le coppie di numeri complessi.
\index{complessi!moltiplicazione}
Imponendo (arbitrariamente) che valga $i\cdot i = -1$ e che rimanga
valida la proprietà distributiva, si ottiene
questa definizione:
\[
   (a+ib) \cdot (c+id) = (ac-bd) + i(ad+bc).
\]

Si può verificare che questa moltiplicazione estende quella ``scalare'' definita
in precedenza.
E' anche facile verificare che addizione e moltiplicazione soddisfano
le proprietà commutativa associativa e distributiva,
che $0$ è elemento neutro per la addizione, che $1$ è elemento neutro
della moltiplicazione.
Si osservi che se $z=x+iy$ non è nullo, allora
\[
  (x+iy) \cdot \frac{x-iy}{x^2+y^2} = 1.
\]
Significa che ogni $z\neq 0$ ammette inverso moltiplicativo e quindi $\CC$,
in definitiva,
risulta essere un campo.

Osserviamo che su $\CC$ non si definisce una relazione d'ordine perché
in effetti non è possibile definire un ordine ``compatibile'' con le operazioni
appena definite.%
\mynote{%
Se $\CC$ fosse un campo ordinato per assurdo
si dovrebbe avere,
che $z^2\ge 0$ per ogni $z\in \CC$ (questo è vero in tutti i campi ordinati). 
Ma
allora $-1 =i^2 \ge 0$ cioè $1\le 0$ che è in contraddizione
con la proprietà $0<1$ valida in ogni campo ordinato.
} % marginnote

Su $\CC$ definiamo delle ulteriori operazioni.
Il \emph{coniugato}%
\mymargin{coniugato}%
\index{coniugato}%
\index{complessi!coniugio}
di un numero complesso $z=x+iy$ è il numero
$\bar z = x - iy$. Geometricamente l'operazione di coniugio è una simmetria
rispetto alla retta reale. I numeri reali sono in effetti punti fissi del
coniugio (il coniugato di un numero reale è il numero stesso).
E' un semplice esercizio verificare che il coniugio ``attraversa''
somma e prodotto:
\[
\overline{z+w} = \bar z + \bar w, \qquad
\overline{z\cdot w} = \bar z \cdot \bar w.
\]
Ovviamente risulta $\overline {\bar z} = z$.
E' anche utile osservare che si ha:
\begin{equation}\label{eq:re_im}
  \Re z = \frac{z+\bar z}{2}, \qquad
  \Im z = \frac{z-\bar z}{2i}
\end{equation}
e
\[
z \cdot \bar z = (x+iy)(x-iy) = x^2-i^2y^2 = x^2+y^2.
\]

Possiamo allora definire il
\emph{modulo}%
\mymargin{modulo}%
\index{modulo}%
\index{complessi!modulo}
 di un numero complesso $z=x+iy$
come il numero reale
\[
\abs{z} = \sqrt{z\cdot\bar z} = \sqrt{x^2+y^2}.
\]
Geometricamente tale quantità rappresenta la distanza del punto $z$
dal punto $0$ e quindi la distanza tra due numeri complessi $z$ e
$w$ si potrà rappresentare con $\abs{z-w}$.

Osserviamo che se $z = x \in \RR \subset \CC$ il modulo di $z$ coincide
con il valore assoluto: $\abs{z} = \sqrt{x^2} = \abs{x}$ e per questo
motivo non distinguiamo, nelle notazioni, il modulo dal valore assoluto.
Più in generale risulta per ogni $z\in \CC$ (la verifica è immediata):
\[
  \abs{\Re z} \le \abs{z}, \qquad
  \abs{\Im z} \le \abs{z}.
\]

Possiamo a questo punto trovare una utile formula per calcolare
il reciproco di un numero complesso. Essendo infatti
$z\cdot \bar z = \abs{z}^2$ si osserva che
\[
  \frac{1}{z}
  = \frac{\bar z}{ \bar z \cdot z}
  = \frac{\bar z}{\abs{z}^2}.
\]

\begin{theorem}
Il modulo di un numero complesso soddisfa (come il valore assoluto)
le seguenti proprietà
\begin{enumerate}
\item $\big\lvert\abs{z}\big\rvert = \abs{z}$,
\item $\abs{-z} = \abs{z}$ = $\abs{\bar z}$,
\item $\abs{z\cdot w} = \abs{z}\cdot\abs{w}$.
\item $\abs{z+w} \le \abs{z}+\abs{w}$ (convessità),
\item $\abs{z-w} \le \abs{z-v} + \abs{v-w}$ (disuguaglianza triangolare),
\end{enumerate}
\end{theorem}
%
\begin{proof}
La prima proprietà è ovvia in quanto il valore assoluto di un numero reale
non negativo è il numero stesso.

La seconda proprietà viene immediatamente dalla definizione.

Per la terza proprietà sia $z=x+iy$, $w=a+ib$.
Allora:
\begin{align*}
\abs{z\cdot w}
&= \abs{(x+iy)\cdot(a+ib)}
=\abs{xa - y b+ i(xb + ay)} \\
&= \sqrt{(xa-yb)^2 + (xb+ay)^2}\\
&=\sqrt{x^2 a^2 + y^2b^2 - 2xayb + x^2b^2+a^2y^2+2xbay} \\
&=\sqrt{x^2 a^2 + y^2 b^2 + x^2 b^2 + a^2 y^2}\\
&=\sqrt{x^2(a^2+b^2) + y^2(a^2+b^2)}\\
&=\sqrt{(x^2+y^2)(a^2+b^2)}
=\abs{x+iy} \cdot \abs{a+ib}\\
&=\abs{z}\cdot\abs{w}.
\end{align*}

Per la quarta disuguaglianza osserviamo che si ha
\[
  \abs{z+w}^2 = (z+w)\cdot(\bar z + \bar w)
  = \abs{z}^2 + \abs{w}^2 + z\cdot \bar w + \bar z \cdot w
\]
e visto che
\[
  z\cdot \bar w + \bar z \cdot w
  = z \cdot \bar w + \overline{z \cdot \bar w}
  = 2 \Re(z\bar w)
  \le 2 \abs {z\bar w}
  = 2 \abs{z}\cdot\abs{\bar w}
  = 2 \abs{z}\cdot\abs{w}
\]
otteniamo
\[
 \abs{z+w}^2 \le \abs{z}^2+\abs{w}^2 + 2 \abs{z}\cdot\abs{w}
 =\enclose{\abs z + \abs w}^2
\]
che è equivalente alla disuguaglianza di convessità.

La disuguaglianza triangolare è conseguenza immediata della convessità, infatti
\[
  \abs{z-w} = \abs{(z-v) + (v-w)}
  \le \abs{z-v} + \abs{v-w}.
\]
\end{proof}

\begin{figure}
  \begin{center}
    \begin{tikzpicture}[x=0.5cm,y=0.5cm]
    	\draw[->] (-1,0) -- (9,0);
      \draw[->] (0,-1) -- (0,8);
      %
      \draw[dotted] (0,0) -- ({sqrt(45)},{sqrt(20)}) -- ({sqrt(45)},0);
      \draw[fill] ({sqrt(45)},{sqrt(20)}) node[right] {$w$} circle [radius=0.1];
      %
      \draw[thick] (0,0) -- (6,0);
      \draw[thick] (0,0) -- (6,3);
      \draw[thick] (0,0) -- (4,7);
      \draw[thick] (6,0) -- (6,3);
      \draw[thick] (6,3) -- (4,7);
      %
      \draw[dashed] (4,0) -- (4,7);
      \draw[dashed] (4,3) -- (6,3);
      %
      \draw (1,0) arc (0:{atan(1/2)}:1);
      \draw (6,3)+(-1,0) arc (180:{180+atan(1/2)}:1);
      \draw (4,7)+(0,-1) arc (-90:{-90+atan(1/2)}:1);
      %
      \draw[fill] (6,3) node[right] {$z$} circle [radius=0.1];
      \draw[fill] (4,7) node[above] {$u$} circle [radius=0.1];
      %
      \node[below] at (3,0) {$a$};
      \node[left] at (6,1.5) {$b$};
      \node[above] at (3,1.5) {$\alpha$};
      \node[right] at (5,5) {$\beta$};
      \node[above] at (5,3) {$s$};
      \node[left] at (4,4.5) {$t$};
      \node[above] at (8.5,0) {$x$};
      \node[left] at (0,7.5) {$y$};
      \node[below left] at (0,0) {$0$};
    \end{tikzpicture}
  \end{center}
  \caption{Consideriamo i numeri complessi $z=a+ib$ e $w=\alpha+i\beta$
  e supponiamo che sia $\alpha^2 = a^2+b^2$.
  Si consideri il punto $u$ che si ottiene ruotando il punto $w$ dell'angolo
  individuato dal punto $z$. Si avrà allora $u=a-s + i(b+t)$ dove $s$ e $t$
  sono i cateti del triangolo rettangolo con ipotenusa $\beta$.
  Grazie alle proprietà di similitudine dei triangoli si ha
  $\frac{s}{\beta} = \frac{b}{\alpha}$ e $\frac{t}{\beta} = \frac{a}{\alpha}$
  da cui si ottiene quindi $u = a-\frac{b\beta}{\alpha}+i(b+\frac{a\beta}{\alpha})$
  ovvero $\alpha u = (a\alpha - b \beta) + i (b\alpha + a \beta) = z\cdot w$.
  Significa che il numero complesso $z\cdot w$ si trova sulla semiretta
  che individua un angolo che è la somma degli angoli individuati
  dai numeri complessi $z$ e $w$.
  }
  \label{fig:prodotto_complesso}
\end{figure}

Possiamo ora dare una interpretazione geometrica del prodotto $z\cdot w$
tra due numeri complessi. In primo luogo sappiamo che $\abs{z\cdot w} = \abs{z} \cdot \abs{w}$ e dunque il punto del piano che rappresenta il prodotto $z\cdot w$ si trova ad una distanza dall'origine che è pari al prodotto delle distanze
dei punti $z$ e $w$. Inoltre l'angolo individuato da $z\cdot w$ rispetto
all'asse delle $x$ positive risulta uguale alla somma
degli angoli individuati dai punti $z$ e $w$ come mostrato in figura~\ref{fig:prodotto_complesso}.

Anche il piano dei numeri complessi può essere esteso aggiungendoci
un punto all'\emph{infinito}%
\mymargin{infinito}%
\index{infinito}.
A differenza dei reali, su cui era presente un ordinamento che era utile conservare,
nel caso dei numeri complessi è più usuale utilizzare un unico punto infinito
che si denota con \emph{$\infty$}%
\mymargin{$\infty$}%
\index{$\infty$}.
Definiamo l'insieme dei complessi estesi $\bar \CC$ come
\[
\bar \CC = \CC \cup \ENCLOSE{\infty}.
\]
Definiamo
\begin{align*}
  z + \infty &= \infty \qquad \forall z \in \CC\\
  z - \infty &= \infty \qquad \forall z \in \CC\\
   z\cdot \infty &= \infty \qquad \forall z \in \bar\CC\setminus\ENCLOSE{0} \\
   z / \infty &= 0 \qquad \forall z \in \CC \\
   z / 0 &= \infty \qquad \forall z \in \bar \CC \setminus\ENCLOSE{0}\\
   \bar \infty &= \infty \\
   \abs{\infty} &= +\infty \in \bar \RR.
\end{align*}
Si noti che abbiamo definito la divisione per zero di numeri complessi
(e quindi anche reali) diversi da zero. Il risultato è $\infty$ e quindi
rimane confermato che la divisione per zero non è una operazione valida
se vogliamo un risultato finito.
Una quantità $z\in \bar \CC$ sarà detta \emph{finita} se $z\in \CC$.

\begin{example}
  La funzione $f\colon \bar \CC \to \bar \CC$ 
  definita da 
  \[
  f(z) = \frac{1}{z}
  \]
  è una funzione bigettiva di $\bar \CC$ in sé.
  Dal punto di vista geometrico il coniugato di tale funzione
  ovvero la funzione $z\mapsto \frac 1 {\bar z}$ 
  è l'inversione circolare rispetto al cerchio unitario di $\CC$:
  i punti sulla circonferenza unitaria vengono lasciati fissi,
  i punti all'interno vengono mandati all'esterno rimanendo sullo 
  stesso raggio uscente dall'origine e invertendo il proprio modulo.
  I punti $0$ e $\infty$ si scambiano.
\end{example}

%% % ancora non abbiamo definito il concetto di funzione continua
%% Per le funzioni di variabile complessa e/o a valori complessi 
%% si applica la stessa definizione~\ref{def:continua} di continuità 
%% che abbiamo dato per le funzioni reali utilizzando il modulo 
%% complesso al posto del valore assoluto.
%% \index{continuità!campo complesso}%
%% \index{funzione!continua!complessa}%

\begin{exercise}[vertici di un triangolo equilatero]
Si risolva l'equazione 
\[ 
 z^3 - 1 = 0
\]
nel campo complesso.
\end{exercise}
%
\begin{proof}[Svolgimento.]
Ricordiamo il prodotto notevole:
\[
  z^3 - 1 = (z-1)(z^2+z+1).
\]
Dunque $z=1$ è una soluzione e le altre soluzioni devono risolvere 
l'equazione $z^2+z+1=0$. 
Certamente $z=0$ non è soluzione e dunque possiamo dividere per $z$ 
e ottenere:
\[
  z + 1 + \frac 1 z = 0.
\]
Osserviamo ora che se $z$ è soluzione si ha $1=z^3$
e quindi: $1 = \abs{z^3}= \abs{z}^3$ da cui $\abs z = 1$.
Ma allora $z\cdot \bar z = \abs{z}^2 = 1$ ovvero $\frac 1 z = \bar z$.
Dunque si ha 
\[
    z + 1 + \bar z = 0.
\]
Ma se $z=x+iy$ con $x,y\in \RR$ allora $z+\bar z = 2x$
e quindi 
\[
    2x + 1 = 0 
\]
da cui $x=-\frac 1 2$. Essendo inoltre $x^2+y^2=\abs{z}^2=1$ si ottiene
$y^2 = 1-x^2 = \frac 3 4$ da cui $y=\pm \frac{\sqrt 3}{2}$.

L'equazione data ha quindi $3$ soluzioni:
\[
z_0 = 1, \qquad 
z_{1,2} = -\frac 1 2 \pm i \frac{\sqrt 3} 2.
\]

Questi tre punti, se disegnati sul piano di Gauss, si trovano 
ai vertici di un triangolo equilatero iscritto nella circonferenza unitaria.
Infatti l'interpretazione geometrica del prodotto di numeri complessi ci dice 
che il punto $z_1$ individua sul piano di Gauss un angolo pari 
ad un terzo dell'angolo giro. Inoltre si ha $z_2 = z_1^2$ e dunque 
$z_2$ corrisponde a $\frac 2 3$ di angolo giro e $z_0=z_1^3 = 1$ rappresenta 
l'angolo giro (o l'angolo nullo).
\end{proof}

\begin{exercise}[pentagono regolare]
Si determini la massima distanza tra due soluzioni 
dell'equazione $z^5=1$. 
\end{exercise}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{funzioni trigonometriche}
\label{sec:funzioni_trigonometriche}%
\label{sec:avvolgimento}%

Consideriamo la circonferenza unitaria 
\[
  U = \ENCLOSE{z\in \CC\colon \abs{z} = 1}.
\]
Ogni punto $z\in U$ individua un angolo geometrico con l'asse reale.
Il nostro obiettivo è ora quello di definire la misura di un angolo.
Il punto $z=1$ individuerà un angolo di misura nulla e 
ruotando $z$ in senso antiorario vogliamo ottenere angoli 
di misura crescente in modo che l'angolo che si ottiene 
giustapponendo uno di seguito all'altro gli angoli individuati 
dal punto $z$ e dal punto $w$ abbia misura pari alla somma delle misure 
degli angoli individuati da $z$ e da $w$.

Scegliamo arbitrariamente di dare una misura $\tau>0$ all'angolo giro.
L'idea intuitiva è quella di \emph{arrotolare} la retta $\RR$ come un filo 
attorno alla circonferenza $U\subset \CC$ 
mandando il punto $0\in \RR$ sul punto $1\in \CC$,
e poi il punto $\frac \tau 4$ su $i$, il punto $\frac \tau 2$ su $-1$,
il punto $3\frac \tau 4$ su $-i$ e il punto $\tau$ di nuovo su $1$.
Punti intermedi andranno su punti intermedi di $U$ in modo da avere 
l'additività degli angoli: la misura della somma di due angoli dovrà 
essere la somma delle misure.

L'insieme $U$ eredita la struttura di gruppo moltiplicativo di $\CC$: 
se $z,w\in U$ 
allora $z\cdot w \in U$ in quanto $\abs{z\cdot w} = \abs{z}\cdot \abs{w} = 1$
essendo $\abs{z}=\abs{w}=1$.
Ricordiamo inoltre che la moltiplicazione di numeri complessi unitari 
corrisponde alla somma dei loro angoli geometrici.
Dunque la funzione $\phi\colon \RR \to U$ che misura gli angoli, 
dovrà avere la proprietà di \emph{omomorfismo}:
\begin{equation}\label{eq:4012387}
  \phi(x+y) = \phi(x)\cdot \phi(y).
\end{equation}
Purtroppo sul gruppo $U$ non possiamo mettere un ordinamento e 
dunque non possiamo utilizzare il teorema~\ref{th:isomorfismo} 
di isomorfismo 
come abbiamo fatto per definire la funzione esponenziale.
L'idea sarà invece quella di definire la funzione $\phi$ 
bisezionando l'angolo giro, quindi estendendola ai multipli 
degli angoli bisecati con \eqref{eq:4012387}
e, infine, estendendola per monotonia a tutti gli angoli.

Per fissare le idee scegliamo $\tau=4$ cioè decidiamo di voler 
dare misura $1$ all'angolo retto e quindi misura $4$ all'angolo 
giro.
Vogliamo innanzitutto definire $\phi\colon[0,1]\to U$ la funzione
che associa alla misura $t\in[0,1]$ un angolo rappresentato da 
un numero complesso unitario $z\in U$ con $\Re z\ge 0$ e $\Im z\ge 0$
(nel primo quadrante del piano complesso).
Vorremo definire $\phi$ in modo che sia $\phi(0)=1$, $\phi(1)=i$,
$\phi(1/2)=\frac{1+i}{\sqrt 2}$ (angolo di $45^\circ$) e così via.

Per fare questo dobbiamo innanzitutto bisecare un generico angolo 
$u\in U$.
Se $u\in U$ l'angolo metà è rappresentato da un numero 
complesso $z\in U$ tale che $z^2=u$. 
L'equazione $z^2=u$ ha in generale due soluzioni, ma se $u$ 
è nel primo quadrante $Q=\ENCLOSE{z\in U\colon \Re z\ge 0, \Im z\ge 0}$
ci sarà una sola soluzione nel primo quadrante.
Posto $u=a+ib$ e $z=x+iy$ l'equazione $z^2=u$ si scrive:
\[
  (x^2-y^2) + i(2xy) = a+ib
\]
da cui $a=x^2-y^2$. Visto che $x^2+y^2=1$ (essendo $u\in U$)
si ha $a=2x^2-1$ da cui $x=\pm\sqrt{\frac{1+a}{2}}$.
La soluzione in $Q$ dovrà avere $x\ge 0$ e dunque segliamo 
il segno positivo:
\[
  x = \sqrt{\frac{1+a}{2}}, \qquad 
  y = \sqrt{1-x^2} = \sqrt{\frac{1-a}{2}}.
\]
Denotiamo con $z=\sqrt u$ la soluzione con parte reale positiva 
dell'equazione $z^2=u$ che abbiamo appena calcolato.
Possiamo allora definire la successione degli angoli dimezzati:
\[
\begin{cases}
u_0 = i\\
u_{n+1} = \sqrt{u_n}.
\end{cases}
\]
Questi angoli sono uno la metà dell'altro $u_{n+1}^2 = u_n$.
Induttivamente si dimostra facilmente che vale $u_{n+k}^{2^k} = u_n$
per ogni $n,k\in \NN$.
Avendo posto $\tau=4$ dovrà essere $\phi(1)=i$ e quindi 
$\phi(1/2^n)=u_n$ affinchè sia rispettata l'equazione \eqref{eq:4012387}.
Inoltre dovrà essere
\begin{equation}
\phi\enclose{\frac{p}{2^n}} = (u_n)^p,
\qquad n\in \NN, p\in \NN, p\le 2^n.
\end{equation}
Questa definizione è ben posta in quanto se $\frac{p}{2^n}=\frac{q}{2^{n+k}}$
si ha $p=2^k q$ e quindi $(u_n)^p = (u_n)^{2^k q} = u_{n+k}^q$.

Posto 
\[
B = \ENCLOSE{\frac{p}{2^n}\colon n\in \NN, p\in \NN, p\le 2^n} \subset [0,1]
\]
abbiamo definito $\phi\colon B\to U$ in modo che \eqref{eq:4012387}
sia soddisfatta. 
Inoltre la definizione di $\phi$ è unica se imponiamo  
$\phi(1)=i$.
Si tratta ora di estendere la definizione di $\phi$ a tutto 
l'intervallo $[0,1]$. 
Possiamo riutilizzare il teorema~\ref{th:estensione_monotona} di 
estensione monotona.

Innanzitutto vogliamo dimostrare che $\Re \phi\colon B\to \RR$ 
e $\Im \phi\colon B\to \RR$ sono funzioni monotone.
In particolare vogliamo dimostrare che se $t\ge s$ allora 
$\Re \phi(t) \le \Re \phi(s)$.
Osserviamo che si ha $\phi(t) = \phi(s)\cdot \phi(t-s)$, 
quindi basta capire come si comporta la moltiplicazione per un 
numero complesso del primo quadrante.
Se $\phi(s)=z=a+ib$ e $\phi(t-s)=w=x+iy$ si ha
$\Re (zw) = ax-by$. Banalmente se $a,b,x,y\in[0,1]$ si ha 
$ax-by \le a$. 
Dunque $\Re \phi(t)\le \Re \phi(s)$ come volevamo dimostrare.
Visto che $\Im \phi(t) = \sqrt{1-\Re \phi(t)^2}$ si ha
anche $\Im \phi(t) \le \Im \phi(s)$.

Questa proprietà ci dice in particolare che $\phi$ assume valori 
nel primo quadrante, in quanto sapendo che agli estremi 
$\phi(0) = 1$ 
e $\phi(1)=i$ ogni altro valore deve avere parte reale 
e parte immaginaria compresa tra $0$ e $1$.

Possiamo allora considerare la funzione 
$f=\Im \phi$, $f\colon B\subset [0,1]\to[0,1]$
a cui applicare il teorema~\ref{th:estensione_monotona}.
Dobbiamo verificare che $f(B)$ è denso in $J=[0,1]$. 
Dati $y_1,y_2\in [0,1]$ con $y_1<y_2$ dobbiamo mosrare che esiste $t\in B$ tale 
che $y_1 < \Im phi(t) < y_2$.
Sarà $y_1=\Im z_1$ e $y_2=\Im z_2$ con $z_1,z_2\in U$.
L'idea è quella di trovare $n$ abbastanza grande in modo che uno dei punti 
$u_n^p$ stia tra $z_1$ e $z_2$. 
L'angolo differenza tra $z_1$ e $z_2$ è rappresentato da 
$w=\frac{z_2}{z_1}$. 
Siccome $u_n\to 1$ per $n\to +\infty$ 
esisterà $n$ tale che $\abs{u_n-1}<y_2-y_1$.
La successione $\Im u_n^p$, al crescere di $p\in \NN$ è crescente 
(come abbiamo già osservato) e varia tra $0$ (quando $p=0$) e $1$ 
(quando $p=2^n$). 
Si ha
\[
 \Im u_n^{p+1} - \Im u_n^p = \Im (u_n^{p+1}-u_n^p) 
 \le \abs{u_n^{p+1}-u_n^p} < y_2-y_1.
\]
Dunque dovrà esistere $p\in \NN$, $p\le 2^n$ tale che 
$y_1 < \Im u_n^p <y_2$. 
Visto che $\Im u_n^p = f(p/2^n)$ abbiamo dimostrato 
che $f(B)$ è denso in $[0,1]$.
Per il teorema~\ref{th:estensione_monotona} possiamo allora estendere 
$f$ a tutto $[0,1]$ preservando la monotonia.
Ma allora possiamo estendere $\phi$ a tutto $[0,1]$ 
ponendo $\phi(t) = \sqrt{1-f^2(t)} + i f(t)$. 
In questo modo $\Im \phi = f$ è monotona crescente mentre 
$\Re \phi=\sqrt{1-f^2}$ risulta decrescente.

Vogliamo ora verificare che la proprietà di omomorfismo 
\eqref{eq:4012387} è verificata
ora per ogni $t\in [0,1]$.
Prendiamo dunque $s,t\in[0,1]$ tali che anche $s+t\in [0,1]$
e puntiamo a dimostrare che per ogni $\eps>0$ 
si ha:
\begin{equation}\label{eq:4438844}
  \Im(\phi(s+t)- \phi(s)\phi(t)) < 4\eps,
  \qquad
  \Re(\phi(s+t)-\phi(s)\phi(t)) < 4\eps.
\end{equation}
Questo direbbe che $\phi(s+t)=\phi(s)\phi(t)$.

Per dimostrare~\eqref{eq:4438844} consideriamo 
$s_1,s_2,t_1,t_2\in B$ tali che $s_1<s<s_2$, 
$t_1<t<t_2$
e $0<\Im \phi(s_2)-\Im \phi(s_1)<\eps$, $0<\Im \phi(t_2)-\Im \phi(t_1)<\eps$,
  $0<\Re \phi(s_1)-\Re \phi(s_2)<\eps$, $0<\Re \phi(t_1)-\Re \phi(t_2)<\eps$.
Questo si può fare perché abbiamo visto che $\Im  \phi$ è crescente 
e $\Im \phi(B)$ è denso in $[0,1]$.
Analogamente si verifica che $\Re \phi$ è decrescente e
e anche $\Re \phi(B)$ è denso in $[0,1]$.
Si ha allora:
\[
\Im \phi(s+t) - \Im (\phi(s)\phi(t))
= \Im \phi(s+t) - \Re \phi(s)\Im \phi(t) - \Re \phi(t)\Im \phi(s)
\]
e usando la monotonia di $\Im \phi$ e $\Re \phi$ si ottiene:
\begin{align*}
\Im \phi(s+t) &- \Im (\phi(s)\phi(t))
\le \Im \phi(s_2+t_2) - \Re \phi(s_2)\Im \phi(t_1) - \Re \phi(t_2)\Im \phi(s_1)\\ 
&= \Im (\phi(s_2)\phi(t_2)) - \Re \phi(s_2)\Im \phi(t_1) - \Re \phi(t_2)\Im \phi(s_1)\\ 
&= \Re\phi(s_2)(\Im\phi(t_2) - \Im \phi(t_1))+\Re\phi(t_2)(\Im\phi(s_2) - \Im \phi(s_1))\\
&< 2\eps.
\end{align*}
Analogamente si ottiene:
\begin{align*}
\Im \phi(s+t) - \Im (\phi(s)\phi(t))
&\ge -2\eps,\\
\Re \phi(s+t) - \Re (\phi(s)\phi(t))
&\le 4\eps,\\
\Re \phi(s+t) - \Re (\phi(s)\phi(t))
&\ge -4\eps.
\end{align*}
Nelle disuguaglianze con la parte reale si ottengono 
termini del tipo $a_1 b_1 - a_2 b_2$ 
ai quali bisogna aggiungere e togliere $a_1 b_2$ 
per ottenere la forma $a_1(b_1-b_2) + (a_1-a_2)b_2$: 
per questo motivo si ottiene $4\eps$ invece che $2\eps$.

**** WIP ****

Si tratta ora di estendere $\phi$ a tutto $\RR$.


\begin{theorem}[definizione funzioni trigonometriche]%
\label{def:sin_cos}%
\label{th:proprieta_trigonometriche}%
Per ogni $\tau>0$ esistono due uniche funzioni $\sin,\cos\colon \RR\to \RR$ 
tali che per ogni $x,y\in \RR$ valgono le seguenti proprietà:
\mynote{Quando avremo definito $\pi$ otterremo 
le usuali funzioni trigonometriche scegliendo $\tau=2\pi$. 
Ma altre scelte di $\tau$ non sono inusuali. 
Ad esempio con $\tau=360$ otteniamo le funzioni trigonometriche 
con gli angoli misurati in gradi. 
Sulle calcolatrici scientifiche 
c'è usualmente l'opzione \texttt{RAD} (radiante) che pone $\tau=2\pi$ e l'opzione 
\texttt{DEG} (\emph{degree} ovvero grado) che pone $\tau=360$.
Si può anche trovare l'opzione \texttt{GRAD} (\emph{gradian} o grado centesimale)
che corrisponde alla scelta $\tau=400$ utilizzata a volte in topografia.}%
\begin{enumerate}
  \item $\sin$ e $\cos$ sono $\tau$-periodiche;
  \item $\sin^2 x + \cos^2 x =1$;
  \item $\sin(x+y) = \sin x \cdot \cos y + \cos x\cdot \sin y$;
  \item $\cos(x+y) = \cos x \cdot \cos y - \sin x\cdot \sin y$;
  \item $\sin(-x) = -\sin(x)$ ($\sin$ è dispari), $\cos(-x) = \cos(x)$ ($\cos$ è pari);
  \item $\sin \colon \closeinterval{-\frac \tau 4}{\frac \tau 4} \to [-1,1]$
  è strettamente crescente e bigettiva;
  \item $\cos \colon \closeinterval{0}{\frac \tau 2} \to [-1,1]$.
  è strettamente decrescente e bigettiva.
\end{enumerate}
\end{theorem}
%
\begin{proof}
Consideriamo la funzione $\phi\colon \RR \to U\subset \CC$ 
definita nel teorema precedente (\ref{th:omomorfismo_U}) 
e definiamo $\cos x = \Re \phi(x)$, $\sin x = \Im \phi(x)$
cosicché $\phi(x) = \cos(x) + i \sin (x)$.
Chiaramente $\cos$ e $\sin$ hanno periodo $\tau$ in quanto 
$\phi$ ha periodo $\tau$.

Visto che $\phi(x)\in U$ si ha $\abs{\phi(x)}^2=1$.
Ma allora vale il punto 2:
\[
 1 = \abs{\phi(x)}^2 
 = \abs{\cos x + i\sin x}^2 
 = \cos^2 x + \sin^2 x.
\]

La proprietà di omomorfismo 
$\phi(x+y)=\phi(x)\cdot \phi(y)$ diventa 
\begin{align*}
  \cos(x+y) + i \sin(x+y)
  &=(\cos x + i \sin x)\cdot(\cos y + i \sin y) \\
  &= 
  \Enclose{\cos x\cdot \cos y - \sin x \sin y}
  + i\Enclose{\sin x\cdot \cos y + \cos x\cdot \sin y}
\end{align*}
da cui, eguagliando parte reale e parte immaginaria, 
si ottengono le formule di addizione dei punti 3 e 4.

Visto che $\abs{\phi(x)}=1$ sappiamo che 
$1/\phi(x) = \overline{\phi(x)}$. 
Ma, per le proprietà di omomorfismo, $1/\phi(x)=\phi(-x)$ e quindi 
\[
\cos (-x) + i \sin(-x) 
= \phi(-x) 
= \overline{\phi(x)}
= \cos(x) - i \sin(x)
\]
da cui, uguagliando parte reale e parte immaginaria, 
si ottiene il punto 5.

Visto che $\Im \phi\colon[-\tau/4,\tau/4]\to[0,1]$ è strettamente crescente e bigettiva
deduciamo che anche $\sin\colon[-\tau/4,\tau/4]\to [0,1]$ lo è.
Ricordando che $\phi(\tau/4)=i$, 
si ha $\cos(\tau/4)=0$, $\sin(\tau/4)=1$ e grazie alle formule 
di addizione troviamo $\sin(\tau/4-x)=\cos(x)$.
Dunque se $\sin$ è strettamente crescente sull'intervallo 
$[-\tau/4,\tau/4]$ scopriamo che $\cos$ è strettamente 
decrescente sull'intervallo $[0,\tau/2]$
e su tale intervallo assume 
tutti i valori compresi tra $[-1,1]$.
\end{proof}

\begin{figure}
  \centering%
  \begin{tikzpicture}[scale=0.75]
  \draw[->] (-2,0) -- (10,0) node[right] {$x$};
  \draw[->] (0,-3) -- (0,3) node[above] {$y$};
  \foreach \x/\xtext in
    {{pi/2}/{\frac \tau 4}, {pi}/{\frac \tau 2},
     {2*pi}/{\tau}, {3*pi/2}/{\frac {3\tau} 4}, {-pi/2}/{-\frac {\tau}{4}}} {
    \draw[shift={(\x,0)},lightgray] (0,-3) -- (0,3);
    \draw[shift={(\x,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\xtext$};
  }
  \foreach \y in {1, -1} {
    \draw[shift={(0,\y)},lightgray] (-1,0) -- (11,0);
  }
  \draw (0,1) node [above right] {$1$};
  \draw (0,-1) node [right] {$-1$};
  \draw[domain=-2:10,smooth,variable=\x,blue,thick] plot ({\x},{cos(deg(\x))});
  \draw[domain=-2:10,smooth,variable=\x,red,thick] plot ({\x},{sin(deg(\x))});
  \draw (3.7,-1) node[blue,below] {$y=\cos x$};
  \draw (2,0.9)  node[red,above] {$y=\sin x$};
  \end{tikzpicture}
  \caption{%
  I grafici delle funzioni $\sin$, $\cos$ di 
  un generico periodo $\tau$.}
\end{figure}


\section{funzioni continue}
\label{sec:continuita}

Intuitivamente una funzione continua ha la proprietà
che se in un punto $x_0$ assume un valore $y_0=f(x_0)$ allora
in punti abbastanza vicini ad $x_0$ i valori assunti
non saranno molto diversi dal valore $y_0$.
Nella definizione seguente questo viene formalizzato:
fissato il punto $x_0$ e scelto un errore $\eps>0$
che siamo disposti a commettere sui valori della funzione
possiamo trovare un errore $\delta>0$ per cui nei punti
che differiscono da $x_0$ per meno di $\delta$ il valore
della funzione differisce da $y_0$ per meno di $\eps$.

Se $x$ e $y$ sono due punti di $\RR$ la loro distanza 
è data da $\abs{x-y}$. 
Una disuguaglianza del tipo $\abs{x-y}<r$ significa 
che il punto $x$ si trova nell'intervallo $(x-r,x+r)$.
Nel seguito ci concentreremo sulle funzioni con dominio 
e codominio nei numeri reali. 
Ma potremo osservare che molte delle definizioni e molti 
dei teoremi possono essere enunciati e dimostrati in maniera 
identica anche per le funzioni con dominio e codominio 
nei numeri complessi%
\footnote{Ci sono in realtà quattro casi rilevanti:
dominio e codominio reale, dominio e codominio complesso, 
dominio reale e codominio complesso, 
dominio complesso e codominio reale, cominio reale 
e codominio complesso. 
Per dire che il dominio è sottoinsieme dei numeri complessi 
diremo che la funzione $f$ è \emph{di variabile complessa},
mentre per dire che la funzione $f$ ha codominio nei numeri 
complessi diremo che $f$ è \emph{a valori complessi}
o più semplicemente che $f$ è complessa.
Il caso di funzioni complesse di variabile complessa 
è ovviamente il caso più generale. 
Ma a volte può essere utile restringersi alla variabile 
reale dove abbiamo la struttura lineare data dall'ordinamento.
Sempre per mantenere l'ordinamento il caso reale e complesso 
si distinguono anche per i punti all'infinito: nel caso reale 
ne introduciamo due, $+\infty$ e $-\infty$ mentre nel caso 
complesso si introduce un unico punto $\infty$.
} 
Ad una prima lettura si consiglia di trascurare 
il caso complesso.
Anche quando $x$ e $y$ sono punti di $\CC$ il modulo della 
differenza $\abs{x-y}$ rappresenta la distanza tra i due 
punti $x$ e $y$. 
Fissato $y\in \CC$ e $r>0$
\mynote{La condizione $r>0$ non ha senso se $r\in \CC$ 
quindi se si impone questa condizione è sottointeso 
che $r\in \RR$}
la condizione $\abs{x-y}<r$ identifica i punti $x$ 
che si trovano all'interno di un cerchio di raggio $r$
intorno a $y$.

\begin{definition}[funzione continua]
  \label{def:continua}%
  \index{funzione!continua}%
  \index{continuità}%
  Sia $f\colon A \subset \RR \to \RR$ 
  (oppure $f\colon A\subset \CC \to \CC$) una funzione. 
  Diremo che $f$ è \emph{continua nel punto}%
\mymargin{continua nel punto}%
\index{continuo!nel punto} $x_0\in A$ se
  \begin{equation}\label{eq:continuita}
  \forall \eps>0 \colon \exists \delta>0 \colon
  \forall x\in A\colon
  \abs{x-x_0} < \delta \implies \abs{f(x)-f(x_0)} < \eps.
  \end{equation}
  
  Diremo che $f$ è \emph{continua}%
\mymargin{continua}%
\index{continuo} se è continua in ogni punto $x_0 \in A$.
  \end{definition}
  
  %%%%%%%%%%%%%%%%%%%
  %%%%%%%%%%%%%%%%%%%
  %%%%%%%%%%%%%%%%%%%
  
  Attenzione: la funzione $f(x)=\frac{1}{x}$
  assume vicino a $x=0$ valori molto diversi tra loro (ad esempio $f(0.01)-f(-0.01)=200$)
  ma ciò non toglie che la funzione possa essere continua in quanto il punto
  $x=0$ non appartiene al dominio e quindi,
  in base alla definizione precedente, non ha senso e non ha importanza
  verificare se la funzione è continua in tale punto.
  
  \begin{theorem}[continuità del reciproco]
  \label{th:cont_reciproco}%
  La funzione $f\colon \RR\setminus\ENCLOSE{0}\to \RR$ definita
  da $f(x)=\frac 1 x$ è una funzione continua.
  \end{theorem}
  %
  \begin{proof}
  Siano $x,x_0\neq 0$.
  Se prendiamo $\delta < \frac{\abs{x_0}}2$
  e se $\abs{x-x_0} < \delta$ si avrà,
  per disuguaglianza triangolare inversa,
  $\abs{x} > \frac{\abs{x_0}}2$. Dunque
  \[
  \abs{\frac 1 x - \frac 1 {x_0}}
  = \frac{\abs{x-x_0}}{\abs{x\cdot x_0}}
  \le \frac{2\delta}{\abs{x_0}^2}.
  \]
  Si ottiene quindi la condizione $\abs{f(x)-f(x_0)}<\eps$
  se si sceglie $\delta$ in modo che
  risulti anche $\delta < \frac{\abs{x_0}^2\cdot \eps}{2}$.
  \end{proof}
  
  \begin{example}
  La \emph{funzione segno}%
\mymargin{funzione segno}%
\index{funzione!segno} $\sgn\colon \RR \to \RR$ definita da
  \[
    \sgn(x) = \begin{cases}
    1 & \text{se $x> 0$}\\
    0 & \text{se $x=0$}\\
    -1 & \text{se $x<0$}
    \end{cases}
  \]
  è un esempio di funzione non continua.
  \end{example}
  %
  \begin{proof}
  Verifichiamo che la funzione non è continua
  nel punto $x_0=0$.
  Infatti se $x\neq 0$ si ha
  \[
  \abs{\sgn(x)-\sgn(x_0)} = \abs{\sgn(x)} = 1
  \]
  e quindi se scegliamo $\eps<1$ non è possibile
  trovare $\delta>0$ per cui valga la condizione
  di continuità~\eqref{eq:continuita}
  nel punto $x_0=0$.
  \end{proof}
  
  \begin{exercise}
  Dimostrare che le funzioni $f(x) = x$ e $g(x)=\abs{x}$ sono continue.
  Dimostrare che le funzioni $h(x) = \lfloor x\rfloor$ e $k(x)=\lceil x \rceil$
  non sono continue (ma sono continue in ogni punto
  $x_0\in \RR \setminus \ZZ$).
  \end{exercise}
  
  \begin{definition}[operazioni sulle funzioni]
  Sia $A \subset \RR$ (oppure $A\subset \CC$) 
  e siano $f,g$ funzioni $A \to \RR$ (oppure $A\to \CC$).
  Possiamo allora definire
  $f+g$, $-f$, $f-g$, $f\cdot g$, $\abs f$, $f^n$ (con $n\in \NN$)
  e (se $g(x)\neq 0$ per ogni $x\in A$) anche $f/g$
  come funzioni $A \to \RR$ (o $A\to \CC$) mediante le seguenti ovvie
  definizioni
  \begin{gather*}
  (f+g)(x) = f(x) + g(x), \qquad
  (f-g)(x) = f(x) - g(x), \\
  (f\cdot g)(x) = f(x) \cdot g(x), \qquad
  (f/g)(x) = f(x) / g(x), \\
  (-f)(x) = -(f(x)), \qquad
  \abs f(x) = \abs{f(x)}, \qquad
  f^n(x) = (f(x))^n.
  \end{gather*}
  
  Se $f\colon A \to B$ e $g\colon B\to C$ ricordiamo
  che abbiamo definito la funzione composta
  $g\circ f\colon A \to C$:
  \[
    (g\circ f)(x) = g(f(x)).
  \]
  
  Se $c\in \RR$ (o $c\in \CC$) è un numero considereremo a volte 
  $c\colon A \to \RR$ come una funzione \emph{costante}.
  Risulta quindi inteso che $c\cdot f$ è la funzione definita da
  $(c\cdot f)(x) = c\cdot (f(x))$.
  La somma e il prodotto per costante rendono l'insieme $\RR^A$
  delle funzioni $A \to \RR$ uno spazio vettoriale sul campo $\RR$
  (lo stesso vale per $\CC^A$ con $A\subset \CC$)
  \end{definition}
  
  \begin{theorem}[composizione di funzioni continue]
  \label{th:continuita_composizione}%
  Se $f$ e $g$ sono funzioni (reali o complesse) definite e continue
  in uno stesso punto $x_0$ (reale o complesso)
  allora anche
  \[
    f+g, \qquad
    f\cdot g, \qquad
    f-g, \qquad
    \abs{f}, \qquad
    f^n\ \text{(con $n\in \NN$)}
  \]
  sono funzioni definite e continue nel punto $x_0$.
  Se inoltre $g(x_0)\neq 0$ anche la funzione
  $f/g$
  è definita e continua nel punto $x_0$.
  
  Se $f\colon A\subset \RR \to \RR$ è una funzione continua
  nel punto $x_0\in A$ e
  $g\colon B\subset \RR \to \RR$ è una funzione
  continua nel punto $y_0=f(x_0)\in B$ allora la funzione $g\circ f$
  definita in $f^{-1}(B)$ è continua nel punto $x_0$
  (lo stesso vale sostituendo $\CC$ ad $\RR$)
  \end{theorem}
  %
  \begin{proof}
  Mostriamo prima di tutto la continuità
  della composizione $g\circ f$.
  Per la continuità di $f$ in $x_0$ e di $g$ in $y_0=f(x_0)$
  si ha che per ogni $\eps>0$ esiste un $\gamma>0$
  e per ogni $\gamma>0$ esiste un $\delta>0$ per cui
  \begin{align*}
   \abs{x-x_0}< \delta &\implies \abs{f(x)-f(x_0)}<\gamma,\\
   \abs{y-y_0}< \gamma & \implies \abs{g(y)-g(y_0)}<\eps
  \end{align*}
  da cui
  \[
  \abs{x-x_0}< \delta
  \implies \abs{f(x)-f(x_0)}< \gamma
  \implies \abs{g(f(x))-g(f(x_0))} < \eps
  \]
  che non è altro che la condizione di
  continuità~\eqref{eq:continuita} per $g\circ f$.
  
  Se $f$ e $g$ sono continue nel punto $x_0$
  allora per ogni $\eps'>0$ esistono $\delta_1$
  e $\delta_2$ tali che
  \begin{align*}
   \abs{x-x_0} < \delta_1 &\implies \abs{f(x)-f(x_0)} < \eps',
   \\
   \abs{x-x_0} < \delta_2 &\implies \abs{g(x)-g(x_0)} < \eps'.
  \end{align*}
  In particolare scegliendo $\delta = \min\ENCLOSE{\delta_1,\delta_2}$
  se $\abs{x-x_0} < \delta$ valgono contemporaneamente
  entrambe le stime:
  \[
   \abs{f(x)-f(x_0)}< \eps', \qquad
   \abs{g(x)-g(x_0)}< \eps'.
  \]
  
  Dunque per la somma osserviamo che se $\abs{x-x_0}<\delta$
  si ha
  \begin{align*}
   \abs{(f+g)(x) - (f+g)(x_0)}
    &= \abs{f(x)+g(x)-f(x_0)-g(x_0)}\\
    &\le \abs{f(x)-f(x_0)} + \abs{g(x)-g(x_0)}
    \le 2 \eps'.
  \end{align*}
  Dato $\eps>0$ basterà quindi scegliere $\eps' = \eps / 2$
  e $\delta$ come sopra per ottenere la condizione di continuità.
  
  Per il prodotto si ha
  \begin{align*}
    \MoveEqLeft \abs{f(x)g(x)-f(x_0)g(x_0)}\\
    &= \abs{f(x)g(x) - f(x_0)g(x) + f(x_0)g(x) - f(x_0)g(x_0)}\\
    &\le \abs{f(x)-f(x_0)}\cdot\abs{g(x)} + \abs{f(x_0)}\cdot \abs{g(x)-g(x_0)} \\
    &\le \eps' \abs{g(x)} + \abs{f(x_0)} \eps'.
  \end{align*}
  Osserviamo ora che $\abs{g(x)}\le \abs{g(x)-g(x_0)} + \abs{g(x_0)}$
  e quindi $\abs{g(x)}\le \abs{g(x_0)}+\eps'$ da cui:
  \begin{align*}
    \abs{f(x)g(x)-f(x_0)g(x_0)}
    &\le \eps' \enclose{\abs{g(x_0)}+\eps'} + \abs{f(x_0)} \eps' \\
    &= \eps' \cdot(\abs{f(x_0)} + \abs{g(x_0)} + \eps').
  \end{align*}
  Possiamo facilmente rendere questa quantità inferiore a
  qualunque $\eps>0$: basterà prendere $\eps'<1$ e
  \[
    \eps' < \frac{\eps}{\abs{f(x_0)} + \abs{g(x_0)} + 1}.
  \]
  
  La funzione $f^n$ è continua per induzione su $n$
  in quanto prodotto di funzioni
  continue: $f^{n+1} = f^{n} \cdot f$.
  
  Abbiamo già visto che la funzione $h(x) = \frac{1}{x}$ è continua,
  dunque se $g$ è continua anche la funzione $\frac{1}{g(x)} = h\circ g$
  è continua essendo composizione di funzioni continue. 
  Di conseguenza anche la funzione $\frac{f}{g} = f \cdot \frac{1}{g}$
  è continua, essendo il prodotto di funzioni continue.
  
  Analogamente la funzione $f-g$ è la somma di $f$ con $-g$ e
  la funzione $-g$ è la composizione di $g$ con $h(x)=-x$.
  E' immediato verificare che la funzione $h(x)=-x$ è continua
  e dunque anche la differenza $f-g$ è continua.
  Lo stesso vale per la funzione $\abs f$ che è la composizione
  di $f$ con la funzione $h(x) = \abs{x}$.
  \end{proof}
  
  Il precedente teorema è molto importante ed utile in quanto
  garantisce che ogni funzione definita tramite una espressione
  che coinvolge solamente le funzioni e le operazioni
  elencate nell'enunciato del teorema, risulta certamente
  essere una funzione continua. Come nel seguente.
  
  \begin{example}
  La funzione
  \[
  f(x) = \frac{(x-3)\cdot x -\frac{1}{x+x^2}}{\abs{x-\frac{1-x^3}{x}}}
  \]
  è continua.
  
  Si intende che tale funzione è definita sull'insieme degli $x\in \RR$
  per cui tutte le operazioni coinvolte sono definite ovvero
  $f\colon D \subset \RR \to \RR$
  con
  \[
    D = \ENCLOSE{x\in \RR \colon x+x^2 \neq 0,\ x\neq 0,\ \abs{x-\frac{1-x^3}{x}}\neq 0}.
  \]
  \end{example}
  \begin{proof}
  Per convincersi che questa funzione $f$ è continua
  si nota che le funzioni $x$ e le costanti $3$ e $1$ sono
  funzioni continue.
  Ma allora, per il teorema~\ref{th:continuita_composizione},
  anche le funzioni $x-3$ e $x^2=x\cdot x$ sono continue.
  Dunque anche $(x-3)\cdot x$, $x+x^2$ e $x^3$ e $1-x^3$ sono continue.
  Di conseguenza sono continue pure $\frac 1{1+x^2}$ e $\frac{1-x^3}{x}$.
  E poi saranno continue anche $(x-3)\cdot x - \frac 1{1+x^2}$ e $x-\frac{1-x^3}{x}$
  e quindi $x-\frac{1-x^3}{x}$ e pure $\abs{x-\frac{1-x^3}{x}}$. Infine sarà
  dunque continua $f(x)$.
  \end{proof}
  
  In particolare è chiaro che le funzioni lineari e quadratiche 
  che abbiamo introdotto nelle sezioni precedenti sono funzioni continue
  in quanto sono ottenute sommando e moltiplicando tra loro funzioni continue.
  
  %%%%%%%%%%%%%%%%%%%
  
  \begin{theorem}[continuità delle funzioni monotone]
    \label{th:monotona_continua}%
    \mymark{*}%
    \index{funzione!continua}%
    \index{funzione!monotòna}%
    \index{funzione!suriettiva}%
    Sia $A\subset \RR$ e sia
    $f\colon I \to \RR$ una funzione monotòna.
    Se $f(I)$ è un intervallo allora $f$ è continua.
%    \label{th:monotona_continua_reverse}%
%    Allora $f$ è continua se e solo se $f(I)$ è 
%    un intervallo.
\end{theorem}
  %
  \begin{proof}
  Senza perdita di generalità possiamo supporre che $f$ 
  sia crescente. 
  % Dimostriamo innanzitutto che se $f(I)$ è intervallo allora $f$ è continua.
  
  Prendiamo un punto $x_0\in I$ e sia $\eps>0$.
  Vogliamo trovare $x_1<x_0$ tale che  
  per ogni $x\in [x_1,x_0]\cap I$ si abbia $f(x)>f(x_0)-\eps$.
  Siccome $f(I)$ è un intervallo che contiene il punto $f(x_0)$ 
  ci sono due possibilità: o $f(x)>f(x_0)-\eps$ per ogni $x\in I$
  e quindi possiamo scegliere $x_1<x_0$ a piacere
  oppure esiste $x_1\in I$ tale che $f(x_1)=f(x_0) - \frac \eps 2$.
  In questo secondo caso dovrà essere $x_1<x_0$ (in quanto $f$ è crescente)
  e per monotonia si avrà, come voluto $f(x)\ge f(x_1) > f(x_0)-\eps$ 
  per ogni $x\in [x_1,x_0]$.
  
  In modo analogo possiamo trovare $x_2>x_0$ tale 
  che per ogni $x\in [x_0,x_2]\cap I$ si abbia $f(x) < f(x_0)+\eps$.
  Essendo $f$ crescente se $x\ge x_0$ si avrà anche $f(x)\ge f(x_0)$ 
  e se $x\le x_0$ si avrà $f(x) \le f(x_0)$. 
  Dunque per ogni $x\in [x_1,x_2]$ si avrà $\abs{f(x)-f(x_0)}<\eps$.
  Basterà scegliere $\delta = \min\ENCLOSE{x_0-x_1,x_2-x_0}$ 
  per ottenere la continuità di $f$ in $x_0$.
  
%  Supponiamo ora che $f$ sia una funzione continua e crescente.
%  Vogliamo dimostrare che $f(I)$ è un intervallo.
%  
%  Siano $y_1, y_2 \in f(I)$ e sia $y_0\in \RR$
%  con $y_1 < y_0 < y_2$.
%  Vogliamo dimostrare che $y_0\in f(I)$ cioè che esiste $x_0\in I$
%  tale che $f(x_0)=y_0$.
%  Sappiamo che esistono $x_1,x_2$ in $I$ tali che
%  $f(x_1) = y_1$ e $f(x_2) = y_2$.
%  Dovrà essere $x_1<x_2$ perché $f(x_1)<f(x_2)$ e
%  $f$ è crescente.
%  Definiamo:
%  \[
%   x_0 = \sup A
%  \qquad
%  \text{con } A=\ENCLOSE{x\in I\colon f(x)<y_0},
%  \]
%  e dimostriamo che $f(x_0)=y_0$. 
%  Chiaramente $x_0\in [x_1,x_2]$ in quanto 
%  $x_1\in A$ e $x_2$ è un maggiorante di $A$
%  e dunque $f$ è definita e continua in $x_0$.
%  
%  Se fosse $f(x_0)<y_0$ scelto $\eps = y_0-f(x_0)$
%  per la definizione di continuità dovrebbe esistere
%  $\delta>0$ tale che per ogni $x\in I$ con $\abs{x-x_0}<\delta$
%  si abbia $\abs{f(x)-f(x_0)}<\eps$.
%  In particolare scelto $x=x_0+\frac \delta 2$
%  si avrebbe $f(x) < f(x_0) + \eps = y_0$.
%  Ma allora avremmo $x\in A$ che è assurdo in quanto
%  $\sup A = x_0 < x$.
%  
%  Se fosse invece $f(x_0)>y_0$ posto $\eps = f(x_0)-y_0$,
%  grazie alla continuità di $f$ in $x_0$,
%  possiamo trovare $\delta>0$ tale che per ogni $x\in I$
%  con $\abs{x-x_0}<\delta$ si abbia $\abs{f(x)-f(x_0)}<\eps$.
%  In particolare scelto $t = x_0 - \frac \delta 2$
%  si ha $f(t) > f(x_0)-\eps = y_0$. 
%  Ma essendo $t<x_0 = \sup A$ sappiamo che $t$ non può essere 
%  un maggiorante di $A$ dunque deve esistere $x\in A$
%  tale che $t<x$. 
%  Ma se $x\in A$ allora $f(x) < y_0 < f(t)$
%  che è assurdo in quanto $f$ è crescente.
%  
%  Abbiamo quindi mostrato che $f(x_0)=y_0$. 
%  Questo è vero per ogni scelta di $y_1<y_2$ in $f(I)$
%  dunque $f(I)$ è un intervallo.
\end{proof}
  %

Il teorema precedente (teorema~\ref{th:monotona_continua}) 
ci permette di affermare che per $a>0$, $a\neq 1$ 
le funzioni $\exp_a$ e $\log_a$ sono continue. 
Infatti tali funzioni sono bigezioni monotone tra 
gli intervalli $\RR$ e $\RR_+$.

Anche le funzioni trigonometriche $\sin$ e $\cos$ sono funzioni continue.
Sappiamo infatti che $\sin \colon [-\tau/4,\tau /4]\to [-1,1]$
e $\cos\colon [0,\tau/2]\to [-1,1]$ sono strettamente monotone 
e bigettive dunque sono continue su tali intervalli. 
Grazie alle proprietà di simmetria e periodicità
(oppure utilizzando le formule di addizione) è facile verificare 
che tali funzioni sono continue su tutto $\RR$.

Grazie al teorema~\ref{th:continuita_composizione} sappiamo 
che se $n\in \NN$ la funzione $x^n$ è continua su tutto il suo 
dominio $\RR$. 
La funzione inversa $\sqrt[n]{x}$ è anch'essa crescente e 
bigettiva come funzione $[0,+\infty)\to[0,+\infty)$ e dunque 
anch'essa risulta essere continua.
Per simmetria (si veda l'esercizio~\ref{ex:simmetrica_continua}) 
possiamo concludere 
%che sia la potenza $x^n$ 
che le radici $\sqrt[n]{x}$ sono 
funzioni continue su tutto il loro dominio.
Anche la funzione $f(x) = x^\alpha$, $f\colon [0,+\infty)\to [0,+\infty]$ 
con $\alpha>0$ è crescente ed è invertibile (l'inversa è $x^{\frac 1 \alpha}$)
e dunque è surgettiva e continua.
Se $\alpha<0$ la funzione $f(x)=x^\alpha$ è definita sull'intervallo 
$(0,+\infty)$ ed è anch'essa continua in quanto 
composizione di funzioni continue: $x^{\alpha} = \frac{1}{x^{-\alpha}}$.

%
\begin{exercise}\label{ex:simmetrica_continua}
  Sia $f\colon \RR\to \RR$ una funzione pari oppure dispari.
  Se la restrizione di $f$ all'intervallo $[0,+\infty)$ 
  è continua allora $f$ è continua su tutto $\RR$.
\end{exercise}

\subsection{limite}

Se una funzione $f$ non è definita in un punto $x_0$ non ha senso chiedersi
se in tale punto è continua. 
Possiamo però chiederci se è possibile definire la funzione anche nel punto 
$x_0$ dando un valore opportuno $\ell$ in modo da rendere $f$ continua 
in quel punto. 
Se ciò è possibile diremo che la funzione $f(x)$ ha limite $\ell$ 
per $x$ che tende a $x_0$ e scriveremo:
\[
  f(x) \to \ell \qquad \text{per $x\to x_0$}
\]
(daremo tra poco una definizione con maggiore precisione e generalità).

Ad esempio la funzione $f(x) = \frac{x^2-1}{x-1}$ è una funzione definita per $x\neq 1$
e coincide, se $x\neq 1$ con la funzione lineare $\tilde f(x) = x+1$ definita 
su tutto $\RR$. 
Visto che $\tilde f$ è continua e $\tilde f(1)=2$
scriveremo:
\[
  \frac{x^2-1}{x-1} \to 2
  \qquad \text{per $x\to 1$.}
\]

Se estendiamo $f$ con un valore $\ell$ nel punto $x_0$ otteniamo 
in generale la funzione 
\[
  \tilde f(x) = \begin{cases}
    f(x) & \text{se $x\neq x_0$}\\
    \ell & \text{se $x=x_0$}
  \end{cases}  
\]
e la continuità di $\tilde f$ nel punto $x_0$ si scrive così:
\[
\forall\eps>0\colon \exists \delta>0\colon
\abs{x-x_0}<\delta \implies \abs{\tilde f(x)-\tilde f(x_0)}<\eps.  
\]
Osserviamo che se $x=x_0$ allora ovviamente $\abs{\tilde f(x)-\tilde f(x_0)}
= 0 < \eps$ dunque possiamo supporre, nella condizione precedente, 
che sia $x\neq x_0$ e dunque $\tilde f(x)=f(x)$. 
Inoltre visto che $\tilde f(x_0)=\ell$ 
e $\tilde f(x)=f(x)$ se $x\neq x_0$,
si ottiene 
la seguente condizione:
\begin{equation}\label{eq:55338}
\forall \eps>0\colon \exists \delta >0 \colon 
  \forall x\neq x_0\colon
  \abs{x-x_0}<\delta \implies \abs{f(x) - \ell} < \eps.
\end{equation}
La~\eqref{eq:55338} potrebbe dunque essere utilizzata per definire 
il concetto di limite $f(x)\to \ell$ per $x\to x_0$.
Sarà però molto utile estendere il concetto di limite $f(x)\to \ell$ 
per $x\to x_0$ anche nei casi in cui $\ell$ e/o $x_0$ possano 
essere infiniti (cioè elementi dei reali estesi $\bar \RR$).

Per fare ciò osserviamo che
se definiamo%
\mynote{%
la lettera $B$ sta per \emph{ball} in quanto 
più in generale (se fossimo in $\RR^3$ invece che in $\RR$)
l'insieme dei punti che distano meno di $\rho$ da un punto fissato 
è l'interno di una sfera piena. 
In geometria una sfera piena si chiama \emph{palla} 
se contiene solo i punti interni (e non la superficie sferica)
e si chiama \emph{disco} o \emph{palla chiusa} se contiene 
anche i punti della superficie.
}
$B_\rho(x_0) = \ENCLOSE{x\in \RR \colon \abs{x-x_0}<\rho}$
la condizione \eqref{eq:55338}
può essere scritta anche nella forma 
\[
  \forall \eps>0\colon \exists \delta >0 \colon 
  x \in B_\delta(x_0)\setminus\ENCLOSE{x_0} \implies f(x) \in B_\eps(\ell)  
\]
che a sua volta si può scrivere nella forma:
\[
  \forall \eps>0\colon \exists \delta >0 \colon 
  f(B_\delta(x_0)\setminus\ENCLOSE{x_0}) \subset  B_\eps(\ell).    
\]

L'idea è che gli insiemi del tipo
$B_\rho(x_0)$ 
rappresentano i punti \emph{vicini} al punto $x_0$. 
In analogia potremmo pensare che i punti \emph{vicini} 
a $+\infty$ siano i punti di una qualunque semiretta 
del tipo $(M,+\infty]$.
Si dà quindi la seguente.


\begin{definition}[intorno]
Per $x\in \RR$ definiamo la famiglia degli \emph{intorni}%
\mymargin{intorni}%
\index{intorno} (basilari) di $x$
come l'insieme di tutti gli intervallini aperti, simmetrici, centrati in $x$:
\[
  \B_x = \ENCLOSE{ (x-\eps, x+\eps) \colon \eps>0}.
\]
Definiamo poi le famiglie 
degli \emph{intorni destri} e \emph{intorni sinistri}
\mymargin{intorni destri/sinistri}%
\index{intorni!destri/sinistri}
\index{intorni}
di $x$ come
\[
  \B_{x^+} = \ENCLOSE{ [x, x+\eps) \colon \eps>0},
  \qquad
  \B_{x^-} = \ENCLOSE{ (x-\eps , x] \colon \eps>0}
\]
e le famiglie degli intorni di $+\infty$ e $-\infty$ come segue
\[
  \B_{+\infty} = \ENCLOSE{ (\alpha,+\infty], \colon \alpha \in \RR },\qquad
  \B_{-\infty} = \ENCLOSE{ [-\infty, -\beta), \colon \beta\in \RR}.
\]

Per ogni $x\in \bar \RR = [-\infty, +\infty]$
risultano quindi definiti gli intorni $\B_x$ e per
ogni $x\in \RR$ sono definiti gli intorni $\B_{x^+}$ e $\B_{x^-}$.

Più in generale se $x\in \CC$ o $x\in \RR^n$
si definiscono gli intorni di $x$ 
utilizzando la norma $\abs{\cdot}$.
Posto $B_\rho(x) = \ENCLOSE{y\colon \abs{y-x}<\rho}$
(palla di raggio $\rho$ centrata in $x$)
la famiglia di intorni di $x$ non è altro che
\[
  \B_x = \ENCLOSE{B_\rho(x)\colon \rho>0}.
\]
Nel caso $x\in \RR$ si riottiene la stessa definizione che 
abbiamo dato sopra.

In $\CC$ o in $\RR^n$ non c'è un ordinamento quindi 
tipicamente si aggiunge un solo punto all'infinito: $\infty$.
Gli intorni di $\infty$
sono dati dall'esterno di una palla:
\[
  \B_\infty = \ENCLOSE{\ENCLOSE{y\colon \abs{y}\ge R}\colon R>0}.
\]

Anche su $\RR$ si può considerare un unico punto 
all'infinito (che potremmo denotare con $\infty$)
invece che i due punti $+\infty$ e $-\infty$.
\end{definition}

% \begin{remark}
% Sarebbe possibile definire in maniera analoga gli intorni dei punti in $\RR^n$
% (per l'analisi di funzioni di più variabili)
% o in $\CC$ (per l'analisi complessa).
% Ma in questo corso e in questo capitolo in particolare siamo interessati 
% allo studio delle funzioni di una singola variabile.
% 
% Su $\RR$ c'è una struttura di ordine totale che è utile preservare aggiungendo
% due punti all'infinito: $+\infty$ e $-\infty$.
% Su $\RR^n$ (e su $\CC$, che in questo contesto possiamo identificare con $\RR^2$)
% non c'è una struttura d'ordine naturale e quindi
% usualmente si considera un unico punto all'infinito $\infty$ i cui intorni
% saranno
% \[
%   \B_\infty = \ENCLOSE{\ENCLOSE{x \in \RR^n\colon \abs{x}>R}\colon R>0}.
% \]
% 
% Su $\RR^n$ (e su $\CC$) non esiste il concetto di intorno \emph{destro}
% e \emph{sinistro} proprio perché questi concetti presuppongono un ordinamento.
% 
% In certi casi può tornare utile considerare un unico punto all'infinito,
% denotato con $\infty$, anche in $\RR$ (in molti testi tale punto verrebbe
% denotato con il simbolo $\pm\infty$)
% e si potrebbero usare le notazioni $+\infty = \infty^-$ e $-\infty = \infty^
% +$ visto che gli intorni di $+\infty$ e $-\infty$ sono in effetti intorni
% unilaterali del punto all'infinito.
% \end{remark}

\begin{definition}[limite di funzione]
\mymark{***}
Sia $A\subset \RR$ e $f\colon A \to \RR$. 
Sia $x_0\in [-\infty,+\infty]$
% un punto di accumulazione di $A$ 
e sia $\ell \in [-\infty,+\infty]$.
Allora diremo che la funzione $f$ ha limite $\ell$ per $x$ che tende a $x_0$ 
e scriveremo\mymargin{limite di funzione}%
\index{limite!di funzione}
\[
  f(x) \to \ell \qquad \text{per $x\to x_0$}
\]
se per ogni intorno di $\ell$ esiste un intorno di $x_0$ tale che
la funzione valutata nell'intorno di $x_0$, tolto eventualmente $x_0$,
assume valori
nell'intorno di $\ell$:
\begin{equation}\label{eq:def_limite}
  \forall V \in \B_\ell \colon \exists U \in \B_{x_0} \colon f(U\setminus\ENCLOSE{x_0}) \subset V.
\end{equation}

La stessa definizione può essere data restringendosi agli intorni destri/sinistri del punto $x_0$ (nel caso $x_0 \in \RR$). Si otterranno quindi le definizioni
di \emph{limite destro} e \emph{limite sinistro}
\mymargin{limite destro/sinistro}%
\index{limite!destro/sinistro} %
semplicemente sostituendo $\B_{x_0^+}$ o $\B_{x_0^-}$ al posto di 
$\B_{x_0}$ nella definizione
precedente. 
In tal caso scriveremo $f(x)\to \ell$ per $x\to x_0^+$ per il limite 
destro e $f(x)\to \ell$ per $x\to x_0^-$ per il limite sinistro.

Infine anche il risultato del limite può essere $\ell^+$ o $\ell^-$, 
in tal caso useremo $\B_{\ell^+}$ o $\B_{\ell^-}$ 
al posto di $\B_{\ell}$.

Anche per le funzioni complesse $f\colon A\subset \CC \to \CC$ 
si applica la stessa identica definizione.
\end{definition}
  
\begin{example}
Si consideri la funzione segno:
\[
\sgn(x) =
\begin{cases}
  1 & \text{se $x>0$},\\
  0 & \text{se $x=0$},\\
  -1 & \text{se $x<0$}.
\end{cases}
\]
Si può verificare che
\[
\sgn(x) \to 1 \qquad \text{per $x\to 0^+$}
\]
e
\[
\sgn(x) \to -1 \qquad \text{per $x\to 0^-$}
\]
\end{example}

Abbiamo già visto che nel caso in cui $x_0\in \RR$ e $\ell\in \RR$ 
siano entrambi finiti 
la definizione di limite $f(x)\to \ell$ per $x\to x_0$
si traduce nella condizione~\eqref{eq:55338}.

Anche negli altri casi esplicitando le definizioni di intorno
si possono ottenere delle condizioni più esplicite.
Ad esempio la condizione $f(x)\to -\infty$ per $x\to x_0^+$
si traduce nel modo seguente:
\[
\forall \beta\in \RR\colon \exists \delta>0 \colon x_0 < x < x_0+\delta 
\implies f(x) < -\beta.  
\]
Visto che ci sono cinque diversi casi per il punto $x_0$:
$x_0\in \RR$, $x_0^+$, $x_0^-$, $+\infty$, $-\infty$ e altrettanti 
casi per $\ell$ (in effetti anche il risultato del limite 
può essere \emph{destro} o \emph{sinistro}), si ottengono 
in tutto 25 diverse definizioni di limite.

In tutte queste definizioni di limite è sottointeso che i punti 
$x$ che vengono presi in considerazione sono punti 
del dominio di $f\colon A \subset \RR \to \RR$.
Accade allora che se esiste un intorno $V\in \B_{x_0}$
per cui $A \cap V \setminus \ENCLOSE{x_0}$ è vuoto allora 
la condizione di limite è vuota ed è quindi sempre verificata 
qualunque sia il valore di $\ell$. 
E' quindi inutile fare il limite per $x\to x_0$ 
se $x_0$ non soddisfa la seguente.

\begin{definition}[punto di accumulazione]
  \mymark{*}
  Siano $A\subset  \RR$ un insieme e $x_0\in [-\infty, +\infty]$.
  Diremo che $x_0$ è un \emph{punto di accumulazione}%
\mymargin{punto di accumulazione}%
\index{punto!di accumulazione} di $A$
  se ogni intorno di $x_0$ contiene punti di $A$ diversi da $x_0$, ovvero:
  \[
   \forall U \in \B_{x_0}\colon (A\setminus \ENCLOSE{x_0}) \cap U \neq \emptyset.
  \]

  Stessa definizione si può dare per $x_0^+$ e $x_0^-$ 
  utilizzando gli intorni destri/sinistri di $x_0$. 

  Sempre la stessa definizione si può applicare 
  quando $A\subset \CC$ e $x_0\in \bar \CC$.
\end{definition}

\begin{theorem}[unicità del limite]
\mymark{*}
Sia $A\subset \RR$, $f\colon A \to \RR$, $x_0$
punto di accumulazione per $A$ e $\ell_1, \ell_2\in [-\infty,+\infty]$.
Se per $x\to x_0$ si ha
\[
  f(x) \to \ell_1 \qquad\text{e}\qquad f(x) \to \ell_2
\]
allora $\ell_1=\ell_2$.

Risultato analogo si ha per i limiti destro e sinistro: $x\to x_0^+$, 
$x\to x_0^-$.
Anche su $\CC$ vale lo stesso risultato
prendendo $\ell_1,\ell_2\in \bar \CC$.
\end{theorem}
%
\begin{proof}
\mymark{*}
Supponiamo per assurdo che $\ell_1\neq \ell_2$.
Allora esiste un intorno $V_1$ di $\ell_1$ ed un intorno $V_2$ di $\ell_2$
tali che $V_1\cap V_2 = \emptyset$ (basta prendere degli intorni abbastanza piccoli). 
Ma per le definizioni di limite $f(x)\to \ell_1$ e $f(x)\to \ell_2$ 
dovranno esistere $U_1$ e $U_2$ intorni di $x_0$ su cui si ha 
$f(U_1)\subset V_1$ e $f(U_2)\subset V_2$. 
Ma allora $f((A\setminus\ENCLOSE{x_0})\cap U_1)\cap f((A\setminus\ENCLOSE{x_0})\cap U_2)\subset V_1\cap V_2 = \emptyset$... 
e questo è assurdo perché certamente $U_1\cap U_2$ 
contiene punti di $A$ diversi da $x_0$ in quanto 
$U_1$ e $U_2$ sono uno contenuto nell'altro e $x_0$ 
è un punto di accumulazione per $A$.
\end{proof}

Il teorema precedente garantisce che se $x_0$ è un punto di accumulazione 
del dominio di $f$ allora il limite per $x\to x_0$ se esiste è unico. 
In tal caso possiamo dunque dare la seguente.
%
\begin{definition}[operatore di limite]
Sia $f\colon A\subset \RR \to \RR$ una funzione e $x_0$ 
un punto di accumulazione per $A$. 
Se esiste $\ell\in\closeinterval{-\infty}{+\infty}$ tale che
$f(x)\to \ell$ per $x\to x_0$ allora poniamo
\[
  \lim_{x\to x_0} f(x) = \ell.
\]
Lo stesso si può fare per il limite destro $x\to x_0^+$ 
e sinistro $x\to x_0^-$.
Anche per funzioni di variabile e/o di valore 
complesso si può dare la stessa definizione prendendo $x_0\in \bar \CC$ 
e/o $\ell\in \bar \CC$.
\end{definition}

Abbiamo visto che in un punto di accumulazione se il limite 
esiste allora è unico.
Sarà però utile osservare che in effetti il limite può non 
esistere, come si può verificare con un esempio.

\begin{example}[in generale il limite non esiste]
Il limite 
\[
  \lim_{x\to 0} \frac{x}{\abs{x}}
\]
non esiste. 
\end{example}
\begin{proof}
Osserviamo infatti che la funzione $f(x) = \frac{x}{\abs x}$ 
vale $1$ se $x>0$ e $-1$ se $x<0$.
Dunque se il limite esistesse e fosse $\ell\in \bar \RR$, 
scelto $\eps=1$, dovrebbe esistere un intervallo intorno di $0$ 
della forma $\openinterval{-\delta}{\delta}$ tale che 
$\abs{f(x)-\ell}<1$ per ogni $x$ in tale intervallo.
In particolare siccome in tale intervallo ci sono sicuramente 
sia numeri positivi che negativi si dovrà avere 
contemporaneamente
\[
  \abs{1-\ell}<1, \qquad 
  \abs{-1-\ell}<1  
\]
che è impossibile in quanto per disuguaglianza triangolare 
\[
 2 = \abs{1-(-1)} 
 \le \abs{1-\ell} + \abs{-1-\ell}
 < 1 + 1 = 2
\]
che è assurdo.
\end{proof}

Si noti che nell'esempio precedente il limite per $x\to 0$ 
non esiste ma in realtà esistono sia il limite per $x\to 0^+$ 
(vale $1$) che i limite per $x\to 0^-$ (vale $-1$).
Possiamo esibire un esempio ``patologico'' di funzione 
che non ammette limite (né da destra né da sinistra)
in nessun punto:
\[
  f(x) = 
  \begin{cases}
     1 & \text{se $x\in \QQ$}\\ 
     0 & \text{se $x\in \RR\setminus \QQ$}.
  \end{cases}
\]
In ogni intervallo $\openinterval a b$ con $a<b$ questa funzione 
assume sia il valore $0$ che il valore $1$ 
in quanto sia $\QQ$ che $\RR\setminus \QQ$ intersecano 
l'intervallo (sono insiemi densi).
Ma se $f$ avesse limite $\ell$ dovrebbe esistere un intervallo 
in cui i valori distano meno di $\eps$ da $\ell$ e quindi 
dovrebbe essere $\abs{1-\ell}<\eps$ e $\abs{0-\ell}<\eps$
che è impossibile se scegliamo $\eps < \frac 1 2$.

\begin{theorem}[collegamento tra limiti e continuità]%
\mymark{***}%
  Sia $A\subset \RR$, $f\colon A \to \RR$. 
  Se $x_0\in A$ è un punto di accumulazione di $A$
  allora $f$ è continua in $x_0$ se e solo se
  \[
    \lim_{x\to x_0}f(x) = f(x_0).
  \]
  Se $x_0\in A$ non è punto di accumulazione diremo 
  che $x_0$ è un \emph{punto isolato}%
\mymargin{punto isolato}%
\index{punto!isolato} di $A$.
  In tal caso la funzione $f$ è sempre continua nel punto $x_0$.

Risultato analogo vale per funzioni complesse e/o di variabile complessa.
\end{theorem}
  
  \begin{proof}
  In base alla definizione~\ref{def:continua} la funzione $f$ è continua nel
  punto $x_0\in \bar \RR$ se
  \[
   \forall \eps>0 \colon \exists \delta >0 \colon
   \forall x \in A\colon
   \abs{x-x_0}<\delta \implies \abs{f(x)-f(x_0)} < \eps
  \]
  mentre la definizione di limite $f(x)\to f(x_0)$ per $x\to x_0$
  si espande in
  \[
  \forall \eps>0 \colon \exists \delta>0\colon
  \forall x \in A, x\neq x_0\colon
  \abs{x-x_0}<\delta \implies \abs{f(x)-f(x_0)} < \eps.
  \]
  L'unica differenza è che nella definizione di limite
  c'è la condizione $x\neq x_0$. Ma visto che per $x=x_0$
  si ha $\abs{f(x)-f(x_0)}=0$ tale condizione è in questo caso 
  inutile e quindi le due definizioni sono equivalenti.

  Se il punto $x_0$ è isolato la definizione di continuità
  è sempre verificata in quanto esiste un $\delta>0$ 
  tale che il punto $x=x_0$ è l'unico punto di $A$ 
  nell'intorno $(x_0-\delta,x_0+\delta)$.
  \end{proof}

\begin{example}
  Non è difficile convincersi che gli unici punti di accumulazione 
  per l'insieme $\ZZ$ sono $+\infty$ e $-\infty$.
  Dunque qualunque funzione $f\colon \ZZ \to \RR$ è continua in quanto 
  tutti i punti del suo dominio sono punti isolati.
\end{example}
  
\begin{theorem}[località del limite]%
\label{th:localita_limite}%
Il limite di una funzione per $x\to x_0$ dipende solamente dai valori di $f$
in un intorno di $x_0$ e non dipende dal valore di $f$ in $x_0$.

Più precisamente: se $A,B\subset \RR$, $f\colon A\to \RR$, $g\colon B\to \RR$, 
$x_0\in \RR$ sono tali che 
esiste un intorno $V$ di $x_0$ per cui 
$(A\setminus\ENCLOSE{x_0}) \cap  V = (B\setminus \ENCLOSE{x_0}) \cap V$ 
e $f(x)=g(x)$ per ogni $x\in(A\setminus\ENCLOSE{x_0}) \cap  V$ 
allora se $f(x)\to \ell$ per $x\to x_0$ anche $g(x)\to \ell$ 
per $x\to x_0$.

Lo stesso risultato vale per funzioni complesse e/o di variabile complessa.
\end{theorem}
%
\begin{proof}
  Basta osservare che nella definizione di limite 
  non è restrittivo supporre che l'intorno del punto $x_0$ 
  sia sempre preso all'interno dell'intorno $V$ su cui 
  le due funzioni coincidono.
\end{proof}

\begin{theorem}[restrizione del limite]
Se una funzione ha limite $\ell$ per $x\to x_0$ 
e se restringiamo l'insieme di definizione della funzione 
allora il limite della funzione non cambia. 
Più precisamente
se $f\colon A \to \RR$ è una funzione tale che $f(x)\to \ell$ per $x\to x_0$
e se $B \subset A$ e $g\colon B\to \RR$ è la restrizione di $f$ 
a $B$ allora anche $g(x)\to \ell$ per $x\to x_0$. 
\end{theorem}
%
\begin{proof}
Il teorema segue immediatamente dalla definizione di limite se si osserva
che restringendo il dominio la condizione di validità del limite si indebolisce
in quanto gli intorni di $x_0$ vengono intersecati con il dominio della funzione.
\end{proof}

Si osservi che a differenza del teorema sulla località del limite è
possibile che la funzione ristretta $g$ abbia limite quando la funzione
$f$ non aveva limite.
Si osservi anche che in entrambi questi teoremi sarà opportuno 
che $x_0$ sia un punto di accumulazione, altrimenti la condizione $f(x)\to \ell$ 
risulta essere vuota.

\begin{theorem}[legame tra limite, limite destro e limite sinistro]%
\mymark{*}%
Sia $A\subset \RR$, $f\colon A \to \RR$ una funzione e $x_0$ un punto di accumulazione
di $A$. Sia $A^+ = A \cap [x_0,+\infty)$ e $A^- = A \cap (-\infty, x_0]$.

Se $x_0$ è punto di accumulazione sia di $A^+$ che di $A^-$
allora si ha
\[
  \lim_{x\to x_0} f(x) = \ell
\]
se e solo se
\[
  \lim_{x\to x_0^+} f(x) = \lim_{x\to x_0^-} f(x) = \ell.
\]

Se $x_0$ è punto di accumulazione di $A^+$ ma non di $A^-$ allora
i limiti
\[
  \lim_{x\to x_0} f(x) \qquad \text{e}\qquad \lim_{x\to x_0^+} f(x)
\]
sono equivalenti. Analogamente se $x_0$ è punto di accumulazione
di $A^-$ ma non di $A^+$ risultano equivalenti
\[
  \lim_{x\to x_0} f(x) \qquad \text{e}\qquad \lim_{x\to x_0^-} f(x).
\]
\end{theorem}
%
\begin{proof}
Si tratta semplicemente di verificare le definizioni di limite sfruttando il fatto che intorni di un punto $x_0$ sono formati dall'unione di intorno destro e intorno sinistro.
\end{proof}

\begin{theorem}[limite della funzione composta/cambio di variabile]
\label{th:limite_composta}
Siano $A\subset \RR$, $B\subset \RR$,
$x_0$ un punto di accumulazione di $A$,
$y_0$ un punto di accumulazione di $B$,
$\ell\in [-\infty,+\infty]$.
Siano $f\colon A \to B$, $g\colon B\to \RR$
funzioni tali che $f(x)\neq y_0$ se $x\neq x_0$ e 
\[
  \lim_{x\to x_0} f(x) = y_0,
\qquad
  \lim_{y\to y_0} g(y) = \ell.
\]
Allora nel secondo limite si può porre $y=f(x)$ e al posto di $y\to y_0$ 
si può mettere $x\to x_0$ (in quanto il primo limite ci dice che se $x\to x_0$ 
allora $y\to y_0$) e dunque vale:
\[
 \lim_{x\to x_0} g(f(x)) = \ell.
\]
\end{theorem}
%
\begin{proof}
Visto che $g(y)\to \ell$
per ogni $U$ intorno di $\ell$ deve esistere un $V$ intorno di $y_0$
tale che $g((B\setminus\ENCLOSE{y_0})\cap V) \subset U$
e visto  che $f(x)\to y_0$ deve esistere un intorno $W$ di $x_0$
tale che $f((A\setminus\ENCLOSE{x_0})\cap W) \subset V$.
Ma visto che per ipotesi $f$ assume valori in $B\setminus\ENCLOSE{y_0}$
si ha anche $f((A\setminus\ENCLOSE{x_0})\cap W)\subset (B\setminus\ENCLOSE{y_0}) \cap V$
e quindi
\[
  g(f((A\setminus\ENCLOSE{x_0})\cap W)) \subset g((B\setminus \ENCLOSE{y_0}) \cap V)
  \subset U
\]
che significa che $g(f(x)) \to \ell$.
\end{proof}

\begin{exercise}
  Si faccia un esempio di una funzione $f\colon\RR\to \RR$ 
  e una funzione $g\colon\RR\to \RR$ tali che 
  \[
  \lim_{x\to 0} f(x) = 0, \qquad 
  \lim_{x\to 0} g(x) = 0
  \]
  ma
  \[
  \lim_{x\to 0} g(f(x)) = 1.
  \]
  Quale ipotesi nel teorema precedente viene a mancare?
\end{exercise}

\begin{theorem}[limite di funzioni monotòne]%
  \mymark{**}%
  \label{th:limite_monotona}%
Sia $f\colon A \subset \RR \to \RR$ una funzione crescente. 
Se $x_0$ è un punto di accumulazione sinistro per $A$ 
il seguente limite esiste e vale
\[
   \lim_{x\to x_0^-}f(x) = \sup f(\ENCLOSE{x\in A\colon x<x_0})
\]
e se $x_0$ è un punto di accumulazione destro per $A$ 
il seguente limite esiste e vale
\[
   \lim_{x\to x_0^+} f(x) = \inf f(\ENCLOSE{x\in A\colon x>x_0}).
\]
In particolare se $+\infty$ è punto di accumulazione per $A$ 
si ha 
\[
  \lim_{x\to +\infty} f(x) = \sup f(A)
\]
e se $-\infty$ è punto di accumulazione per $A$ si ha 
\[
  \lim_{x\to -\infty} f(x) = \inf f(A).
\]

Gli stessi risultati valgono per le funzioni decrescenti, 
scambiando $\sup$ e $\inf$.
\end{theorem}
%
\begin{proof}\mymark{**}
Supponiamo che $f$ sia crescente e consideriamo il limite 
sinistro $x\to x_0^-$. Può anche essere $x_0=+\infty$, in tal 
caso il limite sinistro $x\to x_0^-$ equivale a $x\to +\infty$.
Poniamo $B=\ENCLOSE{x\in A\colon x<x_0}$
e $\ell=\sup f(B)$ e ricordiamo le proprietà che caratterizzano 
l'estremo superiore
(sappiamo che $B$ non è vuoto in quanto $x_0^-$ per ipotesi 
è un punto di accumulazione per $A$):
\begin{gather*}
  \forall x \in B \colon f(x) \le \ell \\
  \forall y < \ell \colon \exists \alpha \in B \colon f(\alpha) > y.
\end{gather*}
Siccome $f$ è crescente, dalla seconda condizione 
si ottiene che per ogni $x>\alpha$ si ha $f(x)\ge f(\alpha)> y$
e mettendo insieme le due condizioni si ottiene che per ogni $y<\ell$
esiste $\alpha\in\RR$ tale che per ogni $x>\alpha$ si ha $y<f(x)\le \ell$.
Certamente si ha $\alpha < x_0$ perché $\alpha\in B$.   
Dunque la condizione $x>\alpha$ identifica un intorno sinistro 
del punto $x_0$ e si ha dunque $f(x)\to \ell$ per $x\to x_0^-$.

Ragionamento analogo si può fare per il limite destro  
e per le funzioni decrescenti.
\end{proof}

\begin{exercise}
  Utilizzando il teorema precedente si studino le \emph{discontinuità}
  delle funzioni monotone. 
  Si dimostri quindi che l'insieme dei punti in cui una funzione monotona 
  \emph{non} è continua può essere messo in corrispondenza biunivoca 
  con un sottoinsieme di $\QQ$ e dunque tale insieme è numerabile.
\end{exercise}

Il teorema precedente si applica in particolare alle funzioni 
esponenziali, potenze, radici e logaritmi negli estremi dei loro 
domini. Ad esempio è chiaro che se $x_0\in (0,+\infty)$ 
si ha 
\[
  \lim_{x\to x_0} \log_a x = \log_a x_0
\]
in quanto il logaritmo è una funzione continua. 
Se $a>1$ il logaritmo è crescente e la sua immagine è tutto $\RR$ 
dunque si ha 
\[
  \lim_{x\to 0^+} \log_a x = \inf \RR = -\infty
  \qquad
  \lim_{x\to +\infty} \log_a x = \sup \RR = +\infty.
\]
Per l'esponenziale avremo 
\[
 \lim_{x\to x_0} a^x = a^{x_0}
\]
se $x_0\in \RR$ per continuità. 
Se $a>1$ l'esponenziale è crescente 
ed ha immagine $(0,+\infty)$ dunque 
\[
  \lim_{x\to -\infty} a^x = 0, \qquad 
  \lim_{x\to +\infty} a^x = +\infty.
\]
Se $0<a<1$ i limiti all'infinito 
si scambiano in quanto $a^{x}= \frac{1}{a^{-x}}$.
Per le potenze avremo, se $x_0\in[0,+\infty)$ e $\alpha>0$
\[
  \lim_{x\to x_0} x^\alpha = x_0^\alpha
\]
per continuità. Invece essendo $x^\alpha$ crescente e bigettiva 
su $[0,+\infty)$ si avrà 
\[
  \lim_{x\to +\infty} x^\alpha = +\infty.
\]
Se $\alpha<0$ la funzione $x^\alpha$ è continua, decrescente e bigettiva 
su $(0,+\infty)$ e dunque in tal caso:
\[
  \lim_{x\to +\infty} x^\alpha = 0.
\]
Tutti questi limiti \emph{notevoli} possono essere facilmente 
ricordati se teniamo in mente i grafici delle funzioni elementari
Figura~\ref{fig:esponenziale_logaritmo} (a pagina \pageref{fig:esponenziale_logaritmo})
e~\ref{fig:potenza_intera_radice} (a pagina \pageref{fig:potenza_intera_radice}).

Anche la funzione valore assoluto $f(x)=\abs{x}$ è separatamente 
monotona sugli intervalli $[0,+\infty)$ e $(-\infty,0]$. 
Dunque sappiamo che 
\[
  \lim_{x\to +\infty} \abs{x} = \abs{+\infty} = +\infty, 
  \lim_{x\to -\infty} \abs{x} = \abs{-\infty} = +\infty.
\]
Se $x_0\in \RR$ ovviamente si ha pure
\[
  \lim_{x\to x_0} \abs{x_0} = \abs{x_0}
\]
in quanto è banale verificare che la funzione $\abs{x}$ è continua.
Lo stesso vale per la funzione \emph{modulo} $\abs{z}$ quando $z\in \CC$.

Ci sarà anche utile osservare che vale anche questa proprietà 
\[
\lim_{x\to x_0} \abs{f(x)} = 0 \iff 
\lim_{x\to x_0} f(x) = 0
\]
valida perché le definizioni di limite $f(x)\to 0$ e $\abs{f(x)}\to 0$ 
coincidono in quanto $\abs{f(x)-0} = \big\lvert{\abs{f(x)} - 0}\big\rvert$.

\begin{theorem}[permanenza del segno]%
\mymark{***}%
\index{permanenza del segno}%
\index{teorema!della permanenza del segno}%
\mymargin{permanenza del segno}%
Se
\[
  \lim_{x\to x_0} f(x) > 0
\]
allora esiste un intorno $U$ di $x_0$ tale che 
per ogni $x\in U$ si ha $f(x) > 0$.

Viceversa se esiste un intorno $U$ di $x_0$ tale che per ogni $x \in U$  
si ha $f(x)\ge 0$ e se esiste $\ell$ tale che 
\[
    \lim_{x\to x_0} = \ell
\]
allora $\ell\ge 0$.
\end{theorem}
%
Intuitivamente il teorema precedente ci dice che le disuguaglianze strette 
si preservano (permangono) togliendo l'operatore di limite mentre 
le disuguaglianze larghe si preservano passando al limite.
%
\begin{proof}
Sia $\ell\in [-\infty,+\infty]$ il valore del limite.
Se $\ell>0$ esiste certamente un intorno $V$ di $\ell$ 
tale che $V\subset (0,+\infty]$: se $\ell\in \RR$ basta prendere 
$V=(\ell/2,3 \ell/2)$, se $\ell=+\infty$ basta prendere $V=(1,+\infty]$.
Per la definizione di limite esiste $U$ intorno di $x_0$ 
tale che $f(U)\subset V$ e il risultato segue.

Per il viceversa si ragiona per assurdo. 
Se il limite $\ell$ di $f$ esistesse e fosse $\ell < 0$
allora per il punto precedente (applicato a $-f$) dovremmo 
concludere che c'è un intorno di $x_0$ in cui $f(x)<0$.
Ma allora non è possibile che ci sia un intorno in cui $f(x)\ge 0$.
\end{proof}

\begin{theorem}[operazioni con i limiti di funzione]
  \label{th:operazioni_limiti}%
  \index{limite!della somma}%
  \index{limite!del prodotto}%
  \index{limite!del rapporto}%
\mymark{***}%
Se
\[
  \lim_{x\to x_0}f(x) = \ell_1,\qquad
  \lim_{x\to x_0}g(x) = \ell_2
\]
allora si ha
\begin{gather*}
  \lim_{x\to x_0} \enclose{f(x) + g(x)} = \ell_1 + \ell_2, \qquad
  \lim_{x\to x_0} \enclose{f(x) - g(x)} = \ell_1 - \ell_2, \\
  \lim_{x\to x_0} f(x)\cdot g(x) = \ell_1 \cdot \ell_2, \qquad
  \lim_{x\to x_0} \frac{f(x)}{g(x)} = \frac{\ell_1}{\ell_2}
\end{gather*}
sempre che le operazioni utilizzate sul lato destro delle uguaglianze
siano state definite\mynote{%
Si veda la sezione~\ref{sec:reali_estesi}.
I casi in cui le operazioni non sono definite si chiamano 
usualmente \emph{forme indeterminate}
\index{forme indeterminate}
e sono: $+\infty - (+\infty)$, 
$-\infty - (-\infty)$, $+\infty + (-\infty)$, 
$-\infty + (+\infty)$, $0\cdot (+\infty)$, $+\infty \cdot 0$
$0\cdot (-\infty)$, $-\infty \cdot 0$, $\frac 0 0$,
$\frac{+\infty}{+\infty}$, $\frac{-\infty}{-\infty}$,
$\frac{+\infty}{-\infty}$, $\frac{-\infty}{+\infty}$. 
}.
Inoltre se $g(x)\to 0^+$ 
si ha
\[
    \lim_{x\to x_0} \frac{1}{g(x)} = +\infty
\]
(informalmente potremmo scrivere: $\frac{1}{0^+} = +\infty$).

Gli stessi risultati valgono per funzioni di variabile e/o valore complesso.
Anzi i limiti a $\infty$ si comportano meglio, visto che 
$g(z)\to 0$ risulta equivalente a $1/g(z)\to \infty$.

\end{theorem}
%
\begin{proof}
Consideriamo la somma dei limiti
e innanzitutto il caso in cui $\ell_1$ ed $\ell_2$ 
siano entrambi finiti. 
In tal caso
dato un qualunque intorno $U=(\ell-\eps,\ell+\eps)$ 
di $\ell=\ell_1+\ell_2$
se prendiamo gli intorni $U_1=(\ell_1-\eps/2,\ell_1+\eps/2)$ 
e $U_2 = (\ell_2-\eps/2,\ell_2+\eps/2)$ si possono trovare 
degli intorni $V_1$ e $V_2$ di $x_0$ per cui si ha 
$f(V_1\setminus\ENCLOSE{x_0}) \subset U_1$ e 
$f(V_2\setminus \ENCLOSE{x_0}) \subset U_2$
e a maggior ragione questo risulta se prendiamo $V=V_1\cap V_2$ 
al posto di $V_1$ e $V_2$. 
Visto che $U_1+U_2 = U$ si avrà allora 
$(f+g)(V\setminus\ENCLOSE{x_0})\subset U$.

Sempre nel caso della somma 
se $\ell_1=+\infty$ e $\ell_2\neq -\infty$
allora $\ell_1+\ell_2=+\infty$ e 
dato un intorno di $+\infty$ 
della forma $U=(\alpha,+\infty]$ con $\alpha>0$
possiamo prendere 
$U_1 = (2\alpha,+\infty)$ e $U_2 = (\ell_2-\alpha,\ell_2+\alpha)$ 
se $\ell_2\in \RR$ oppure $U_2 = (\alpha,+\infty)$ se $\ell_2=+\infty$.
In ogni caso si ha $U_1+U_2 = U$ e si procede quindi come nel caso precedente.
Il caso $\ell_1=-\infty$ si dimostra in maniera del tutto analoga.

Per la differenza basta osservare che $f(x)-g(x) = f(x) + (-g(x))$.
Se $\ell_2$ è finito la continuità della funzione $h(y)=-y$
ci garantisce che $-g(x)\to -\ell_2$.
Lo stesso si verifica facilmente quando $\ell_2$ è infinito 
(basta osservare che se $U=(\alpha,+\infty]$ è un intorno di $+\infty$
allora $-U = [-\infty,-\alpha)$ è un intorno di $-\infty$). 
Dunque il limite della differenza si riconduce al limite della somma.

Per quanto riguarda il prodotto ci ricordiamo che grazie 
al teorema~\ref{th:isomorfismo} il gruppo additivo totalmente 
ordinato $\RR = \openinterval{-\infty}{+\infty}$ 
è isomorfo al gruppo moltiplicativo $\RR_+ = \openinterval 0 {+\infty}$
e di conseguenza $\bar \RR = \closeinterval{-\infty}{+\infty}$
corrisponde a $\closeinterval {0^+}{+\infty}$
(l'isomorfismo $\RR_+\to \RR$ è dato dalla funzione $\log_a x$ con $a>1$ 
fissato,
tale funzione preserva gli intorni dei punti corrispondenti salvo il fatto 
che gli intorni di $-\infty$ si trasformano in intorni destri di $0$).

Dunque se $f > 0$ e $g > 0$ i risultati per il limite del prodotto 
sono conseguenza dei risultati analoghi per il limite della somma.
Cambiando segno ad una delle due funzioni o ad entrambe ci si può 
ricondurre al caso $f > 0$ e $g > 0$ quando le due funzioni assumono 
un segno costante in almeno un intorno del punto $x_0$.
Per il teorema della permanenza del segno questo è vero se 
$\ell_1\neq 0$ e $\ell_2\neq 0$: il limite del prodotto in questo caso 
è dunque $\ell_1\cdot \ell_2$.
Se invece $\ell_1=0$ e $\ell_2\in\RR$ sappiamo che $f(x)\to 0$ 
è equivalente a $\abs{f(x)}\to 0$ dunque in tal caso si può rimpiazzare $f(x)$ con $\abs{f(x)}\ge 0$
(gli eventuali punti in cui $f(x)=0$ sono irrilevanti e possono essere tolti 
dal dominio di $f$ per garantire $\abs{f}>0$) e ottenere che il limite 
del prodotto è $0$.
Lo stesso accade se $\ell_2=0$ con la funzione $g(x)$.

Per quanto riguarda il rapporto il teorema~\ref{th:isomorfismo}
ci dice che le proprietà additive dell'opposto diventano (tramite logaritmo)
proprietà moltiplicative del reciproco, almeno se siamo nell'ambito di numeri positivi.
Dunque se $f(x)\to \ell$ con $\ell>0$ 
allora $\frac{1}{f(x)} \to \frac{1}{\ell}$.
Se $\ell=0$ non possiamo concludere niente in quanto le proprietà 
additive a $-\infty$ si rispecchiano nelle proprietà moltiplicative 
in $0^+$, non in $0$. 
Dunque i risultati sul limite del rapporto discendono dai risultati 
sul limite del prodotto con il reciproco.
\end{proof}


Se dobbiamo calcolare un limite in cui compare un elevamento 
a potenza $f(x)^{g(x)}$ con base ed esponente variabile converrà 
scrivere
\[
 f(x)^{g(x)} = a^{g(x)\cdot \log_a f(x)}
\]
per poter applicare il teorema precedente al prodotto $g(x)\cdot \log_a f(x)$.

\begin{example}
  Si calcoli
  \[
  \lim_{x\to +\infty} \frac{2+x^2-x^3}{(x^2-x+2)^2}.
  \]
  \end{example}
  \begin{proof}[Svolgimento.]
  Per $x\to +\infty$ per il teorema sul limite del
  prodotto sappiamo che $x^2\to +\infty$ e
  $x^3\to +\infty$.
  Per il teorema sulla somma dei limiti
  sappiamo che $2+x^2\to +\infty$ ma
  a priori non possiamo applicare tale teorema
  al limite di $(2+x^2)-x^3$ in quanto
  $(+\infty)-(+\infty)$ è una forma indeterminata
  (non rientra nelle ipotesi di quel teorema).
  Bisogna allora intuire che le potenze di $x$
  con esponente maggiore sono preponderanti e vanno
  quindi messe in evidenza tramite
  manipolazioni algebriche. L'espressione
  di cui vogliamo calcolare il limite
  si può quindi riscrivere in questo modo:
  \begin{align*}
  \frac{2+x^2-x^3}{(x^2-x+2)^2}
  &= \frac{x^3 \enclose{\frac 2 {x^3}+\frac{1}{x}-1}}{x^4\enclose{1-\frac 1 x + \frac{2}{x^2}}^2}
  = \frac{1}{x}\cdot \frac{\frac 2 {x^3}+\frac{1}{x}-1}{\enclose{1-\frac 1 x + \frac{2}{x^2}}^2}.
  \end{align*}
  A questo punto l'espressione non presenta più forme indeterminate.
  Applicando i teoremi precedenti possiamo allora affermare che
  si ha
  \begin{align*}
  \lim_{x\to+\infty}\frac{1}{x}\cdot \frac{\frac 2 {x^3}+\frac{1}{x}-1}{\enclose{1-\frac 1 x + \frac{2}{x^2}}^2}
  &= \frac{1}{+\infty} \cdot \frac{\frac 2 {(+\infty)^3}+\frac{1}{+\infty}-1}{\enclose{1-\frac 1 {+\infty} + \frac{2}{(+\infty)^2}}^2}\\
  &= 0 \cdot \frac{0+0-1}{(1-0+0)^2} = 0\cdot (-1) = 0.
  \end{align*}
\end{proof}

L'aver definito le operazioni sulle quantità infinite
risulta in effetti comodo nello svolgimento dei limiti.
Bisogna però essere consapevoli che $\bar \RR$ non è un campo
e quindi le operazioni con i simboli $+\infty$ e $-\infty$
non rispettano molte delle regole che siamo abituati
ad avere sui numeri finiti.
Sarà quindi opportuno ricondursi immediatamente ad una espressione
che abbia senso in $\RR$, sulla quale potremo
applicare le manipolazioni algebriche con più tranquillità.
Per questo motivo in molti testi l'espressione intermedia in cui compaiono 
le operazioni eseguite sulle quantità $+\infty$ e $-\infty$ non è ritenuta valida
e si preferisce scrivere direttamente il risultato.
  
\begin{example}
Si calcoli il seguente limite nel campo complesso:
\[
\lim_{z\to 0} \enclose{\frac 1 {z} - \frac 1 {z^2-z}}. 
\]
\end{example}
\begin{proof}
  Anche in questo caso non possiamo applicare direttamente le regole 
  di calcolo del limite in quanto otterremmo la forma indeterminata 
  $\infty - \infty$.
  Possiamo però operare una semplice manipolazione algebrica
  per eliminare l'indeterminazione:
  \[
    \frac 1 {z} - \frac 1 {z^2-z}
    = \frac{z- 1 - 1}{z^2-z}
    = \frac{z-2}{z^2-z}
    \to \frac{0-2}{0^2-0} = \frac{-2}{0} = \infty 
    \qquad \text{per $z\to 0.$}
  \]
\end{proof}

\begin{comment} % non abbiamo ancora gli strumenti per fare questi esercizi
\begin{exercise}
  Calcolare 
  \[
  \lim_{x\to 0^+} x^x.
  \]
\end{exercise}

\begin{exercise}
  Trovare un esempio di funzioni $f(x)$ e $g(x)$ tali che 
  \[
     \lim_{x\to 0} f(x) = 0, \qquad 
     \lim_{x\to 0} g(x) = 0
  \]
  ma 
  \[
    \lim_{x\to 0} f(x)^{g(x)} \neq 1.
  \]
\end{exercise}
\end{comment}

\subsection{proprietà frequenti e definitive}

\begin{definition}[proprietà frequenti e definitive]
Diremo che un predicato $P(x)$ definito su un insieme $A\subset \RR$ 
di cui $x_0$ è punto di accumulazione vale 
\emph{definitivamente}%
\mymargin{definitivamente}%
\index{definitivamente} per $x\to x_0$ se
vale in un intorno di $x_0$ ovvero:
\[
  \exists U\in \B_{x_0}\colon \forall x \in A\cap U\setminus\ENCLOSE{x_0}\colon P(x).
\]
Diremo che $P(x)$ vale \emph{frequentemente}%
\mymargin{frequentemente}%
\index{frequentemente} per $x\to x_0$
se in ogni intorno di $x_0$ c'è almeno un punto $x\neq x_0$ 
in cui vale:
\[
  \forall U\in \B_{x_0}\colon \exists x\in A\cap U\setminus\ENCLOSE{x_0}
  \colon P(x).
\]
\end{definition}

Chiaramente se una proprietà vale definitivamente vale anche frequentemente
infatti se c'è un intorno $U$ su cui vale la proprietà per ogni altro intorno 
$V$ la proprietà risulta valida su $U\cap V$ che non è mai vuoto.
Se una proprietà vale frequentemente significa in particolare che vale per 
infiniti valori diversi in quanto se vale in punto $x\neq x_0$ 
posso sempre trovare un intorno $V$ di $x_0$ che non contiene $x$
e in tale intorno trovo un ulteriore punto in cui vale la proprietà. 
Iterando il procedimento posso trovare infiniti punti diversi su cui 
la proprietà è valida.

Le due proprietà sono complementari nel senso che
in base alle proprietà dei quantificatori logici vale 
la seguente relazione:
\[
  \text{non frequentemente $P(x)$} \iff
  \text{definitivamente non $P(x)$}
\]

Se due proprietà $P(x)$ e $Q(x)$ valgono definitivamente allora anche
$P(x)\land Q(x)$ vale definitivamente. Se invece valgono entrambe
frequentemente allora anche $P(x) \lor Q(x)$ vale frequentemente.

\begin{example}
La proprietà $x^3 - x > 1000 x^2 + 1$
vale definitivamente per $x\to +\infty$.
La proprietà $x>0$ vale frequentemente per $x\to 0$.
\end{example}


La definizione di limite $f(x) \to \ell$ per $x\to x_0$ 
potrebbe quindi enunciarsi così:
per ogni intorno $U$ di $\ell$ si ha $f(x)\in U$ definitivamente.
E la sua negazione è: esiste un intorno $U$ di $\ell$ per cui
frequentemente $f(x)\not\in U$.


\subsection{criteri di confronto}

\begin{theorem}[criteri di confronto]
\label{th:confronto}%
\index{teorema!del confronto}%
\index{limite!confronto}%
\index{teorema!dei due carabinieri}%
\index{carabineri!teorema dei}%
\mymark{***}%
Siano 
$f$, $g$, $h$ tre funzioni reali%
\mynote{Non è possibile fare confronti tra valori complessi, visto che
sui numeri complessi non abbiamo un ordinamento}
definite su uno stesso dominio $A\subset \RR$ 
con punto di accumulazione $x_0$
\mymargin{confronto tra limiti}%
\index{confronto tra limiti}
\begin{enumerate}
\item
Se per ogni $x\in A$ si ha
\[
f(x) \le g(x)
\]
e se entrambe le funzioni ammettono limite: $f(x) \to \ell_1$ 
e $g(x) \to \ell_2$ per $x\to x_0$
allora
\[
\ell_1 \le \ell_2.
\]

\item
Se per ogni $x\in A$ si ha:
\[
f(x) \le g(x)
\]
e se $f(x)\to +\infty$ allora anche $g(x) \to +\infty$ per $x\to x_0$.
Viceversa se $f(x) \le g(x)$ e $g(x) \to -\infty$ allora anche $f(x) \to -\infty$.

\item
(teorema dei carabinieri)
Se per ogni $x\in A$ vale
\mymargin{teorema dei carabinieri}%
\index{teorema!dei carabinieri}%
\[
f(x) \le h(x) \le g(x)
\]
 e se le due
funzioni $f$ e $g$ hanno lo stesso limite: $f(x) \to \ell$ e $g(x)\to \ell$
per $x\to x_0$
allora anche $h(x) \to \ell$.
\end{enumerate}
\end{theorem}
%
\begin{proof}
\mymark{**}
\begin{enumerate}
\item
Se per assurdo fosse $\ell_1 > \ell_2$
la funzione $f(x)-g(x)$ avrebbe limite positivo e per il teorema
della permanenza del segno dovrebbe essere definitivamente positiva. 
Ma questo contraddice l'ipotesi $f(x)-g(x)\le 0$. 

\item 
Se non fosse $g(x)\to +\infty$ significa che 
esiste $\alpha \in \RR$ tale che $g(x)<\alpha$ frequentemente. 
Ma visto che definitivamente $f(x)>\alpha$ troviamo 
che frequentemente si ha $f(x)>g(x)$ in contrasto con l'ipotesi 
$f(x)\le g(x)$.

\item
Se $f$ e $g$ hanno lo stesso limite $\ell$ significa che per ogni
$U$ intorno di $\ell$ si ha definitivamente $f(x)\in U$ e $g(x)\in U$.
Visto che $U$ è un intervallo anche $h(x)$ è definitivamente in $U$ 
e quindi $h(x)\to \ell$.
\end{enumerate}
\end{proof}

\begin{example}
  Dimostrare che 
  \[
    \lim_{x\to +\infty} \enclose{2x - \lfloor x\rfloor} = +\infty. 
  \]
\end{example}
\begin{proof}[Svolgimento.]
  Sappiamo che $\lfloor x\rfloor \le x$ dunque 
  \[
    2x - \lfloor x \rfloor \ge 2x -x = x \to +\infty.  
  \]
  Dunque per confronto si ottiene il risultato richiesto.
\end{proof}

\begin{corollary}[limitata per infinitesima]%
\label{cor:limitata_per_infinitesima}%
\mymark{**}%
  Se $f(x)$ è una funzione limitata e $g(x)\to 0$ per 
  $x\to x_0$ allora anche
  \[
    f(x)\cdot g(x) \to 0 \qquad \text{per $x\to x_0.$} 
  \]
\end{corollary}
%
\begin{proof}
  Se $f$ è limitata significa che esiste $R>0$ tale che $\abs{f(x)}\le R$
  per ogni $x$ nel dominio di $f$.
  Ma allora 
  \[
     0\le \abs{f(x)\cdot g(x)} = \abs{f(x)}\cdot \abs{g(x)} 
     \le R \abs{g(x)} \to R\cdot 0 = 0.
  \]
  Per confronto deduciamo che $\abs{f(x)\cdot g(x)}\to 0$ 
  che è equivalente alla tesi.
\end{proof}

\begin{exercise}
  Mostrare che 
  \[
   \lim_{x\to +\infty} \frac{x-\lfloor x \rfloor}{x} = 0.  
  \]
\end{exercise}
%\input{chapters/AnalisiUno-02-funzioni.tex}

\section{successioni}
\label{sec:successioni}

Una \emph{successione}%
\mymargin{successione}%
\index{successione} in un insieme $X$ è una
funzione $\vec a\colon \NN \to X$.
L'insieme delle funzioni $\NN \to X$ viene usualmente indicato
con $X^\NN$ e potremmo dunque scrivere $\vec a \in X^\NN$. 
In effetti una successione $\vec a$ può essere interpretata
come una sequenza infinita di elementi di $X$:
\mynote{%
Utilizziamo il grassetto per evidenziare il fatto
che $\vec a$ non è un numero ma una \emph{lista} (o vettore) di numeri.
Nella scrittura a mano non è possibile usare il grassetto, ma potremmo
sottolineare il nome della variabile scrivendo $\underline a$ invece che $\vec a$.
In alternativa si potrebbe scrivere $\stackrel{\rightarrow}a$ oppure evitare
qualunque distinzione e scrivere più semplicemente $a$.}
\[
  \vec a = (a_0, a_1, a_2, \dots, a_n, \dots )
\]
dove si intende
\[
   a_n = \vec a(n).
\]
Le componenti $a_n$ si chiamano \emph{termini} della successione.
I numeri $n$ si chiamano, invece, \emph{indici}.
L'intera
successione $\vec a$ può essere indicata con $(a_n)_{n=0}^\infty$
oppure $(a_n)_n$ oppure,
più semplicemente, con $a_n$ quando sia chiaro che si intende l'intera
successione $\vec a$ e non un singolo termine della stessa.%

Per noi il caso più interessante sarà quello delle \emph{successioni reali}
$a_n\in \RR$ cioè il caso $X=\RR$. Considereremo però anche il caso di
\emph{successioni complesse} $a_n\in \CC$ (dunque $X=\CC$) perché questo
potrà essere utile in alcune situazioni.%
\mynote{In alcuni testi le successioni vengono indicate
con la notazione $\ENCLOSE{a_n}$ che però è fuorviante in quanto
una successione in $X$ non è semplicemente un sottoinsieme di $X$:
l'ordine in cui vengono presi gli elementi è rilevante.}

\subsection{limite di successione}

Visto che $\vec a \colon \NN\to\RR$ (o in $\CC$) è una funzione 
con dominio $\NN\subset \RR$ 
e visto che $+\infty$ è l'unico punto di accumulazione di $\NN$ 
sarà possibile considerare il limite
\[
  \ell = \lim_{n\to +\infty} \vec a(n)
\]
che potremmo anche scrivere con una delle seguenti notazioni:
\[
\ell = \lim \vec a = \lim_n a_n = \lim_{n\to +\infty} a_n
\]
o più concisamente:
\[
  a_n \to \ell. 
\]

Esplicitando la definizione astratta di limite osserviamo che se $(\alpha,+\infty]$
è un intorno di $+\infty$ con $\alpha>0$ la sua intersezione con $\NN$ (il dominio della funzione)
è l'insieme $\ENCLOSE{n\in \NN\colon n> N}$ dove $N=\lfloor \alpha \rfloor$ è 
un numero naturale. Dunque se $\ell \in \RR$ 
la condizione $a_n \to \ell$ si esplicita nel modo seguente:
\begin{equation}\label{eq:limite_successione_convergente}
\forall \eps>0\colon \exists N\in \NN\colon n>N\implies \abs{a_n-\ell} < \eps.  
\end{equation}
La condizione $a_n\to +\infty$ si scrive
\[
  \forall \alpha\in \RR \colon \exists N\in \NN \colon n>N \implies a_n > \alpha  
\]
e infine $a_n\to-\infty$ diventa
\[
  \forall \alpha\in \RR \colon \exists N\in \NN \colon n>N \implies a_n < -\alpha.    
\]

\begin{definition}[carattere di una successione]
Sia $a_n$ una successione a valori reali o complessi
e si consideri il limite 
\[
  \lim_n a_n.  
\]
Se tale limite esiste diremo che la successione $a_n$ è 
\emph{regolare}%
\mymargin{regolare}%
\index{regolare},
\index{successione!regolare}%
se il limite esiste ed è finito diremo che la successione è 
\emph{convergente}%
\mymargin{convergente}%
\index{convergente}%
\index{successione!convergente}
se il limite è infinito diremo che la successione è 
\emph{divergente}%
\mymargin{divergente}%
\index{divergente}%
\index{successione!divergente}
se il limite non esiste diremo infine che la successione è
\emph{indeterminata}%
\mymargin{indeterminata}%
\index{indeterminato}%
\index{successione!indeterminata}.

Abbiamo dunque le seguenti alternative
\begin{enumerate}
 \item la successione è convergente (ha limite finito);
 \item la successione è divergente (ha limite infinito);
 \item la successione è indeterminata (non ha limite).
\end{enumerate}
Determinare il \emph{carattere}
\mymargin{carattere di una successione}%
\index{carattere!di una successione}%
\index{successione!carattere}%
di una successione
significa specificare a quale delle tre categorie appartiene.
\end{definition}

\begin{exercise}
Una successione complessa $z_n\in \CC$ potrà essere scritta
nella forma $z_n = x_n + i y_n$ dove $x_n$ e $y_n$ sono successioni
reali. Si può allora verificare che $z_n\to z$ per $z\in \CC$ se e solo se
$x_n\to x$ e $y_n\to y$ dove $z=x+ iy$ con $x,y\in \RR$.
\end{exercise}

Si faccia attenzione al fatto che una successione $a_n\in \RR \subset \CC$
può essere interpretata sia come successione reale che come successione complessa.
Le condizioni di convergenza in $\RR$ o $\CC$ sono allora equivalenti. Ma
se $a_n \to \infty$ (in $\bar \CC$) significa che $\abs{a_n}\to +\infty$
e può capitare che $a_n$ non abbia limite né $+\infty$
né $-\infty$ in quanto potrebbe frequentemente cambiare di segno
(un esempio è $a_n = (-n)^n$).

In generale potremmo avere delle successioni definite solamente 
su un sottoinsieme $\NN$ dei numeri naturali. 
Finché la successione è definita in un intorno di $+\infty$ (cioè 
da un certo $n_0$ in poi) questo non ha nessuna conseguenza sul 
limite per $n\to +\infty$ (grazie alla località del limite, 
teorema~\ref{th:localita_limite}).

\begin{example}
  La successione $a_n = 1/n$ è definita per $n\in \NN$ ma $n\neq 0$.
  Ciò non toglie che possiamo studiarne il limite come qualunque altra
  successione. Per evidenziare il fatto che il primo indice è $n=1$
  si potrà usare la notazione $(a_n)_{n=1}^\infty$.
\end{example}
 
\subsection{successioni limitate}
\label{sec:successione_limitata}%

Se abbiamo una successione $a_n$ reale possiamo anche considerare gli operatori:
\[
  \sup_n a_n, \qquad 
  \inf_n a_n, \qquad 
  \max_n a_n, \qquad 
  \min_n a_n 
\]
che sono definiti come per qualunque altra funzione. 
Sappiamo che $\sup$ e $\inf$ esistono sempre (in $\bar\RR$) mentre $\max$ e $\min$
potrebbero non esistere.

Anche il concetto di limitatezza per una successione è ereditato dallo stesso 
concetto valido per le funzioni.
Una successione $a_n$ (a valori reali o complessi) si dice essere 
\emph{limitata}%
\mymargin{limitata}%
\index{limitato} se 
l'insieme $\{\abs{a_n}\colon n \in \NN\}$ è limitato. Cioè se 
\[
\sup_n \abs{a_n} < +\infty.  
\]
\mynote{si noti che anche quando $a_n$ è complessa la successione 
dei moduli $\abs{a_n}$ è reale (e non negativa).
Vedremo nel seguito che le successioni a valori complessi non creano 
molte più difficoltà di quanto ne creino le successioni che assumono 
valori negativi. 
Il vero vantaggio si avrà con le successioni a valori positivi, 
per questo spesso si considera il modulo di una successione.
}
In caso contrario la successione si dice essere \emph{illimitata}%
\mymargin{illimitata}%
\index{illimiatato}.
Queste definizioni si applicano tali e quali alle successioni di numeri 
complessi (rimpiazzando il valore assoluto con il modulo).

Se la successione ha valori reali potremo anche parlare di 
\emph{limitatezza superiore} quando $\sup a_n <+\infty$ 
e \emph{limitatezza inferiore} quando $\inf a_n > -\infty$.


\begin{example}
Si consideri $a_n = \frac{1}{n+1}$ definita per $n\in \NN$.
Allora
\[
  \sup a_n = \max a_n = 1, \qquad
  \inf a_n = 0, \qquad \text{non esiste }\min a_n.
\]
\end{example}
\begin{proof}
Per ogni $n \in \NN$ si ha $n+1\ge 1$ e quindi $a_n = 1/(n+1) \le 1$.
Visto poi che $a_0 = 1$ si ottiene immediatamente che $\max a_n = 1$
e di conseguenza $\sup a_n = 1$.

Per verificare che $\inf a_n = 0$ dobbiamo verificare innanzitutto
che $0$ è minorante, e questo è vero in quanto $a_n = 1/(n+1)> 0$ essendo $n+1\ge 1 \ge 0$.
Inoltre dobbiamo verificare che per ogni $\eps >0$ esiste $n\in \NN$ tale
che $a_n < 0 + \eps = \eps$. Questo succede se $1/(n+1) < \eps$ ovvero
se $n > 1/\eps -1$ ad esempio per $n=\lceil 1/\eps\rceil$.
Abbiamo dunque verificato che $\inf a_n = 0$.
Il minimo di $a_n$ non esiste perché se esistesse dovrebbe essere uguale
all'estremo inferiore cioè dovrebbe essere $0$. Ma questo è impossibile
perché per ogni $n\in \NN$ si ha $a_n = 1/(n+1)\neq 0$.
\end{proof}

Visto che l'insieme $\NN$ su cui sono definite le successioni 
ha un unico punto di accumulazione $+\infty$ se la successione 
è convergente non potrà essere illimitata, come viene espresso nel seguente.

\begin{theorem}[limitatezza delle successioni convergenti]
\mymark{**}%
Se una successione (reale o complessa) è convergente allora è anche limitata.
Se una successione reale diverge a $+\infty$ allora è inferiormente limitata,
se diverge a $-\infty$ è superiormente limitata.
\end{theorem}
%
\begin{proof}
  Per la definizione di limite~\eqref{eq:limite_successione_convergente} 
  se $a_n\to \ell$ con $\ell$ finito sappiamo 
  che scelto $\eps=1$ dovrà esistere $N\in \NN$ tale che 
  \[
      \forall n>N\colon \abs{a_n - \ell} < 1.
  \]
  Osserviamo ora che gli indici $n$ per cui $n\le N$ sono in numero finito 
  (in effetti sono $N+1$) e quindi esiste
  \[
   M = \max_{n\le N} \abs{a_n} 
   = \max \ENCLOSE{\abs{a_0}, \abs{a_1}, \dots , \abs{a_N}}.  
  \]
  Dunque scelto $R=\max\ENCLOSE{\abs{\ell}+1,M}$ 
  se $n\le N$ si ha certamente $\abs{a_n}\le M \le R$
  e se $n>N$ si ha comunque, per disuguaglianza triangolare,
  \[
  \abs{a_n} \le \abs{a_n-\ell} + \abs{\ell} < 1+ \abs{\ell} \le R.  
  \]
  Dunque nel complesso risulta $\sup_n \abs{a_n}\le R$ e la successione 
  è limitata.

  Se $a_n\to +\infty$ per la definizione di limite 
  scelto $(0,+\infty]$ come intorno di $+\infty$ 
  deve esistere un indice $N\in \NN$ tale che se $n>N$ si ha $a_n>0$. 
  Ma allora posto $R=\min\ENCLOSE{0, a_0,\dots,a_N}$
  si avrà $a_n\ge R$ per ogni $n\in \NN$ e dunque la successione 
  risulta essere inferiormente limitata.

  Dimostrazione analoga si fa nel caso $a_n\to -\infty$.
\end{proof}


% \begin{theorem}[prodotto di limitata per infinitesima]
% \mymark{**}%
% \mymargin{prodotto limitata per infinitesima}%
\index{prodotto limitata per infinitesima}%
% Se $a_n$ è una successione limitata e $b_n\to 0$ allora
% $a_n\cdot b_n \to 0$ (il risultato vale sia per successioni reali 
% che per successioni complesse).
% \end{theorem}
% %
% \begin{proof}
%   Se $a_n$ è limitata significa che esiste $R>0$ tale che $\abs{a_n}\le R$ per
%   ogni $n\in \NN$.
%   Se $b_n\to 0$ sappiamo che anche $\abs{b_n}\to 0$, dunque
%   \[  
%     0
%     \le \abs{a_n\cdot b_n} 
%     = \abs{a_n}\cdot \abs{b_n} 
%     \le R\cdot \abs{b_n}\to R\cdot 0 = 0.
%   \]
%   Per il teorema dei due carabinieri deduciamo che $\abs{a_n\cdot b_n}\to 0$ 
%   e quindi $a_n\cdot b_n \to 0$.
% \end{proof}

\subsection{successioni monotòne}

Le definizioni~\ref{def:monotonia} si applicano alle successioni. 
Abbiamo quindi già definito cosa significa che una successione è 
crescente, decrescente, strettamente crescente, strettamente decrescente,
monotona, costante. Ad esempio, una successione $a_n$ si dice essere 
crescente se $n\ge m$ implica $a_n \ge a_m$.

La verifica della monotonia di una successione può essere però dimostrata 
più facilmente rispetto al caso generale delle funzioni in quanto 
possiamo utilizzare il principio di induzione, come mostrato 
nel seguente teorema.


\begin{theorem}[successioni monotòne]
\mymark{***}
Una successione $a_n$ è
\begin{enumerate}
\item \emph{crescente}: se per ogni $n\in \NN$ si ha $a_{n+1} \ge a_n$;
\item \emph{decrescente}: se per ogni $n\in \NN$ si ha $a_{n+1} \le a_n$;
\item \emph{strettamente crescente}: se per ogni $n\in \NN$ si ha $a_{n+1}>a_n$;
\item \emph{strettamente decrescente}: se per ogni $n\in \NN$ si ha
$a_{n+1}<a_n$;
\end{enumerate}
\end{theorem}
%
\begin{proof}
  Consideriamo ad esempio la prima condizione (funzione crescente).
Ovviamente se $a_n$ è crescente si ha $a_{n+1}\ge a_n$ in quanto $n+1 > n$.
Viceversa supponiamo che per ogni $n\in \NN$ si abbia $a_{n+1}\ge a_n$.  Allora
chiaramente $a_1\ge a_0$, $a_2\ge a_1 \ge a_0$, $a_3 \ge a_2 \ge a_1 \ge a_0$...
Per induzione si può quindi dimostrare che  $a_n \ge a_{n-1} \ge \dots \ge a_2
\ge a_1$.

Gli altri casi si svolgono in maniera analoga.
\end{proof}

\begin{example}
  La successione $a_n = n!$ è crescente 
  in quanto per ogni $n$ si ha $(n+1)! = (n+1)\cdot n! \ge n!$.
\end{example}

La monotònia di una successione è di estrema rilevanza in quanto,
come enunciato nel teorema seguente, le successioni monotòne sono regolari, 
cioè hanno sempre limite (finito o infinito). 
Questo teorema verrà utilizzato molte volte, in particolare quando vogliamo 
dimostrare che una successione ha limite ma non conosciamo esplicitamente il valore 
del limite. 
Il primo esempio notevole si ha nel Teorema~\ref{th:5767684} dove definiremo 
la costante di Nepero $e$ come il limite di una particolare successione crescente.

\begin{theorem}[regolarità delle successioni monotòne]
Le successioni monotòne sono regolari.
Più precisamente se $a_n$ è crescente allora $\lim a_n = \sup a_n$ 
mentre se $a_n$ è decrescente $\lim a_n = \inf a_n$.
\end{theorem}
\begin{proof}
In realtà questo teorema è un caso particolare del 
Teorema~\ref{th:limite_monotona} se ricordiamo che una successione 
$a_n$ non è altro che una funzione $f(n)=a_n$ definita sui numeri naturali.
E il limite a $+\infty$ è un limite sinistro.
Vista però l'importanza di questo risultato possiamo ripetere la dimostrazione 
in questo caso specifico.

Per fissare le idee supponiamo che la successione $a_n$ sia crescente e dimostriamo 
che $\lim a_n = \ell$ con $\ell=\sup a_n$.
Per la definizione di limite dobbiamo verificare che scelto un qualunque intorno $U$ 
di $\ell$ si ha definitivamente $a_n\in U$.
Dimostriamo anzi una condizione più forte e cioè che $a_n$ sta definitivamente 
in un intorno sinistro di $\ell$ cioè che per ogni $q<\ell$ esiste $N$ tale che 
per ogni $n\ge N$ si ha $a_n\in (q,\ell]$ (si noti che $\ell$ può essere finito o $+\infty$ 
e quanto abbiamo scritto vale in entrambi i casi).
Che valga $a_n\le \ell$ è ovvio in quanto $\ell=\sup a_n$ è, per definizione, un maggiorante 
di $a_n$. Inoltre $\ell$ è il minimo dei maggioranti e quindi preso 
$q<\ell$ sappiamo che $q$ non è un maggiorante ovvero deve esistere $N$ tale che 
$a_N > q$. Ma, essendo $a_n$ crescente, sappiamo che per ogni $n\ge N$ si ha 
$a_n \ge a_N >q$ e questo conclude la dimostrazione.
\end{proof}

%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%

\subsection{successioni ricorsive}

Le successioni ricorsive sono le successioni
definite per induzione (tramite il teorema~\ref{th:induzione}):
\[
 \begin{cases}
   a_0 = \alpha \\
   a_{n+1} = f(a_n).
 \end{cases}
\]
Si potrebbe affrontare ora il capitolo~\ref{ch:successioni_ricorsive}
per uno studio di questo tipo di successioni.
La prima parte di quel capitolo è infatti accessibile con le nozioni
che sono state sviluppate finora.
La seconda parte richiederà invece degli strumenti più avanzati.

\subsection{la costante di Nepero}

\begin{figure}
  \begin{center}
    \begin{tikzpicture}[x=4.0cm,y=1.8cm]
    	\draw[thick,->] (-0.5,0) -- (1.2,0);
      \draw[thick,->] (0,-0.2) -- (0,3.0);
      %
      \draw[domain=-0.5:1.05,smooth,variable=\x,thick,blue] plot
      ({\x}, {exp(\x)});
      \draw[blue] (1.0,-0.05) -- (1.0,{exp(1.0)})
      -- (-0.2, {exp(1.0)}) node[left]{$e^q$};
      \draw (-0.2,1) node[left]{$\scriptstyle 1$} -- (0,1);
      \draw (0.2,-0.05) node[below]{$\frac 1 n$} -- (0.2,1.2)
      -- (-0.05,1.2) node[left]{$\scriptstyle 1+\frac q n$};
      \draw (0.4,-0.05) node[below]{$\frac 2 n$} -- (0.4,1.44)
      -- (-0.2,1.44) node[left]{$\scriptstyle\enclose{ 1+\frac q n}^2$};
      \draw (0.6,-0.05) node[below]{$\frac 3 n$} -- (0.6,1.738)
      -- (-0.05,1.738) node[left]{$\scriptstyle\enclose{1+\frac q n}^3$};
      \draw (0.8,-0.05) node[below]{$\rule{0mm}{2mm}\dots$} -- (0.8,2.0736)
      -- (-0.2,2.0736) node[left]{$\vdots$};
      \draw (1.0,-0.05) node [below] {$1$} -- (1.0,2.48832)
      -- (-0.05,2.48832) node[left]{$\scriptstyle\enclose{1+\frac q n}^n$};
      \draw[thick] (0,1) -- (0.2,1.2)
      -- (0.4,1.44) -- (0.6,1.738)
      -- (0.8,2.0736) -- (1.0,2.48832);
    \end{tikzpicture}
  \end{center}
  \caption{L'interesse composto.
  Se dividiamo l'intervallo $[0,1]$
  in $n$ parti (in figura $n=5$), al passo zero
  partiamo con un capitale pari ad $1$ e ad ogni
  passo di ampiezza $\frac 1 n$ moltiplichiamo
  il nostro capitale per $1+\frac q n$ (supponendo
  di avere un interesse pari a $q$ che
  nel tempo $\frac 1 n$ ci paga quindi $\frac q n$
  volte il nostro capitale).
  Dopo
  $n$ passi, cioè al tempo $1$, avremo
  un capitale pari a $\enclose{1+\frac q n}^n$.
  Se $n\to+\infty$ questa quantità tende ad $e^q$.}
  \label{fig:nepero}
\end{figure}


La funzione esponenziale è legata ad un modello di crescita che si trova spesso
in natura: la \emph{crescita esponenziale}%
\mymargin{crescita esponenziale}%
\index{crescita!esponenziale}.
Prendiamo come esempio una popolazione di batteri che cresce senza
limitazioni di spazio e di nutrimento oppure
pensiamo alla crescita di un capitale dovuto ad una rendita finanziaria.

Supponiamo che una popolazione che al tempo $t_0=0$
ammonta ad un certo numero $c$ di batteri, al tempo
$t>0$ raggiunga una numerosità $q(t,c)$.
Se lascio crescere la popolazione per un ulteriore
tempo $s>0$ troverò al tempo $t+s$ la stessa
popolazione che avrei al tempo $s$ se al tempo
zero fossi partito con la popolazione $q(t)$:
\[
  q(t+s,c) = q(s,q(t,c)).
\]
L'equazione precedente si chiama proprietà
di \emph{semigruppo}
\index{semigruppo}%
continuo.
Ma fissato $t$ la popolazione $q(t,c)$ deve
essere proporzionale a $c$ perché ogni batterio
ha la sua discendenza indipendentemente dalla numerosità
totale della popolazione. In pratica
si deve avere $q(t,c) = k(t) \cdot c$ per una opportuna
funzione $k(t)$ che non dipende da $c$.
Dunque
\[
  q(t+s,c)
  = q(s,q(t,c))
  = k(s) \cdot q(t,c)
  = k(s) \cdot k(t) \cdot c
\]
da cui
\[
  k(t+s) = k(s) \cdot k(t).
\]
In base al teorema~\ref{th:isomorfismo}
possiamo affermare
che $k(t)$ è una funzione esponenziale $k(t)=a^t$
per una qualche costante $a$.
La costante $a$ può essere determinata mediante la formula:
\[
  a = k(1) = \frac{q(1,c)}{c}
\]
ma questa espressione non ha un preciso significato fisico in quanto
dipende dall'unità di tempo scelta.

La costante a cui possiamo dare significato è invece l'aumento relativo
istantaneo della popolazione. Possiamo infatti supporre che
se lasciamo la popolazione crescere per un tempo $\Delta t$ molto piccolo,
si otterrà un aumento di popolazione proporzionale al tempo $\Delta t$
e alla popolazione:%
\mynote{stiamo qui anticipando il concetto di derivata}
\begin{equation}\label{eq:488464}
  q(\Delta t,c) = c + r c \Delta t = (1+r \Delta t) c.
\end{equation}
La costante $r$ rappresenta quindi l'aumento
relativo istantaneo della popolazione (nel caso dell'investimento
$r$ sarebbe il tasso di interesse istantaneo).
Questa definizione ha senso
quando $\Delta t$ è piccolo in quanto non tiene conto del fatto che
nell'intervallo di tempo $[t,t+\Delta t]$ la popolazione che si
è aggiunta genera anch'essa nuova popolazione (ovvero l'interesse
accumulato genera anch'esso interesse\mynote{%
In effetti la scoperta della costante $e$
è dovuta a Jacob Bernoulli (1655--1705) vedi note storiche 
a pag~\pageref{note:Bernoulli}}).

Per calcolare l'aumento della popolazione su tempi ``grandi'' possiamo
suddividere gli intervalli temporali in $n$ intervallini di ampiezza
$\Delta t$ e applicare in ognuno di essi la relazione \eqref{eq:488464}.
Si trova:
\begin{align*}
 q(\Delta t,c) &= c(1+r\Delta t) \\
 q(2\Delta t,c) &= q(\Delta t,c) (1+r\Delta t)  = c(1+r\Delta t)^2\\
 &\vdots \\
 q(n\Delta t) &= c(1+r\Delta t)^n.
\end{align*}
Dunque, ponendo $\Delta t=t/n$ si ha
\[
  q(t,c) = c\enclose{1+r\frac{t}{n}}^n
\]
in particolare per $t=1/r$ si ottiene:
\[
  q(1/r,c) = c\enclose{1+\frac{1}{n}}^n
\]
e ricordando che $q(t,c)=c a^t$ otteniamo:
\[
  a^{\frac 1 r} = \enclose{1+\frac{1}{n}}^n.
\]
Se per $n\to +\infty$ (che corrisponde a $\Delta t \to 0$)
la quantità sul lato destro tende ad un numero $e$ (che chiameremo costante
di Nepero) avremo allora
\[
  a = e^r, \qquad q(t,c) = c e^{rt}
\]
che è la relazione che lega le due costanti $a$ e $r$ che definiscono
la crescita esponenziale.

Risulta in effetti valido il seguente.

\begin{theorem}[costante di Nepero]
\mymark{**}%
\label{th:5767684}
La successione
\[
  a_n = \enclose{1+\frac 1 n}^n
\]
è crescente e limitata, dunque è convergente.
\end{theorem}
%
Per dimostrare il teorema precedente ci serve 
preliminarmente il seguente risultato.
%
\begin{theorem}[disuguaglianza di Bernoulli]
  \label{th:disuguaglianza_bernoulli}%
  \mymark{**}%
  \mymargin{disuguaglianza di Bernoulli}%
  \index{Bernoulli!disuguaglianza di}%
  \index{disuguaglianza!di Bernoulli}%
  Se $x > -1$ e $n\in \NN$ si ha
  \begin{equation}
  \label{eq:bernoulli}
  (1+x)^n \ge 1 + nx.
  \end{equation}
  \end{theorem}
  %
  \begin{proof}
  \mymark{**}
  Dimostriamo che vale~\eqref{eq:bernoulli}
  per induzione su $n$.
  Per $n=0$ la disequazione \eqref{eq:bernoulli} diventa $1\ge 1$
  ed è quindi verificata.
  Se~\eqref{eq:bernoulli}
  è verificata per un certo $n$
  moltiplicando ambo i membri per $1+x > 0$ si ottiene
  \[
  (1+x)^{n+1} \ge (1+x) (1+nx) = 1 + (n+1)x + n x^2
  \ge 1 + (n+1)x
  \]
  che è proprio la disuguaglianza~\eqref{eq:bernoulli}
  con $n+1$ al posto di $n$.
  \end{proof}
%
\begin{proof}[Dimostrazione del teorema~\ref{th:5767684}]
Dimostriamo innanzitutto che $a_n$ è crescente, cioè che
per ogni $n\ge 2$ si ha $a_n \ge a_{n-1}$.
E' chiaro che $a_n>0$ per ogni $n$,
quindi ci riconduciamo a
verificare che $\frac{a_n}{a_{n-1}} \ge 1$.

Si ha
\begin{align*}
\frac{a_n}{a_{n-1}}
&= \frac{\enclose{1+\frac 1 n}^n}{\enclose{1+\frac 1 {n-1}}^{n-1}}
= \frac{\enclose{\frac{n+1}{n}}^n}{\enclose{\frac{n}{n-1}}^{n-1}}\\
&= \enclose{\frac{n+1}{n}\cdot\frac{n-1}{n}}^n \cdot \frac{n}{n-1}
= \enclose{\frac{n^2- 1}{n^2}}^n \cdot \frac{n}{n-1}
\end{align*}
Osserviamo ora che la disuguaglianza di Bernoulli, 
teorema~\ref{th:disuguaglianza_bernoulli},
garantisce
\[
  \enclose{\frac{n^2 -1}{n^2}}^n
  = \enclose{1-\frac{1}{n^2}}^n
  \ge 1 - \frac{n}{n^2} = 1 - \frac{1}{n} = \frac{n-1}{n}
\]
da cui si ottiene, come volevamo, $a_n / a_{n-1} \ge 1$ cioè
$a_n$ è crescente.

Se ora consideriamo la successione
\[
  b_n = \enclose{1+\frac 1 n}^{n+1}
\]
osserviamo che si ha
\[
  b_n = \enclose{1+\frac 1 n}^n \cdot \enclose{1+\frac 1 n}
   = a_n\cdot \enclose{1+\frac 1 n} > a_n.
\]
Per dimostrare che $a_n$ è limitata sarà quindi sufficiente dimostrare
che $b_n$ è superiormente limitata. Vedremo ora che $b_n$ è decrescente (e quindi $a_n \le b_n \le b_1$ è superiormente limitata).

Procediamo in maniera analoga a quanto fatto per $a_n$:
\begin{align*}
\frac{b_{n-1}}{b_n}
& = \frac{\enclose{1+\frac{1}{n-1}}^n}{\enclose{1+\frac{1}{n}}^{n+1}}
  = \frac{\enclose{\frac{n}{n-1}}^n}{\enclose{\frac{n+1}{n}}^{n+1}}
  = \enclose{\frac{n}{n-1}\cdot\frac{n}{n+1}}^{n+1}\cdot\frac{n-1}{n} \\
& = \enclose{\frac{n^2}{n^2-1}}^{n+1} \cdot \frac{n-1}{n}
  = \enclose{1 + \frac{1}{n^2-1}}^{n+1} \cdot \frac{n-1}{n}.
\end{align*}
In base alla disuguaglianza di Bernoulli otteniamo
\[
  \enclose{1 + \frac{1}{n^2-1}}^{n+1}
  \ge 1 + (n+1) \cdot \frac{1}{n^2-1}
  = 1 + \frac{1}{n-1} = \frac{n}{n-1}.
\]
Mettendo insieme le due stime si ottiene dunque $b_{n-1}/b_n \ge 1$
che è quanto ci rimaneva da dimostrare.
\end{proof}

E' quindi giustificata la seguente.

\begin{definition}[costante di Nepero]
\mymark{***}
Definiamo la \emph{costante di Nepero}%
\mymargin{costante di Nepero}%
\index{costante!di Nepero}%
\index{$e$}%
\mynote{John Napier (1550-1617) vedi note storiche a pag~\pageref{nota:Nepero}}%
\[
  e = \lim_{n\to +\infty} \enclose{1+\frac 1 n}^n,
  \qquad n\in\NN.
\]
\end{definition}

Sapendo che
\[
  \enclose{1+\frac 1 n}^n \le e \le \enclose{1+\frac 1 n}^{n+1}
\]
e ponendo $n=1$ otteniamo $2\le e \le 4$.

\begin{exercise}\label{ex:4876765}
Posto $a_n = \frac{n^n}{n!}$ mostrare che $\frac{a_{n+1}}{a_n} \to e$.
\end{exercise}


\begin{theorem}[limiti che si riconducono al numero $e$]
\mymargin{limiti che si riconducono al numero $e$}%
\index{limiti che si riconducono al numero $e$}
Si ha 
\[
\lim_{x\to 0}  \enclose{1 + x}^{\frac 1 {x}} = e.
\]
\end{theorem}
%
\begin{proof}
  Iniziamo col dimostrare che 
  \begin{equation}\label{eq:2373793}
    \lim_{x\to +\infty} \enclose{1+\frac 1 x}^x = e.
  \end{equation}
  Ogni numero reale $x$ è compreso tra due interi consecutivi:
  \[
      \lfloor x \rfloor \le x \le \lfloor x\rfloor + 1
  \]
  e dunque
  \[
    1+\frac{1}{\lfloor x\rfloor +1 } 
    \le 1 + \frac 1 x 
    \le 1 + \frac 1 {\lfloor x\rfloor} 
  \]
  da cui 
  \begin{equation}\label{eq:48675248}
    \enclose{1+\frac{1}{\lfloor x\rfloor +1 }}^{\lfloor x\rfloor} 
    \le \enclose{1 + \frac 1 x }^x
    \le \enclose{1 + \frac 1 {\lfloor x\rfloor}}^{\lfloor x\rfloor +1}. 
  \end{equation}
  Per calcolare il limite della espressione a sinistra 
  operiamo il cambio di variabile $n=\lfloor x\rfloor + 1$ per 
  ottenere:
  \begin{align*}
  \lim_{x\to+\infty} \enclose{1+\frac{1}{\lfloor x\rfloor +1 }}^{\lfloor x\rfloor}
  &= \lim_{n\to +\infty} \enclose{1+\frac 1 n}^{n-1}\\
  &= \lim_{n\to +\infty} \frac{\enclose{1+\frac 1 n}^{n}}{1+\frac 1 n}
   = \frac{e}{1} = e.
  \end{align*}
  Similmente per quanto riguarda il limite della espressione a destra 
  si può operare il cambio di variabile $n=\lfloor x\rfloor$:
  \begin{align*}
    \enclose{1 + \frac 1 {\lfloor x\rfloor}}^{\lfloor x\rfloor +1}
    &= \lim_{n\to+\infty} \enclose{1+\frac 1 n}^{n+1} \\
    &= \lim_{n\to+\infty} \enclose{1+\frac 1 n}^n 
    \cdot \enclose{1 + \frac 1 n} 
    = e \cdot 1 = e.
  \end{align*}
  Dunque per il teorema dei due carabinieri otteniamo
  che anche l'espressione 
  al centro in~\eqref{eq:48675248} tende ad $e$.
  Come conseguenza, tramite il cambio di variabile $x\mapsto \frac 1 x$
  si ottiene 
  \[
  \lim_{x\to 0^+}\enclose{1+x}^{\frac 1 x} = e.  
  \]

  Consideriamo ora il limite per $x\to -\infty$ 
  della solita espressione. 
  Tramite il cambio di variabile $y=-x$ si ha 
  \begin{align*}
  \lim_{x\to -\infty} \enclose{1+\frac{1}{x}}^x 
  &= \lim_{y\to +\infty} \enclose{1 - \frac 1 y}^{-y}
   = \lim_{y\to +\infty} \enclose{\frac {y-1} y}^{-y}\\
  &= \lim_{y\to +\infty} \enclose{\frac{y}{y-1}}^y
   = \lim_{y\to +\infty} \enclose{1 + \frac{1}{y-1}}^y\\
  &= \lim_{y\to +\infty} \enclose{1 + \frac{1}{y-1}}^{y-1}
    \cdot\enclose{1+\frac 1 {y-1}} 
    = e\cdot 1 = e.\\
  \end{align*}
  Di conseguenza, facendo il cambio di variabile $x\mapsto \frac 1 x$ 
  si ottiene
  \[
  \lim_{x\to 0^-} \enclose{1+x}^{\frac 1 x} = e.
  \]
  Mettendo insieme limite destro e limite sinistro si ottiene 
  infine il limite completo per $x\to 0$. 
\end{proof}
%
\begin{corollary}%
\label{cor:limite_notevole_ex}%
\mymark{**}%
Per ogni $x\in \RR$ si ha
\[
  \lim_{n\to +\infty} \enclose{1+ \frac x n}^n = e^x.
\]
\end{corollary}
%
\begin{proof}
Infatti, per il teorema precedente, posto $a_n = x/n$ si ha
\[
\lim_{n\to +\infty}\enclose{1+\frac x n}^{\frac n x} = e.
\]
Ma allora
\[
\enclose{1+ \frac x n}^n = \enclose{\enclose{1+\frac x n}^{\frac n x}}^x
\to e^x
\]
\end{proof}

\begin{definition}[logaritmi naturali]
Vedremo che il numero $e$ risulta essere una base naturale per la funzione
esponenziale e di conseguenza per il logaritmo. Il logaritmo in base
$e$ viene chiamato \emph{logaritmo naturale}%
\mymargin{logaritmo naturale}%
\index{logaritmo!naturale} e viene indicato con $\ln = \log_e$.
\end{definition}

\mynote{%
In alcuni testi si utilizza l'operatore $\log$, indicato senza una base esplicita,
ma la definizione non è completamente condivisa.
In certi testi (per lo più in ambito matematico)
si definisce $\log  = \ln = \log_e$,
in altri testi si considera $\log = \log_{10}$.
}

\begin{corollary}[limiti notevoli]\label{cor:limite_notevole_e}
\mymark{*}%
Si ha
\begin{gather}
 \lim_{x\to 0} \frac{\ln \enclose{1+ x}}{x} = 1; \\
 \lim_{x\to 0} \frac{e^x-1}{x} = 1.
\end{gather}
\end{corollary}
%
\begin{proof}
Per quanto riguarda il logaritmo ci si riconduce al teorema precedente
osservando che:
\[
  \frac{\ln(1+x)}{x}
  = \ln \enclose{(1+x)^{\frac 1 {x}}}
  \to \ln e = 1.
\]
Per l'esponenziale ci si riconduce al logaritmo
osservando che posto
\[
  y = e^x-1
\]
se $x\to 0$ anche $y\to 0$ e quindi si ha:
\[
\frac{e^{x}-1}{x} = \frac{y}{\ln(1+y)} \to 1.
\]

\end{proof}

\begin{exercise}
Mostrare che
\begin{gather*}
  \lim_{n\to+\infty} n^n\cdot \enclose{\frac{n+1}{n^2+1}}^n = e; \\
  \lim_{n\to+\infty} n\cdot \ln\enclose{1 + \frac 1 n} = 1; \\
  \lim_{n\to+\infty} \enclose{1-\frac{n+1}{n!}}^{(n-1)!} = \frac 1 e; \\
  \lim_{n\to+\infty} n \cdot \enclose{\sqrt[n]{2}-1} = \ln 2.
\end{gather*}
\end{exercise}

%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
\subsection{criteri del rapporto e della radice}

Succede spesso di dover determinare il limite
del rapporto di due successioni che tendono entrambe a infinito
oppure entrambe a zero.
In queste situazioni il teorema del limite del rapporto non
si applica in quanto siamo di fronte ad una forma indeterminata.
Dovremo quindi capire quale delle due successioni
tende a infinito o a zero ``più velocemente''.

I teoremi che seguono si basano (in maniera più o meno implicita)
sull'andamento della successione geometrica:
\[
  a_n = q^n
\]
dove $q>0$ è una costante fissata.
Dalle proprietà della funzione esponenziale 
sappiamo che se $q>1$ si ha $q^n\to \infty$.
Se $q=1$ chiaramente $q^n=1\to 1$
e se $q<1$ si ha $q^{-1}>1$ e quindi $q^{-n} \to +\infty$
da cui $q^n \to 0$.

\begin{theorem}[criterio del rapporto]
\label{th:criterio_rapporto}
\index{criterio!del rapporto per le successioni}
\index{rapporto!criterio del}
  Sia $a_n$ una successione reale a termini positivi
  $a_n > 0$ tale che esista il limite del rapporto di due termini consecutivi:
  \[
     \frac{a_{n+1}}{a_n} \to \ell \in [0,+\infty].
  \]
  Se $\ell < 1$ allora $a_n \to 0$, se $\ell >1$ allora $a_n \to +\infty$.
\end{theorem}
%
%
% \begin{proof}\mynote{%
%   la dimostrazione di questo teorema si potrebbe fare in maniera
%   molto simile alla dimostrazione del teorema~\ref{th:criterio_radice}
%   senza tirare in ballo il teorema~\ref{th:criterio_cesaro} che è decisamente più complesso.
%   }
% Grazie al teorema~\ref{th:criterio_cesaro} sappiamo
% che $\sqrt[n]{a_n}\to \ell$ e quindi il risultato
% segue direttametne dal teorema~\ref{th:criterio_radice}.
% \end{proof}
%

\begin{proof}
Supponiamo sia $\ell<1$. Posto $q=(1+\ell)/2$ si ha $\ell < q < 1$ 
e posto $\eps=q-\ell>0$ per la definizione di limite $\frac{a_{n+1}}{a_n}\to \ell$ 
dovrà esistere un $N\in \NN$ tale
che per ogni $n\ge N$ si abbia:
\[
  \frac{a_{n+1}}{a_n} < \ell + \eps = q
\]
ovvero $a_{n+1} < q \cdot a_n$. In particolare si avrà:
\begin{align*}
  a_{N+1} &< q \cdot a_N \\
  a_{N+2} &< q \cdot a_{N+1} < q^2\cdot a_N \\
  a_{N+3} &< q \cdot a_{N+2} < q^3\cdot a_N \\
  \vdots
\end{align*}
ed è chiaro che per induzione potremo dimostrare che per
ogni $k\in \NN$ si ha
\[
  a_{N+k} < q^k\cdot a_N.
\]
Osserviamo però che $q^k \cdot a_N \to 0$ per $k\to +\infty$
in quanto $q<1$ e quindi $q^k \to 0$. 
Dunque, tolti i primi $N$ termini, la successione $a_n$ tende a zero. 
Ma i primi $N$ termini non influenzano né il carattere né il limite 
della successione e quindi l'intera successione $a_n$ tende a zero.

Il caso $\ell>1$ si fa in maniera analoga. Si sceglie $q$ tale
che $1<q<\ell$ e si trova, in maniera analoga al caso precedente,
che per un certo $N\in \NN$ e per ogni $k\in \NN$ si ha
\[
  a_{N+k} > q^k \cdot a_N \to +\infty.
\]
\end{proof}

Osserviamo che, nel teorema precedente (ma anche nel criterio della radice teorema~\ref{th:criterio_radice}),
non si può concludere alcunché nel
caso in cui sia $\ell = 1$.
Ad esempio le due successioni $a_n = 1/n$ e $b_n = n$
hanno limiti diversi ($a_n \to 0$, $b_n\to +\infty$) ma per entrambe
il limite del rapporto di termini consecutivi tende ad $\ell=1$.

\begin{exercise}
Mostrare che
\begin{gather*}
  \lim \frac{n!}{n^n} = 0 \\
  \lim \frac{(2n)!}{(2n)^n} = +\infty
\end{gather*}
\end{exercise}

\begin{theorem}[criterio della radice]
\label{th:criterio_radice}%
\mymark{***}%
\mymargin{criterio della radice}%
\index{criterio!della radice per successioni}%
Sia $a_n$ una successione a termini non negativi, $a_n\ge 0$, tale che
\[
  \sqrt[n]{a_n} \to \ell
\]
con $\ell \in \bar \RR$.
Allora se $\ell<1$ si ha $a_n \to 0$ se invece $\ell > 1$ si ha $a_n \to +\infty$.
\end{theorem}
%
\begin{comment}
\begin{proof}
\mymark{**}
Consideriamo prima il caso $\ell < 1$.
Se $\lim \sqrt[n]{a_n} = \ell$ significa che per ogni $\eps>0$ la successione
$\sqrt[n]{a_n}$ risulta definitivamente minore di $\ell +\eps$.
Scegliendo opportunamente $\eps$ (ad esempio $\eps = (1-\ell)/2$) si potrà
avere $q = \ell+\eps < 1$. Dunque avremo definitivamente $\sqrt[n]{a_n}< q$
ovvero $a_n < q^n$. Per ipotesi $a_n\ge 0$
e quindi, tolto un numero finito di termini, si ottiene $0 \le a_n < q^n \to 0$
da cui $a_n \to 0$ (in quanto l'aver tolto un numero finito di termini non
cambia né il carattere né il limite della successione).

Se $\ell>1$ si potrà procedere in maniera analoga. Esisterà $q$ con $1 < q < \ell$ tale che definitivamente $\sqrt[n]{a_n} > q$ da cui $a_n > q^n \to +\infty$.
\end{proof}
\end{comment}

\begin{proof}
  Si può osservare che
  \[
    a_n = \enclose{\sqrt[n]{a_n}}^n
     = e^{n \cdot \ln \sqrt[n]{a_n}}.
  \]
  Se $\ell <1$ allora il logaritmo tende ad un numero negativo,
  l'argomento dell'esponenziale tende a $-\infty$ e quindi l'esponenziale tende a zero.

  Se invece $\ell>1$ il logaritmo tende ad un numero positivo e quindi l'esponenziale tende a $+\infty$.
\end{proof}

%%%%%
%%%%%
\section{ordini di infinito, equivalenza asintotica}
%%%%%
%%%%%

\begin{definition}[ordine di infinito/infinitesimo]%
  \label{def:ordine_infinito}%
  \mymark{***}%
  \mymargin{ordine di infinito/infinitesimo}%
\index{ordine di infinito/infinitesimo}%
  \index{ordine!di infinito}%
  \index{infinito}%
  \index{infinitesimo}%
  Sia $A\subset \RR$, $f,g\colon A \to (0,+\infty)$.
  Sia $x_0\in \bar \RR$ un punto di accumulazione di $A$.
  \begin{enumerate}
  \item
  Diremo che
  per $x\to x_0$ la funzione $f$ è \emph{molto più piccola}
  della funzione $g$ e scriveremo $f(x) \ll g(x)$ se vale
  \mymargin{$\ll$}%
\index{$\ll$}
  \[
  \frac{f(x)}{g(x)} \to 0, \qquad \text{per $x\to x_0$}
  \]
  diremo invece che $f$ è \emph{molto più grande}
  di $g$ e scriveremo $f(x) \gg g(x)$ se
  \mymargin{$\gg$}%
\index{$\gg$}
  \[
  \frac{f(x)}{g(x)} \to +\infty, \qquad \text{per $x\to x_0$.}
  \]
  \item
  Diremo infine che $f$ e $g$
  sono \emph{asintoticamente equivalenti}%
\mymargin{equivalenza asintotica}%
\index{asintoticamente equivalenti}
  \mymargin{equivalenza asintotica}%
\index{equivalenza!asintotica}%
  per $x\to x_0$
  e scriveremo $f(x) \sim g(x)$ se
  \mymargin{$\sim$}%
\index{$\sim$}
  \[
  \frac{f(x)}{g(x)} \to 1, \qquad \text{per $x\to x_0.$}
  \]
  \end{enumerate}
\end{definition}
  
Ad esempio è facile verificare che se $\alpha > \beta > 0$
allora $x^\alpha \gg x^\beta$ per $x\to +\infty$
mentre $x^\alpha \ll x^\beta$ per $x\to 0^+$.
Analogamente se $a>b>1$ allora $a^x\gg b^x$ per $x\to +\infty$
mentre $a^x \ll b^x$ per $x\to -\infty$.

E' molto facile verificare che le relazioni
$\ll$ e $\gg$ sono una l'inversa dell'altra
e soddisfano la proprietà transitiva
mentre la relazione $\sim$ soddisfa la proprietà simmetrica
e la proprietà transitiva.

\begin{theorem}[ordini di infinito]
\label{th:ordine_infinito}%
\mymargin{ordini di infinito}%
\index{ordini di infinito}%
\mymark{***}%
Siano $a>1$ e $\alpha>0$. Per $n\to +\infty$, $n\in\NN$
si ha
\[
  n^\alpha \ll a^n \ll n! \ll n^n
\]
e per $x\to +\infty$, $x\in \RR$ si ha 
\[
\log_a x \ll x^\alpha \ll a^x.
\]
\end{theorem}
%
\begin{proof}
\mymark{**}
Cominciamo col mostrare che $a^n \ll n!$
applicando il criterio del rapporto alla successione $\frac{a^n}{n!}$:
\[
\frac{\displaystyle \frac{a^{n+1}}{(n+1)!}}{\displaystyle \frac{a^n}{n!}}
= \frac{a^{n+1}}{a^n}\cdot \frac{n!}{(n+1)!}
= a \cdot \frac {1}{n + 1} \to 0 < 1.
\]
Dunque si ha, come richiesto, $a^n / n! \to 0$.
Si procede in modo analogo per mostrare che $n! \ll n^n$:
\begin{align*}
\frac{(n+1)!}{n!}\cdot \frac{n^n}{(n+1)^{n+1}}
&= (n+1) \cdot \enclose{\frac{n}{n+1}}^n \frac {1}{n+1}\\
&= \frac{1}{\enclose{1+\frac 1 n}^n} \to \frac 1 e < 1.
\end{align*}
  
Per dimostrare che
$n^\alpha \ll a^n$
si può procedere con il criterio del rapporto, come nei casi precedenti:
\[
\frac{(n+1)^\alpha}{n^\alpha}\cdot \frac{a^n}{a^{n+1}}
= \frac 1 a \cdot \enclose{\frac{n+1}{n}}^\alpha \to \frac 1 a \cdot 1^\alpha = \frac 1 a < 1
\]
da cui $n^\alpha / a^n \to 0$.

Per $x\in \RR$,
cerchiamo di ricondurci ad una successione a valori interi.
Osserviamo che si ha
\[
\lfloor x \rfloor
\le x
\le \lfloor x \rfloor + 1
\]
da cui, per monotonia,
\[
\lfloor x \rfloor^\alpha
\le x^\alpha
\le (\lfloor x \rfloor + 1)^\alpha
= \lfloor x \rfloor^\alpha \enclose{1+ \frac{1}{\lfloor x \rfloor}}^\alpha
\]
e
\[
a^{\lfloor x \rfloor}
\le a^{x}
\le a^{\lfloor x \rfloor + 1}
= a \cdot a^{\lfloor x \rfloor}.
\]
Dunque
\[
\frac{\lfloor x \rfloor^\alpha}{a \cdot a^{\lfloor x \rfloor}}
\le \frac{x^\alpha}{a^{x}}
\le \frac{\lfloor x \rfloor^\alpha \enclose{1+ \frac{1}{\lfloor x \rfloor}}^\alpha}
    {a^{\lfloor x \rfloor}}.
\]
Ma ora, se $x\to +\infty$ sapendo che $n = \lfloor x\rfloor \to +\infty$ 
possiamo effettuare un cambio di variabile nel limite
\[
\lim_{x\to +\infty} \frac{\lfloor x \rfloor^\alpha}{a^{\lfloor x \rfloor}} 
= \lim_{n\to+\infty} \frac{n^\alpha}{a^n} = 0
\]
da cui segue che $\frac{x^\alpha}{a^{x}}\to 0$.

Per dimostrare l'ultima relazione, $\log_a x\ll x^\alpha$,
operiamo il cambio di variabile $y = \alpha \cdot \log_a x$
cosicché $a^y = x^\alpha$.
Notiamo che se $x\to +\infty$
anche $y \to +\infty$.
Dunque, per le proprietà precedenti,
sappiamo che $y \ll a^y$ e dunque
\[
\frac{\log_a x}{x^\alpha}
= \frac{1}{\alpha}\cdot\frac{y}{a^{y}} \to 0.
\]
\end{proof}

Le notazioni e gli
ordini di infinito individuati nel teorema precedente
sono strumenti molto utili nel calcolo dei limiti.

L'equivalenza asintotica
si mantiene per prodotto e rapporto:
se $f\sim F$ e $g\sim G$ allora
\[
 f \cdot g \sim F \cdot G,
 \qquad
 \frac{f}{g} \sim \frac{F}{G}.
\]
Osserviamo inoltre che se
$f \sim g$ e se $f\to \ell$ allora
anche $g\to \ell$.
Se poi $\ell\in(0,+\infty)$
la relazione $f\sim \ell$ è equivalente ad $f\to \ell$.

Per quanto riguarda la somma
è facile verificare che se $f\ll g$ allora
$(f+g) \sim g$ in quanto
\[
  \frac{f + g}{g} = \frac{f}{g} + 1 \to 1.
\]

In un limite in cui compaiono somme di termini
di ordini diversi potremo allora raccogliere i termini di ordine
massimo per individuare il limite, come facciamo
nel seguente.

\begin{example}
Calcolare il limite
\[
\lim_{n\to+\infty}
\frac{2n^4 + 3^n - 3 \ln n}{n! - 3\sqrt n}.
\]
\end{example}
\begin{proof}[Svolgimento.]
Si ha
\[
\frac{2n^4 + 3^n - 3 \ln n}{n! - 3\sqrt{n}}
= \frac
{3^n \cdot \enclose{2\frac{n^4}{3^n}+ 1 - 3\frac{\ln n}{3^n}}}
{n!\cdot \enclose{1-3\frac{\sqrt n}{n!}}}
\]
e ricordando che risulta (teorema~\ref{th:ordine_infinito})
\[
n^4 \ll 3^n, \qquad
\ln n \ll 3^n, \qquad
\sqrt n \ll n!, \qquad
3^n \ll n!
\]
avremo
\[
\frac{2n^4 + 3^n - 3 \ln n}{n! - 3\sqrt{n}}
\sim \frac{3^n}{n!} \to 0.
\]
\end{proof}


\begin{exercise}
Calcolare i seguenti limiti
\begin{gather*}
  \lim_{n\to +\infty} \frac{\displaystyle \ln\sqrt{n^2+n^n}}
  {\displaystyle e^{1 + \ln n}\cdot \ln(n^2-n\sqrt n)}, \qquad
  \lim_{n\to +\infty} \frac{\sqrt{n! + 2^n}}{3^n}, \\
  \lim_{n\to +\infty} \frac{\sqrt{(2n)!}}{n^n}, \qquad
  \lim_{n\to +\infty} \sqrt[n]{e^n + \sqrt{10^n}}.
\end{gather*}
\end{exercise}

\begin{exercise}
  Dimostrare che $\sqrt[n]{n}\to 1$ per $n\to +\infty$.
\end{exercise}



%%%%%%%%%%%
%%%%%%%%%%%
\section{successioni estratte}
%%%%%%%%%%%
%%%%%%%%%%%

\begin{definition}[sottosuccessione]
\mymark{*}
Se $a_n$ è una successione e $n_k$ è una successione strettamente crescente i cui valori sono numeri naturali, allora la successione
$b_k = a_{n_k}$ si dice essere una \emph{sottosuccessione}%
\mymargin{sottosuccessione}%
\index{sottosuccessione} di $a_n$
(o anche \emph{successione estratta} da $a_n$).
\end{definition}

Ricordando che una successione $a_n$ non è altro che una funzione
$\vec a\colon \NN \to \RR$, la successione $n_k$ corrisponde ad una funzione
$\vec n\colon \NN \to \NN$ e la sottosuccessione $a_{n_k}$ corrisponde alla
funzione composta $\vec a \circ \vec n$.

Si osservi che nella definizione precedente la variabile $n$ rappresenta
una variabile muta quando scriviamo la successione $a_n$, ma
rappresenta anche il nome della successione fissata $n_k$.
Questo sovraccarico
di significato è voluto e se usato correttamente rende più semplice
le notazioni, in quanto la successione $n_k$ viene sostituita alla
variabile $n$, con lo stesso nome, nella successione $a_n$.
La sottosuccessione $a_{n_k}$ risulta essere una successione nella variabile $k$, non nella variabile $n$.

\begin{example}
Sia $a_n = n^2$ la successione dei quadrati perfetti:
\begin{center}
\begin{tabular}{l|rrrrrrrrr}
$n$   & $0$ & $1$ & $2$ & $3$ & $4$  & $5$  & $6$  & \dots \\ \hline
$a_n$ & $0$ & $1$ & $4$ & $9$ & $16$ & $25$ & $36$ & \dots
\end{tabular}
\end{center}
Consideriamo la successione dei numeri pari $n_k = 2k$.
la corrispondente sottosuccessione dei quadrati perfetti
$b_k = a_{n_k}$
rappresenta la successione dei quadrati dei numeri pari:
\begin{center}
\begin{tabular}{l|rrrrrrrrr}
$k$       & $0$ & $1$ & $2$ & $3$ & $4$  & $5$  & $6$  & \dots \\ \hline
$n_k$ & $0$ & $2$ & $4$ & $6$ & $8$ & $10$ & $12$ & \dots \\
$a_{n_k}$ & $0$ & $4$ & $16$ & $36$ & $64$ & $100$ & $144$ & \dots
\end{tabular}
\end{center}
Si ha in pratica
  $b_k = a_{n_k} = a_{2k} = (2k)^2$.

Abbiamo in effetti \emph{estratto} alcuni dei termini della successione
originaria.
\end{example}

\begin{example}
Se $a_n = (-1)^n$ e $n_k=2k$ allora $a_{n_k} = 1$.
Vediamo quindi che una successione irregolare
può contenere una sottosuccessione regolare.
\end{example}

Osserviamo che se $\vec n\colon \NN\to \NN$ è una
funzione strettamente crescente
(cioè $n_k=\vec n(k)$ è una successione strettamente crescente di indici)
allora posto $A=\vec n(\NN)=\ENCLOSE{n_k\colon k\in \NN}$ si ha che
$\vec n \colon \NN \to A$ è una bigezione. Quindi $A$ è un insieme infinito.
Viceversa dato un qualunque insieme infinito $A\subset \NN$ esiste una
unica successione $\vec n\colon \NN \to A$ bigettiva e strettamente crescente:
basterà porre, per induzione,
$n_0 = \min A$, $n_1 = \min \ENCLOSE{n\in A \colon n > n_0}$
e, in generale,
 $n_{k+1} = \min\ENCLOSE{ n\in A \colon n > n_k}$.

Dunque possiamo identificare le sottosuccessioni di una successione
$\vec a \colon \NN \to \RR$ con le restrizioni ai sottoinsiemi infiniti di $\NN$.
Nell'esempio precedente, si è considerata la sottosuccessione
di tutti i termini con indice pari $n_k=2k$ per ottenere la sottosuccessione
$a_{n_k} = a_{2k}$. Si può equivalentemente pensare di prendere l'insieme di
tutti i numeri pari $A=2\NN$ e considerare la successione ristretta ai soli
indici pari:
\[
  a_0, a_2, a_4, \dots
\]
Se rinumeriamo gli indici pari usando tutti i numeri naturali otteniamo
la sottosuccessione $b_k=a_{n_k}$:
\[
  b_0 = a_0,\ b_1 = a_2,\ b_2 = a_4,\ \dots,\ b_k = a_{n_k},\ \dots
\]

\begin{lemma}[estratte monotone]%
\label{lem:estratte_monotone}%
Ogni successione $a_n\in \RR$ ha una estratta $a_{n_k}$ monotona.
Inoltre se $\sup a_n = +\infty$ c'è una estratta $a_{n_k}$
strettamente crescente che tende a $+\infty$.
\end{lemma}
%
\begin{proof}
Consideriamo l'insieme $P$ dei punti di ``picco'', ovvero degli indici
di quei termini della successione che sono maggiori o uguali a tutti i termini
seguenti:
\[
  P = \ENCLOSE{n\in \NN\colon m\ge n \implies a_n\ge a_m}.
\]
Se $P$ è finito
significa che esiste un indice $n_1\in \NN$ tale
che non ci sono picchi da $n_1$ in poi. In particolare $n_1$ non è un punto di
picco
quindi deve esistere $n_2>n_1$ tale che $a_{n_2}>a_{n_1}$.
Ma neanche $n_2$ è un punto di picco quindi deve esistere $n_3>n_2$ tale
che $a_{n_3}>a_{n_2}$... procedendo induttivamente si riesce quindi a definire
una successione $n_k$ di indici tali che $a_{n_k}$ risulta essere strettamente
crescente.

In particolare se $\sup a_n = +\infty$ siamo nella situazione precedente 
perché chiaramente in tal caso $P$ è vuoto visto che per ogni $n\in \NN$ 
deve esistere $m\in \NN$ tale che $a_m > \max\ENCLOSE{a_0, a_1, \dots a_n}$
e certamente $m>n$.

Se, viceversa, $P$ è infinito allora elencando in ordine i suoi elementi otterremo
una successione $n_1 < n_2 < n_3, \dots$ di indici ognuno dei quali corrisponde ad un valore
di picco. 
Se $j>k$ si ha dunque $n_j>n_k$ ed essendo $n_k\in P$ significa che
$a_{n_j} \le a_{n_k}$. 
Dunque la successione $a_{n_k}$ risulta essere decrescente.
\end{proof}


\begin{theorem}[Bolzano-Weierstrass]\label{th:Bolzano}
\label{th:bolzano_weierstrass}%
\mymark{***}%
\mymargin{Bolzano-Weierstrass}%
\index{Bolzano-Weierstrass}%
\index{teorema!di Bolzano-Weierstrass}%
Ogni successione $a_n$ ha una estratta regolare.
Più precisamente se $a_n$ è una successione limitata
allora esiste una sottosuccessione
$a_{n_k}$ convergente.
Se $a_n$ è una successione non limitata allora 
esiste una estratta $a_{n_k}$ divergente.
\end{theorem}
%
\begin{proof}
\mymark{***}
Cominciamo con il caso reale $a_n\in \RR$.
Il lemma~\ref{lem:estratte_monotone} garantisce 
che esiste una estratta $a_{n_k}$ monotona. 
Ma per il teorema~\ref{th:limite_monotona} concludiamo 
immediatamente che $a_{n_k}$ ha limite.
Se $a_n$ è limitata anche $a_{n_k}$ è limitata e quindi 
in tal caso il limite è finito e dunque la successione 
estratta è convergente.

Se $a_n$ non è superiormente limitata il lemma 
ci garantisce che l'estratta tende a $+\infty$ 
e dunque è divergente.
Per simmetria se $a_n$ non è inferiormente limitata 
esiste una estratta che tende a $-\infty$ e quindi anche in
questo caso l'estratta è divergente.

Se $a_n$ è una successione di numeri complessi, si potrà scrivere
$a_n = x_n + i y_n$ con
$x_n$ e $y_n$ successioni reali. Se $a_n$ è limitata significa che $\abs{a_n}$
è superiormente limitata. Ma risulta $\abs{x_n} \le \abs{a_n}$ e
$\abs{y_n}\le \abs{a_n}$ quindi se $a_n$ è limitata anche la parte reale
$x_n$ e la parte immaginaria $y_n$ sono successioni limitate.
Allora $x_n$ ammette una sotto-successione convergente $x_{n_k}$.
Ma $y_{n_k}$ è anch'essa limitata e quindi anch'essa ammette una
sotto-sotto-successione $y_{n_{k_j}}$ convergente.
Dunque la sotto-sotto-successione $a_{n_{k_j}}$ è convergente.

Se $a_n\in \CC$ non è limitata, applicando il teorema al suo modulo $\abs{a_n}$
troviamo che c'è una estratta $a_{n_k}$ tale che $\abs{a_{n_k}}\to +\infty$.
Ma questo significa che $a_{n_k}\to \infty \in \bar \CC$.
\end{proof}

%% \begin{comment}%% SECONDO METODO DIAGONALE DI CANTOR
%% 
%% Il seguente teorema è molto importante dal punto di vista
%% culturale, ma non verrà utilizzato nella teoria seguente.
%% 
%% \begin{theorem}[Cantor: secondo metodo diagonale]
%% \label{th:cantor_secondo}%
%% \mymargin{non numerabilità dei reali}%
%% \index{non numerabilità dei reali}%
%% \index{secondo metodo diagonale di Cantor}%
%% \index{Cantor}%
%% \index{teorema!di Cantor}%
%% L'insieme dei numeri reali non è numerabile: $\#\RR > \#\NN$.
%% \end{theorem}
%% %
%% \begin{proof}
%% E' sufficiente dimostrare che $\#[0,1] > \#\NN$ in quanto
%% chiaramente $\#\RR \ge \#[0,1]$.
%% Supponiamo per assurdo che esista una funzione biettiva $a\colon \NN \to [0,1]$.
%% Questa funzione corrisponde dunque ad una successione $a_n$.
%% Consideriamo l'intervallo $[0,1]$ e dividiamolo in tre intervalli  di lunghezza $1/3$: $[0,1/3]$, $[1/3,2/3]$, $[2/3,1]$. Il punto $a_0$ non può stare in tutti e tre questi intervalli. Sia $[A_0,B_0]$ un intervallo (dei tre) che non contiene $a_0$: $a_0 \not \in [A_0,B_0]$.
%% Dividiamo anche $[A_0,B_0]$ in tre intervalli di lunghezza $1/9$.
%% Almeno uno di questi tre intervalli, che chiamiamo $[A_1,B_1]$,
%% non contiene $a_1$: $a_1 \not \in [A_1,B_1]$.
%% Procediamo così all'infinito in maniera simile al teorema precedente.
%% Otterremo due successioni $A_n$, $B_n$ che soddisfano queste proprietà:
%% \begin{enumerate}
%% \item $A_n$ crescente, $B_n$ decrescente;
%% \item $0\le A_n \le B_n \le 1$;
%% \item $a_n \not \in [A_n, B_n]$;
%% \item $B_n - A_n = 1/3^{n+1}$.
%% \end{enumerate}
%% 
%% Essendo $A_n$ monotona e limitata, essa ha limite finito $\lim A_n = \ell$.
%% Fissato $n$ osserviamo che per ogni $k\ge n$ si ha
%% \[
%%   A_n \le A_k \le b_k \le B_n
%% \]
%% passando al limite in $k$ (con $n$ fissato) si ottiene
%% \[
%%   A_n \le \ell \le B_n
%% \]
%% che significa che $\ell \in [A_n, B_n]$ per ogni $n\in \NN$
%% (in particolare $\ell \in [0,1]$).
%% Visto che invece $a_n \not \in [A_n, B_n]$ risulta che per
%% ogni $n\in \NN$ si ha $\ell \neq a_n$.
%% Dunque il numero $\ell$ non è un termine della successione $a_n$
%% ovvero la funzione $a\colon \NN \to [0,1]$ non è suriettiva.
%% \end{proof}
%% \end{comment}


%%%%%%%%%%%%
%%%%%%%%%%%%
\subsection{punti limite}
%%%%%%%%%%%%
%%%%%%%%%%%%

\begin{theorem}[ponte di collegamento tra limiti di funzione e limiti di successione]%
\label{th:ponte}%
\mymark{***}%
Sia $A \subset \RR$, $f\colon A \to \RR$, sia $x_0$ un punto di accumulazione di $A$ e sia
$\ell \in [-\infty, +\infty]$.
Le due seguenti condizioni sono equivalenti:
\begin{enumerate}
\item $\displaystyle \lim_{x\to x_0} f(x) = \ell$;
\item per ogni successione $a_n\to x_0$ con $a_n\in A\setminus\ENCLOSE{x_0}$ risulta
\[
\lim_{n\to+\infty} f(a_n) = \ell. 
\]
\end{enumerate}
\end{theorem}
%
\begin{proof}
\mymark{***}
Se per $x\to x_0$ si ha $f(x)\to \ell$ e se $a_n \to x_0$ con $a_n\in A\setminus\ENCLOSE{x_0}$ la successione $f(a_n)$ non è altro che la composizione
della funzione $f$ con la funzione $n\mapsto a_n$. Si può quindi applicare
il teorema sul limite della funzione composta per ottenere che $f(a_n)\to \ell$.

Supponiamo viceversa di sapere che per ogni successione $a_n\to x_0$ si ha $f(a_n)\to \ell$. Vogliamo mostrare allora che $f(x)\to \ell$. Lo facciamo per assurdo: supponiamo che esista un intorno $U$ di $\ell$ tale che preso un qualunque intorno $V$ di $x_0$ non si abbia $f((A\setminus\ENCLOSE{x_0})\cap V)\subset U$.
Possiamo considerare per ogni $n\in \NN$ degli intorni $V_n$ sempre più piccoli. Ad esempio nel caso $x_0 \in \RR$ potremo scegliere $V_n = (x_0-1/n, x_0+1/n)$, nel caso $x_0 = +\infty$ si potrà scegliere $V_n = (n,+\infty]$ e nel caso $x_0=-\infty$ si sceglierà $V_n = [-\infty, -n)$.
Se per assurdo $f((A\setminus\ENCLOSE{x_0}\cap V_n))$ non fosse contenuto in $U$
significherebbe che per ogni $n\in\NN$ esisterebbe $a_n \in (A\setminus\ENCLOSE{x_0})\cap V_n$ tale che $f(a_n)\not \in U$. Ma allora $a_n$ risulterebbe essere una successione in
$A\setminus \ENCLOSE{x_0}$ con limite $x_0$
(in quanto per ogni intorno di $x_0$ esiste un $N$ tale che $V_N$ sia contenuto in tale intorno e per ogni $n>N$ si ha $V_n\subset V_N$)
ma $f(a_n)$ non potrebbe avere limite $\ell$
(essendo fuori dall'intorno $U$).
Ma questo nega l'ipotesi e conclude quindi la dimostrazione del teorema.
\end{proof}
\begin{proposition}[proprietà caratteristica della convergenza]
  \label{prop:convergenza}
Sia $f\colon A\subset \RR\to \RR$ e $x_0$ punto di accumulazione di $A$.
Sia $\ell\in \bar \RR$.
Se per ogni $a_n\to x_0$, $a_n\in A\setminus\ENCLOSE{x_0}$
esiste una estratta $a_{n_k}$ tale che $f(a_{n_k})\to \ell$ 
allora $f(x)\to \ell$ per $x\to x_0$.
\end{proposition}
%
\begin{proof}
  Se per assurdo non fosse $f(x) \to \ell$
  esisterebbe un intorno $U\in \B_\ell$
  per cui frequentemente $f(x) \not \in U$.
  Questo significa che esiste una successione
  $a_n\to x_0$ con $a_n\neq x_0$ tale che $f(a_n)\not \in U$.
  Ma allora da $f(a_n)$
  non è possibile estrarre una sottosuccessione
  che abbia limite $\ell$, e questo è contrario alle
  ipotesi.
\end{proof}

\begin{definition}[punti limite, limite superiore, limite inferiore]
  Sia $f\colon A\subset \RR \to \RR$ una funzione e $x_0\in \bar \RR$ 
  un punto di accumulazione per $A$.
  Una quantità $\ell\in \bar\RR$ si dice essere
  un \emph{punto limite}%
\mymargin{punto limite}%
\index{punto!limite} di $f(x)$ per $x\to x_0$ se 
  per ogni $U$ intorno di $\ell$ si ha $f(x)\in U$ 
  frequentemente per $x\to x_0$.
  
  Se denotiamo con $L\subset \bar\RR$ l'insieme
  dei punti limite possiamo definire il \emph{limite superiore} e il
  \emph{limite inferiore}
  \mymargin{limite superiore/inferiore}%
\index{limite!superiore/inferiore}
  rispettivamente come
  \[
  \limsup_{x\to x_0} f(x) = \sup L, \qquad
  \liminf_{x\to x_0} f(x) = \inf L.
  \]
\end{definition}
  
\begin{proposition}[base numerabile di intorni]%
  \label{prop:base_numerabile}%
  Per ogni $\ell\in \bar \RR$ esiste una successione $U_n$ di intorni di $\ell$ 
  con queste proprietà:
  \begin{enumerate}
    \item $U_{n+1}\subset U_n$;
    \item per ogni $U$ intorno di $\ell$ esiste $n\in \NN$ tale che $U_n\subset U$;
    \item se $a_n\in U_n$ allora $a_n\to \ell$.
  \end{enumerate}
\end{proposition}
\begin{proof}
Possiamo esplicitamente definire gli intorni $U_n$ come segue:
\[
  U_n = 
  \begin{cases}
    \openinterval{\ell-\frac 1 n}{\ell+\frac 1 n} & \text{se $\ell\in \RR$}\\ 
    \opencloseinterval{n}{+\infty} & \text{se $\ell=+\infty$}\\
    \closeopeninterval{-\infty}{-n} & \text{se $\ell=-\infty$.}
  \end{cases}
\]
La prima proprietà è ovviamente verificata.
La proprietà archimedea dei numeri reali garantisce la validità della seconda 
proprietà, da cui segue immediatamente la terza.
\end{proof}

\begin{proposition}[caratterizzazione dei punti limite]
  Sia $f\colon A\subset \RR\to \RR$, $x_0\in \bar \RR$ 
  punto di accumulazione per $A$. 
  Sono equivalenti:
  \begin{enumerate}
    \item $\ell$ è un punto limite di $f(x)$ per $x\to x_0$.
    \item esiste una successione $a_n\in A$, $a_n\neq x_0$, $a_n\to x_0$ 
    tale che $f(a_n)\to \ell$.
  \end{enumerate}
\end{proposition}
%
\begin{proof}
  Siano $U_n$ intorni di $\ell$ e $V_n$ intorni di $x_0$ definiti 
  come nella proposizione~\ref{prop:base_numerabile}.
  Se $\ell$ è un punto limite di $f(x)$ per $x\to x_0$ 
  significa che per ogni $U$ intorno di $\ell$ e per ogni $V$ 
  intorno di $x_0$ esiste $x\in A\cap V\setminus\ENCLOSE{x_0}$ 
  tale che $f(x)\in U$.
  Dunque per ogni $n$ esiste $a_n\in A \cap V\setminus\ENCLOSE{x_0}$ 
  tale che $a_n\in V_n$ e $f(a_n)\in U_n$. 
  Significa che $a_n\to x_0$, $a_n\neq x_0$, $f(a_n)\to \ell$ 
  come volevasi dimostrare.
  
  Viceversa se esiste una tale successione $a_n\to x_0$ allora 
  per ogni $V$ intorno di $x_0$ si ha definitivamente $a_n\in V$.
  E se $f(a_n)\to \ell$ per ogni $U$ intorno di $\ell$
  si ha anche $f(a_n)\in U$ definitivamente.
  Dunque esiste $n$ tale che $a_n\in V$ e $f(a_n)\in U$ confermando 
  quindi che $f(x)\in U$ frequentemente. 
\end{proof}

Molto spesso considereremo i punti limite di una successione $a_n$
per $n\to +\infty$.
In tal caso la caratterizzazione precedente ci dice che $\ell$ 
è un punto limite di $a_n$ per $n\to+\infty$ se esiste 
una successione di indici $n_k\to+\infty$ tale che $a_{n_k}\to \ell$.
Potremmo anche supporre $n_k$ strettamente crescente in quanto se 
$n_k\to \infty$ possiamo estrarre da $n_k$ una sottosuccessione 
strettamente crescente. 
Dunque l'insieme dei punti limite di una successione $a_n$ 
corrisponde all'insieme dei limiti di tutte le possibili 
sottosuccessioni di $a_n$.

\begin{example}
  La successione $a_n=(-1)^n$ ha due punti limite:
  \[
    \limsup_{n\to +\infty}(-1)^n = 1, \qquad \liminf_{n\to+\infty} (-1)^n = -1.
  \]
  Infatti la sottosuccessione dei termini con indice pari è costante $1$ mentre
  quella dei termini di indice dispari è costante $-1$.
  Non ci possono essere altri punti limite perché se ci fosse $a_{n_k}\to \ell$
  allora certamente $a_{n_k}=1$ frequentemente oppure $a_{n_k}=-1$
  frequentemente da cui o $\ell=1$ oppure $\ell=-1$.
\end{example}
%
\begin{example}
  Visto che $\#\QQ=\#\NN$ esiste una funzione $\vec a \colon \NN \to \QQ$
  surgettiva. Utilizzando la proprietà di densità dei numeri razionali
  si può dimostrare che l'insieme dei punti limite della corrispondente successione
  $a_n = \vec a(n)$ è tutto $\bar \RR$.
\end{example}

\begin{exercise}
  Si consideri la successione $a_n = \sqrt n -\lfloor \sqrt n\rfloor$.
  Calcolare 
  \[
    \liminf_{n\to+\infty} a_n, \qquad 
    \limsup_{n\to+\infty} a_n.
  \]
  Qual è l'insieme dei punti limite di $a_n$ per $n\to +\infty$?
\end{exercise}

%
\begin{theorem}[proprietà del limite superiore/inferiore]
Sia $f\colon A\subset \RR \to \RR$ e sia $x_0$ un punto di accumulazione per $A$.
Sia $L$ l'insieme dei punti limite di $f(x)$ per $x\to x_0$. 
Allora:
\begin{enumerate}
  \item %1
  $L\neq \emptyset$;

  \item %2
  $\displaystyle\limsup_{x\to x_0} f(x) \ge \liminf_{x\to x_0} f(x)$;

  \item %3
  se $\displaystyle\limsup_{x\to x_0} f(x) = \liminf_{x\to x_0} f(x) = \ell$ 
  allora $\displaystyle\lim_{x\to x_0} f(x) = \ell$;

  \item %4
  l'insieme dei punti limite è chiuso per passaggio al limite:
  se $\ell_k\in L$ e $\ell_k \to \ell$ per qualche $\ell \in \bar \RR$ 
  allora $\ell \in L$;

  \item %5
  $\displaystyle\limsup_{x\to x_0} f(x)$ e $\displaystyle\liminf_{x\to x_0} f(x)$ sono punti limite;

  \item %6
  la condizione
  $\displaystyle\limsup_{x\to x_0} f(x) = \ell$ è equivalente a
  \[
  \begin{cases}
   \forall q > \ell \colon f(x) < q \text{ definitivamente,} \\
   \forall q < \ell \colon f(x) > q \text{ frequentemente,}
  \end{cases}
  \]
  e la condizione $\displaystyle\liminf_{x\to x_0} f(x) = \ell$ è equivalente a
  \[
  \begin{cases}
  \forall q > \ell \colon f(x) < q \text{ frequentemente,} \\
  \forall q < \ell \colon f(x) > q \text{ definitivamente;}
  \end{cases}
  \]

  \item %7
  se $a_n$ è una successione 
  \[
    \limsup_{n\to +\infty} a_n = \lim_{n\to +\infty} \sup_{k\ge n} a_k,
    \quad
    \liminf_{n\to +\infty} a_n = \lim_{n\to +\infty} \inf_{k\ge n} a_k.
  \]
 \end{enumerate}
\end{theorem}
%
\begin{proof}
  Per quanto riguarda il punto 1.\
  il teorema~\ref{th:bolzano_weierstrass} di Bolzano-Weierstrass
  garantisce che sia $L\neq \emptyset$ e
  quindi $\sup L \ge \inf L$ da cui discende il punto 2.

  Per il punto 3.\ se $\limsup = \liminf = \ell$ significa che $L=\ENCLOSE{\ell}$
  ha un solo elemento. Ma per il corollario al teorema di Bolzano Weierstrass
  sappiamo che da ogni successione $f(a_n)$ con $a_n\to x_0$ 
  è possibile estrarre una sottosuccessione $f(a_{n_k})$ regolare. 
  Il limite di tale sottosuccessione deve essere un elemento di $L$
  e quindi non può che essere $\ell$. 
  Allora per la proposizione~\ref{prop:convergenza}
  deduciamo che l'intera successione ha limite $\ell$.

  Per il punto 4.\ sia $\ell_k\in L$ una successione di punti limite
  e sia $\ell\in \bar \RR$ tale che $\ell_k \to \ell$ per $k\to +\infty$.
  Ora consideriamo la successione $U_n$ di intorni di $\ell$ 
  data dalla proposizione~\ref{prop:base_numerabile}.
  Visto che $\ell_k\to \ell$ per ogni $n$ deve esistere $k_n$ tale 
  che $\ell_{k_n}\in U_n$. Senza perdita di generalità possiamo 
  supporre direttamente che sia $\ell_n\in U_n$.
  Consideriamo anche gli intorni $V_n$ di $x_0$ dati sempre 
  dalla proposizione~\ref{prop:base_numerabile}.
  Per ogni $\ell_n \in L$ deve esistere una successione $a_k\to x_0$ 
  con $a_k\neq x_0$ tale che $f(a_k)\to \ell_n$.
  Ma allora certamente esiste $k=k_n$ tale che $a_{k_n}\in V_n$ 
  e $f(a_{k_n})\in U_n$. 
  Posto $b_n = a_{k_n}$ abbiamo trovato una successione $b_n$ 
  tale che $b_n\to x_0$ (in quanto $b_n\in V_n$) e $f(b_n)\to \ell$
  in quanto $f(b_n)\in U_n$. Dunque $\ell$ è anch'esso un punto limite. 

  Per il punto 5
  visto che $L\neq \emptyset$ la caratterizzazione del $\sup$
  garantisce che esista una successione $\ell_n\in L$ tale che $\ell_n \to \sup L$.
  Ma allora per il punto precedente si deve avere $\sup L \in L$.
  Lo stesso per l'$\inf$.

  Per il punto 6.\ facciamo la dimostrazione per il $\limsup$ (per il $\liminf$
  sarà analogo). Se $\limsup f(x) = \ell$ e se fosse frequentemente
  $f(x) \ge q > \ell$ allora esisterebbe una successione $a_n\to x_0$, 
  $a_n\neq x_0$ tale che $f(a_n)\ge q$.
  Tale successione avrebbe una estratta regolare
  che ha limite $\ge q> \ell$, il che è assurdo.
  Dunque definitivamente deve essere $f(x) < q$ per ogni $q>\ell$.
  Se invece fosse definitivamente $f(x) \le q < \ell$ per ogni
  successione $a_n\to x_0$ con $a_n\neq x_0$ si dovrebbe avere 
  $f(a_n) \le q$ e questo contraddice il fatto che $\ell>q$ 
  è un punto limite.

  Viceversa se per ogni $q>\ell$ si ha $f(x)<q$ definitivamente,
  significa che per ogni successione $a_n\to x_0$ si ha
  $f(a_n) < q$ definitivamente e quindi se $f(a_n)\to \ell$
  dovrà essere $\ell\le q$. 
  Dunque ogni $q>\ell$ è un maggiorante di $L$ e $\sup L\le \ell$.
  Se poi per ogni $q<\ell$ si ha $f(x)\ge q$ frequentemente
  significa che esiste una successione $a_n\to x_0$, $a_n\neq x_0$ 
  tale che $f(a_n)\ge q$. 
  Per il teorema di Bolzano-Weierstrass si potrà trovare 
  una estratta convergente $f(a_{n_k})\to \ell'\ge q$.
  Dunque per ogni $q<\ell$ risulta
  $\sup L \ge q$ da cui in definitiva $\sup L = \ell$. 

  Per il punto 7.\ facciamo la dimostrazione per il $\limsup$ (per il $\liminf$
  sarà analogo).
  Posto $A_n = \sup_{k\ge n} a_k$ osserviamo che $A_n$ è decrescente
  in quanto all'aumentare di $n$ l'insieme
  $\ENCLOSE{k\colon k \ge n}$ decresce (nel senso dell'inclusione insiemistica)
  e quindi
  il $\sup$ non aumenta.
  Dunque $\ell=\lim A_n$ esiste certamente in $\bar \RR$.
  Inoltre per definizione di limite per ogni $\ell'>\ell$
  si dovrà avere $A_n < \ell'$ definitivamente e quindi
  (essendo ovviamente $a_n \le A_n$) si avrà
  anche $a_n < \ell'$ definitivamente.
  Viceversa preso $\ell'<\ell$ si avrà definitivamente
  $A_n > \ell'$. Ma questo significa che esiste $k>n$
  per cui si ha $a_k > \ell'$ e quindi
  risulta $a_n > \ell'$ frequentemente.
  Per il punto precedente si può quindi concludere che
  $\ell = \limsup a_n$.
\end{proof}

\begin{theorem}[operazioni con $\limsup$ e $\liminf$]
  Siano $f,g\colon A\subset \RR\to\RR$ e sia $x_0$ un punto di accumulazione di $A$. 
  \begin{enumerate}
    \item 
      Per $x\to x_0$ si ha 
      \begin{align*}
      \limsup_{x\to x_0} (-f(x)) &= -\liminf_{x\to x_0} f(x)\\ 
      \liminf_{x\to x_0} (-f(x)) &= -\limsup_{x\to x_0} f(x);
      \end{align*}
    \item
      se $\lambda \ge 0$ allora
        \begin{align*}
        \limsup_{x\to x_0} (\lambda \cdot f(x)) &= \lambda \cdot \limsup_{x\to x_0} f(x), \\
        \liminf_{x\to x_0} (\lambda \cdot f(x)) &= \lambda \cdot \liminf_{x\to x_0} f(x);
        \end{align*}
    \item
    inoltre
    \begin{gather*}
    \limsup_{x\to x_0} (f(x) + g(x)) \le \limsup_{x\to x_0} f(x) + \limsup_{x\to x_0} g(x),\\
    \liminf_{x\to x_0} (f(x) + g(x)) \ge \liminf_{x\to x_0} f(x) + \liminf_{x\to x_0} g(x);
    \end{gather*}
    \item
    e infine se $f(x) \ge g(x)$ allora
    \[
     \limsup_{x\to x_0} f(x) \ge \limsup_{x\to x_0} g(x), \qquad \liminf_{x\to x_0} f(x) \ge \liminf_{x\to x_0} g(x).
    \]
  \end{enumerate}
\end{theorem}
%
\begin{proof}
  Per il punto 1.\ basti osservare che se la funzione $f(x)$ ha $L$ come
  insieme dei punti limite allora la funzione $-f(x)$ ha $-L$ come punti
  limite. Quindi $\sup (-L) = -\inf L$ e $\inf(-L) = -\sup L$.

  Per il punto 2.\ si osservi che se $L$ è l'insieme dei punti limite
  di $f(x)$ allora l'insieme dei punti limite di $\lambda f(x)$ è $\lambda L$.
  Se $\lambda \ge 0$ si ha dunque $\sup \lambda L = \lambda \sup L$
  e $\inf \lambda L = \lambda \inf L$ (se $\lambda<0$ invece $\inf$ e $\sup$
  si scambiano, come nel punto 1).

  Per il punto 3.\ consideriamo il caso del $\limsup$ (per il $\liminf$ sarà analogo).
  Se $\ell = \limsup(f(x)+g(x))$ significa che esiste una successione
  di $a_n\to x_0$ tale che $f(a_n)+g(a_n)\to \ell$. 
  Ma posso estrarre una sottosuccessione
  tale che anche il primo addendo $f(a_{n_k})$ abbia limite. 
  E poi posso estrarre
  una sotto-sottosuccesione in modo che anche il secondo addendo $g(a_{n_{k_j}})$
  abbia limite. 
  Dunque avremo $f(a_{n_{k_j}}) \to \ell_1$, $g(a_{n_{k_j}} \to \ell_2$
  con $\ell_1+\ell_2=\ell$.
  Ma allora per definizione di $\limsup$ si avrà $\limsup f(x) \ge \ell_1$
  e $\limsup g(x) \ge \ell_2$ da cui $\limsup f(x) + \limsup g(x) \ge \ell_1+\ell_2 = \ell$.

  Per il punto 4.\ si osserva che se $\ell = \limsup f(x)$ allora
  per ogni $q>\ell$ si ha definitivamente
  $f(x)<q$ e di conseguenza anche $g(x) < q$ definitivamente.
  Dunque $\limsup g(x) \le \ell$.
  Se invece poniamo $\ell = \liminf h(x)$ allora
  per ogni $q<l$ si ha definitivamente $g(x) \ge q$ ma
  allora anche $f(x)\ge q$ defitiviamente e quindi
  $\liminf f(x) \ge \ell$.
\end{proof}
    
\begin{theorem}[convergenza alla Cesàro]
  \label{th:criterio_cesaro}%
  \mymark{*}%
  \mymargin{Cesàro}%
\index{Cesàro}%
  \index{criterio!del rapporto alla Cesàro}%
  \index{somma!di Cesàro}%
  Sia $a_n$ una successione a termini positivi.
  \begin{enumerate}
  \item
    Se
    $   a_n \to \ell \in \bar \RR$
    allora
    \[
    \frac 1 n \cdot \displaystyle\sum_{k=1}^n a_k \to \ell.
    \]
  
  \item
    Se $a_n>0$,
    $\displaystyle\frac{a_{n+1}}{a_n} \to \ell \in [0,+\infty]$
    allora
    $\displaystyle \sqrt[n]{a_n}\to \ell$.
  \end{enumerate}
  \end{theorem}
  %
  \begin{proof}
  Dimostriamo il primo punto.
  Per ogni $q<\ell$ visto che $a_n\to \ell$ deve esistere $N$ tale che 
  $a_n\ge q$ se $n> N$. 
  Dunque 
  \[
    b_n = \frac 1 n \sum_{k=1}^{n} a_k 
    \ge \frac 1 n \sum_{k=1}^N a_k + \frac 1 n \sum_{k=N+1}^n q 
    = \frac{\sum_{k=1}^N a_k}{n} + \frac{n-N}{n}\cdot q \to q.
  \]
  Significa che per ogni $q<\ell$ si ha $\liminf b_n \ge q$ e 
  dunque $\liminf b_n \ge \ell$.
  Viceversa per ogni $q>\ell$ ragionando in maniera analoga si ottiene 
  che $b_n$ non supera una successione che tende a $q$.
  Dunque $\limsup b_n\le \ell$. 
  Mettendo insieme le cose si deduce che $\lim b_n = \ell$.
    
  Il punto 2 si può ricondurre all'1.
  Infatti
  \[
    \ln \sqrt[n]{a_n}
    = \ln \sqrt[n]{a_0\cdot \frac{a_1}{a_0} \cdots \frac{a_n}{a_{n-1}}}
    = \frac{\ln a_0 + \ln \frac{a_1}{a_0} + \dots + \ln \frac{a_n}{a_{n-1}}}{n}.
  \]
  Posto $x_n = \ln \frac{a_n}{a_{n-1}}$
  se $\frac{a_n}{a_{n-1}}\to \ell$
  si ha $x_n\to \ln \ell$ (intendendo $\ln 0 = -\infty$ e $\ln (+\infty)=+\infty$) e dunque
  \[
    \ln \sqrt[n]{a_n} = \frac{\ln a_0}{n} + \frac{x_1 + \dots + x_n}{n}
    \to \ln \ell.
  \]
  Facendo l'esponenziale di ambo i membri si trova il risultato desiderato.
  \end{proof}
  
  \begin{exercise}\label{ex:7340098}
  Si applichi il risultato precedente per
  verificare che
  \[
     \lim \sqrt[n]{n} = 1
  \]
 e
 \index{fattoriale!stima asintotica}%
 \[
   \lim \frac{n}{\sqrt[n]{n!}} = e.
 \]
 \end{exercise}
 \mynote{Nell'esercizio\ref{ex:7340098} si dimostra che 
 \[
  \sqrt[n]{n!} \sim \frac{n}{e}  
  \qquad\text{per $n\to +\infty$.}
 \]
Si faccia attenzione che non è possibile elevare alla $n$ 
entrambi i lati di questa stima asintotica.
Infatti nel Teorema~\ref{th:stirling} troveremo questa stima 
asintotica per il fattoriale:
 \[
  n! \sim \sqrt{2\pi n} \cdot \frac{n^n}{e^n}.
 \]
 Si veda l'esempio~\ref{ex:498124} per un risultato simile.%
 }

 \begin{exercise}
 Si consideri la successione
 \[
 a_n =
 \begin{cases}
    2^n &\text{se $n$ pari},\\
    n\cdot 2^n &\text{se $n$ dispari}.
 \end{cases}
 \]
 Verificare che alla successione $a_n$
  si può applicare il criterio della radice ma
  non il criterio del rapporto.
  Usare questo esempio per mostrare che le implicazioni
  enunciate nel teorema~\ref{th:criterio_cesaro} non
  possono essere invertite.
  \end{exercise}  

\subsection{il teorema degli zeri}

\begin{theorem}[degli zeri]
\mymark{***}%
\mymargin{teorema degli zeri}%
\index{teorema!degli zeri}%
\label{th:zeri}%
Sia $f\colon[a,b] \to \RR$, una funzione
continua tale che $f(a)\le 0$ e $f(b)\ge 0$.
\mynote{Se $b<a$ si intende $[a,b]=[b,a]$.}
Allora esiste
 $c\in [a,b]$ tale che $f(c)=0$.
\end{theorem}

\begin{proof}
\mymark{***}
La dimostrazione che adottiamo è di particolare rilevanza in quanto
non solo permette di dimostrare l'esistenza del punto $c$ che risolve
$f(x)=0$
ma ci presenta
un algoritmo, il \emph{metodo di bisezione}%
\mymargin{metodo di bisezione}%
\index{metodo!di bisezione},
\index{bisezione!metodo di}
che può essere effettivamente utilizzato per approssimare
tale soluzione.

Possiamo supporre senza perdere di  generalità che sia $a<b$.
Poniamo $A_0 = a$, $B_0= b$ e consideriamo il punto medio $C_0 = (A_0+B_0)/2$.
Scegliamo tra i due intervalli $[A_0, C_0]$ e $[C_0,B_0]$ quello per cui
il segno ai due estremi è discorde (o, caso fortunato, nullo).
Più precisamente se $f(C_0)\ge 0$ poniamo $[A_1,B_1] = [A_0,C_0]$ altrimenti
scegliamo $[A_1,B_1] = [C_0,B_0]$ così si ha, in ogni caso,
$f(A_1)\le 0$, $f(B_1)\ge 0$.

Consideriamo il punto medio $C_1$ del nuovo intervallo $[A_1,B_1]$ e ripetiamo
il procedimento indefinitamente. Quello che otteniamo sono due successioni
$A_n$, $B_n$ con queste proprietà (che potrebbero essere dimostrate per induzione):
\begin{enumerate}
\item $A_n < B_n$, $B_n - A_n = (b-a)/2^n$;
\item $A_n$ è crescente, $B_n$ è decrescente;
\item $f(A_n)\le 0$, $f(B_n)\ge 0$.
\end{enumerate}

Essendo $A_n$ monotòna sappiamo che $A_n$ converge $A_n\to c$.
Inoltre visto che $A_n \in [a,b]$ anche $c\in [a,b]$ (per la permanenza del
segno delle successione $A_n-a$ e $b-A_n$).
Passando al limite nell'uguaglianza $B_n = A_n + (b-a)/2^n$
si ottiene che anche $B_n \to c$. Essendo $f$ continua
avremo
\[
f(A_n) \to f(c), \qquad
f(B_n) \to f(c).
\]
Ma $f(A_n)\le 0$ e quindi per la permanenza del segno anche $f(c)\le 0$.
D'altra parte $f(B_n) \ge 0$ e quindi $f(c)\ge 0$.
Si ottiene dunque $f(c) = 0$, come volevamo dimostrare.
\end{proof}

\begin{example}\label{ex:75445}
Si voglia risolvere l'equazione
\[
  x^5-x-1=0.
\]
\end{example}
%
\begin{proof}[Svolgimento]
Posto $f(x) = x^5-x-1$ è chiaro che la funzione $f\colon \RR\to \RR$
è continua (in quanto composizione di funzioni continue).
Osserviamo che $f(0) = -1$ e $f(2)=29$, dunque la funzione
soddisfa le ipotesi del teorema degli zeri sull'intervallo $[0,2]$.
Sappiamo quindi che l'equazione in questione ha almeno una soluzione
in tale intervallo.

Utilizzando il metodo di bisezione possiamo determinare una soluzione
con precisione arbitraria. Posto $A_0=0$, $B_0=2$ abbiamo verificato che
$f(A_0)<0$ e $f(B_0)>0$.
Prendiamo il punto
medio $C_0=1$ e calcoliamo la funzione: $f(C_0)=-1 < 0$. Sappiamo
allora che una soluzione deve essere compresa nell'intevallo
$[A_1,B_1] = [C_0,B_0] = [1,2]$ perché anche in tale intervallo valgono le ipotesi
del teorema degli zeri.
Il punto medio di tale intervallo è $C_1=3/2 = 1.5$
e risulta $f(3/2) = 163/32>0$ dunque l'intervallo successivo
che andremo a considerare è $[A_2,B_2]=[1,3/2]$.
Per non dover lavorare con troppe cifre decimali invece di suddividere
esattamente a metà quest'ultimo intervallo consideriamo un punto
intermedio $C_2 = 6/5 = 1.2$ dove si ha $f(C_2)=901/3125>0$.
Sappiamo allora che una soluzione è compresa nell'intervallo
$[A_3,B_3] = [1,1.2]$. Prendiamo il punto medio $C_3=11/10=1.1$
e troviamo $f(C_3) = -48949/10^5 <0$. Abbiamo quindi ottenuto
che esiste $x\in (1.1,1.2)$ tale che $f(x)=0$. Sappiamo quindi
che $\abs{x-1.15} < 0.05$ cioè abbiamo trovato $x$ con un errore
inferiore a $0.05$.

Con molta pazienza si può procedere
con il metodo di bisezione fino ad arrivare a verificare
che $f(116/10^2)$ $=$ $-596583424/10^{10}<0$ e $f(117/10^2)=224480357/10^{10}>0$ da cui
si ottiene che una soluzione è compresa tra $1.16$ e $1.17$ con un errore
inferiore a $0.005$.
Con il calcolatore (si veda ad esempio il codice a pagina \pageref{code:bisection})
si possono ottenere più cifre significative: $x=1.1673039782614187\ldots$
\end{proof}

\begin{table}
\begin{center}
\begin{tabular}{r}
$\sqrt 2 \approx $ \ttfamily\footnotesize 
1.4142135623 7309504880 1688724209 6980785696 7187537694 \\ \ttfamily\footnotesize
8073176679 7379907324 7846210703 8850387534 3276415727 \\
% 3501384623 0912297024 9248360558 5073721264 4121497099 \\ \ttfamily\footnotesize
% 9358314132 2266592750 5592755799 9505011527 8206057147 \\ \ttfamily\footnotesize
% 0109559971 6059702745 3459686201 4728517418 6408891986 \\ \ttfamily\footnotesize
% 0955232923 0484308714 3214508397 6260362799 5251407989 \\ \ttfamily\footnotesize
% 6872533965 4633180882 9640620615 2583523950 5474575028 \\ \ttfamily\footnotesize
% 7759961729 8355752203 3753185701 1354374603 4084988471 \\ \ttfamily\footnotesize
% 6038689997 0699004815 0305440277 9031645424 7823068492 \\ \ttfamily\footnotesize
% 9369186215 8057846311 1596668713 0130156185 6898723723 \\ \ttfamily\footnotesize
% 5288509264 8612494977 1542183342 0428568606 0146824720 \\ \ttfamily\footnotesize
% 7714358548 7415565706 9677653720 2264854470 1585880162 \\ \ttfamily\footnotesize
% 0758474922 6572260020 8558446652 1458398893 9443709265 \\ \ttfamily\footnotesize
% 9180031138 8246468157 0826301005 9485870400 3186480342 \\ \ttfamily\footnotesize
% 1948972782 9064104507 2636881313 7398552561 1732204024 \\ \ttfamily\footnotesize
% 5091227700 2269411275 7362728049 5738108967 5040183698 \\ \ttfamily\footnotesize
% 6836845072 5799364729 0607629969 4138047565 4823728997 \\ \ttfamily\footnotesize
% 1803268024 7442062926 9124859052 1810044598 4215059112 \\ \ttfamily\footnotesize
% 0249441341 7285314781 0580360337 1077309182 8693147101 \\ \ttfamily\footnotesize
% 7111168391 6581726889 4197587165 8215212822 9518488472 \\
\\
$\sqrt 3 \approx$ \ttfamily\footnotesize 
1.7320508075 6887729352 7446341505 8723669428 0525381038 \\ \ttfamily\footnotesize
0628055806 9794519330 1690880003 7081146186 7572485757 \\
\\
$\phi = \frac{\sqrt 5+1}{2} \approx $ \ttfamily\footnotesize 
1.6180339887 4989484820 4586834365 6381177203 0917980576 \\ \ttfamily\footnotesize
2862135448 6227052604 6281890244 9707207204 1893911375
  \end{tabular}
\end{center}
\caption{Le prime 100 cifre decimali di alcune
costanti calcolate con il metodo di bisezione usato nella dimostrazione
del teorema~\ref{th:zeri}.
Si veda il codice a pagina~\pageref{code:bisection}.}
\label{fig:cifre_sqrt2}
\index{$\sqrt 2$!cifre decimali}
\index{cifre!$\sqrt 2$}
\end{table}

\begin{theorem}[teorema dei valori intermedi]
\label{th:valori_intermedi}%
\mymark{**}%
\mymargin{proprietà dei valori intermedi}%
\index{proprietà!dei valori intermedi}%
\index{teorema!dei valori intermedi}%
Sia $I\subset \RR$ un intervallo e $f\colon I \to \RR$ una
funzione continua.
Allora se $f$ assume due valori $y_1$ e $y_2$ allora $f$
assume anche tutti i valori intermedi tra $y_1$ e $y_2$.
Detto altrimenti: una funzione continua
manda intervalli in intervalli.
\end{theorem}
%
\begin{proof}
Se $y_1$ e $y_2$ sono valori assunti da $f$ significa
che esistono $x_1,x_2 \in I$ tali che $f(x_1)= y_1$ e $f(x_2)=y_2$.
Allora scelto $y$ si consideri la funzione $g(x) = f(x)-y$.
Se $y$ è intermedio tra $y_1$ e $y_2$ la funzione $g$ assumerà
segni opposti in $x_1$ e $x_2$ e dunque, per il teorema degli zeri,
dovrà esserci un punto $x$ in cui $g$ si annulla. In tale punto
si avrà dunque $f(x)=y$, come volevamo dimostrare.
\end{proof}

\begin{lemma}
\label{ex:inversa_monotona}%
Se $I$ è un intervallo di $\RR$ ogni funzione $f\colon I \to \RR$
iniettiva e continua è strettamente monotona.
\end{lemma}
%
\begin{proof}
Si può osservare che una funzione è strettamente monotona se mantiene i valori
intermedi cioè se dati tre punti
$x<y<z$ risulta sempre che $f(y)$ è un valore intermedio tra $f(x)$ e $f(z)$:
\[
  f(x)< f(y) <f(z) \qquad\text{oppure} \qquad f(x)> f(y) > f(z).
\]
Se ciò non accadesse, ad esempio se fosse $f(y)>f(z)>f(x)$ con $x<y<z$
allora per la continuità di $f$ dovrebbe esistere un valore intermedio
tra $x$ e $y$ in cui la funzione assume il valore $f(z)$. Ma allora la funzione
non sarebbe iniettiva.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%
\section{il teorema di Weierstrass}
    
Ricordiamo che nella definizione~\ref{def:funzione_limitata}
abbiamo definito i concetti di massimo, minimo, estremo superiore
e inferiore di una funzione a valori reali.

\begin{lemma}[successioni minimizzanti/massimizzanti]%
\mymargin{successioni mi\-ni\-miz\-zan\-ti}%
\index{successione!minimizzanti}%
\index{successione!massimizzanti}%
Sia $A$ un insieme non vuoto e
sia $f\colon A \to \RR$ una funzione. Allora esistono
due successioni $a_n$ e $b_n$ di punti di $A$ tali che
\[
  \lim_{n\to +\infty} f(a_n) = \inf f(A), \qquad
  \lim_{n\to +\infty} f(b_n) = \sup f(A).
\]
\end{lemma}
\mymargin{successioni mi\-ni\-miz\-zan\-ti}
%
\begin{proof}
Ricordiamo che $f(A) = \ENCLOSE{f(x)\colon x \in A}$ è l'immagine
della funzione $f$. Facciamo la dimostrazione per l'estremo inferiore,
risultato analogo si potrà ottenere per l'estremo superiore.

Sia $m=\inf f(A)$.
Se $m=-\infty$ significa che $f(A)$ non è inferiormente limitato,
in particolare per ogni $n\in \RR$ esiste $a_n$ tale che
$f(a_n) < - n$.
Dunque (per confronto) $f(a_n) \to -\infty$
come volevamo dimostrare.

Se $m\in \RR$ per le proprietà caratterizzanti l'estremo inferiore
sappiamo che per ogni $\eps>0$ esiste $a\in A$ tale che
$f(a) < m + \eps$.
Per ogni $n\in\NN$ possiamo scegliere $\eps=1/n$ e ottenere quindi
una successione $a_n$ tale che $f(a_n) < m + 1/n$.
D'altra parte essendo $m$ un minorante di $f(A)$ sappiamo che
$m \le f(a_n)$.
Abbiamo dunque $m \le f(a_n) < m+ 1/n$ e per il teorema dei
carabinieri possiamo quindi concludere che $f(a_n) \to m$
per $n\to +\infty$.
\end{proof}

\begin{theorem}[Weierstrass]%
\label{th:weierstrass}%
\mymark{***}%
\mymargin{teorema di Weierstrass}%
\index{teorema!di Weierstrass}%
\mynote{vedi note storiche a pag~\pageref{note:isoperimetrico}}%
Siano $a,b\in \RR$ e $f\colon [a,b]\to \RR$ una funzione continua.
\mynote{Ricordiamo che se $b<a$ si intende $[a,b]=[b,a]$ dunque 
l'intervallo $[a,b]$ non è vuoto.}%
Allora esistono punti di massimo e di minimo per $f$ su $[a,b]$.
\end{theorem}
%
\begin{proof}
\mymark{***}%
Dimostriamo solamente che $f$ ha minimo, per il massimo la dimostrazione procede
infatti in maniera del tutto analoga.

Sia $m= \inf f([a,b])$.
Per il lemma precedente sappiamo che esiste una successione $a_n$ minimizzante ovvero tale che
$a_n \in A$ e $f(a_n)\to m$ per $n\to +\infty$.

Per il teorema di Bolzano-Weierstrass dalla successione $a_n$ possiamo estrarre una sottosuccessione 
$a_{n_k}$ convergente: $a_{n_k} \to x_0$.
Visto che $a_{n_k} \in [a,b]$ si avrà, per il teorema della permanenza del segno, anche 
$x_0 \in [a,b]$ (si applichi la permanenza del segno alle successioni $a_{n_k}-a$ e $b-a_{n_k}$).

Dunque abbiamo una successione $a_{n_k}\to x_0$ con $a_{n_k}\in [a,b]$ e
$x_0 \in [a,b]$. Essendo $f$ continua si avrà dunque $f(a_{n_k}) \to f(x_0)$.
Ma noi sapevamo che $f(a_n)\to m$ e dunque anche $f(a_{n_k}) \to m$.
Concludiamo quindi che $f(x_0) = m$ cioè $m$, l'estremo inferiore,
è un valore assunto dalla funzione ed è quindi un minimo.
Dal canto suo $x_0$ è un punto di minimo assoluto.
\end{proof}

\begin{corollary}[limitatezza delle funzioni continue]
Sia $f\colon [a,b]\to \RR$ una funzione continua. Allora $f$ è limitata.
\end{corollary}
\begin{proof}
Visto che $f$ ha massimo $M$ e minimo $m$ si ha $f(x)\in [m,M]$ per ogni $x\in[a,b]$.
Ovviamente $m>-\infty$ e $M<+\infty$ in quanto $m$ e $M$ sono valori della funzione $f$.
\end{proof}


%%%%%%%%%%%
%%%%%%%%%%%
\section{funzioni trigonometriche, radianti}
%%%%%%%%%%%
%%%%%%%%%%%

Nel capitolo~\ref{sec:avvolgimento} abbiamo definito le 
funzioni $\sin$ e $\cos\colon \RR\to \RR$ con periodo $\tau>0$ (arbitrario)
in modo tale che la funzione $\phi\colon \RR\to\RR^2$, $\phi(t)=(\cos t, \sin t)$ 
percorra, con moto circolare uniforme, in senso antiorario, la circonferenza 
unitaria $\ENCLOSE{(x,y)\in \RR^2\colon x^2+y^2=1}$.
Tale funzione descrive in effetti un moto circolare uniforme 
in quanto percorre archi congruenti in tempi uguali.
\mynote{Due figure geometriche sono \emph{congruenti} se c'è una isometria 
che manda una nell'altra.
Due archi sono congruenti se hanno la stessa lunghezza e lo stesso raggio, 
ma non è necessario introdurre il concetto di \emph{lunghezza d'arco} per parlare 
di congruenza.
}

Vogliamo ora mostrare che è possibile scegliere la costante $\tau$
in modo tale che la linea descritta da $\phi$ percorra la circonferenza 
con \emph{velocità} unitaria.
\mynote{Ricordiamo che $\tau$ è il periodo delle funzioni $\phi$,
$\cos$ e $\sin$}%
Se seguo il punto $f(t)$ a partire dall'istante $t=0$ per un breve tempo 
$\Delta t\neq 0$
osservo che il punto si sposta tra $f(0) = (1,0)$ e 
$f(\Delta t) = (\cos \Delta t, \sin \Delta t)$.
\mynote{La notazione $\Delta t$ indica un qualunque numero positivo.
Usiamo tale notazione perché tale numero rappresenta 
una differenza ($\Delta$ è una lettera $D$ greca)
di tempi tra loro vicini.}%
Intuitivamente quando $t=0$ il punto $f(t)$ si muove verticalmente, 
verso l'alto. 
Lo spazio percorso $\Delta s$ sarà quindi approssimativamente 
uguale alla variazione della coordinata $y$: 
$\Delta y = \sin \Delta t$.
\mynote{Ricordiamo che $\sin 0 = 0$}
Dunque la velocità sarà pari alla componente verticale della velocità 
e sarà, intuitivamente, il limite di $\frac{\Delta y}{\Delta t}$ ovvero 
\mynote{Vedremo tra poco che questo limite è la  
\emph{derivata} della funzione $f$ nel punto $t=0$.}
\[
\lim_{\Delta t\to 0} \frac{\sin(\Delta t)}{\Delta t}.  
\]

Dal punto di vista formale non è del tutto ovvio che questo limite esista.
Nel seguito lo dimostriamo, con un metodo molto simile a quello utilizzato 
per definire la costante $e$ di Nepero.
Così come l'esponenziale reale $x\mapsto a^x$ 
è un isomorfismo tra il gruppo additivo di $\RR$ e il gruppo moltiplicativo 
di $\RR^+$, così la funzione $\phi(t) = (\cos(t), \sin(t))$ 
risulta essere un isomorfismo 
tra il gruppo additivo $\RR$ e il gruppo delle rotazioni del piano che può essere 
rappresentato dall'insieme $U$ dei numeri complessi unitari.
Abbiamo già visto che affinché il punto che si muove con legge 
oraria $x\mapsto a^x$ abbia velocità $1$ per $x=0$ 
si deve porre $a=e$, la base dei logaritmi naturali.
Allo stesso modo vedremo ora che affinché la velocità 
del punto $t\mapsto \phi(t)$ 
sia anch'essa unitaria bisogna avere $\tau = 2\pi$.
Mettendo assieme i due isomorfismi $e^t$ e $\phi(t)$ si potrà definire,
come vedremo tra poco, un isomorfismo tra il gruppo additivo $\CC$ 
e il gruppo moltiplicativo $\CC\setminus\ENCLOSE 0$.
Quello che si ottiene è l'esponenziale complesso $z\mapsto e^z$. 
La velocità di $\phi(t)$ rappresenta in effetti la derivata di tale funzione 
complessa nel punto $1$ nella direzione dell'asse immaginario 
così come la derivata della funzione esponenziale reale è la derivata 
nella direzione reale. 
Si intuisce così come le costanti fondamentali $e$ e $\pi$ siano legate 
tra loro dalla condizione di fare sì che la funzione esponenziale complessa 
sia derivabile in senso complesso ed abbia derivata complessa pari a $1$.

\subsection{il numero $\pi$}

In questo capitolo dobbiamo lavorare con le funzioni 
$\sin$, $\cos$ e $\tg=\frac{\sin }{\cos}$ introdotte 
nel capitolo~\ref{sec:avvolgimento}. 
Queste funzioni sono state definite con un periodo $\tau>0$
fissato in modo arbitrario. 
Scriveremo 
$\sin_\tau$ 
e $\cos_\tau$ invece di $\sin$ e $\cos$ se è utile mettere in evidenza 
la dipendenza da $\tau$.

\begin{theorem}[limite notevole $\sin$]
Per ogni $\tau>0$, $x\in \RR$, $x\neq 0$, la successione
\[
    a_n = \frac{\sin_\tau \frac xn} {\frac xn}
\]
converge ad un limite positivo (e finito).
\end{theorem}
%
\begin{proof}
Faremo uso della funzione $\tg x= \frac{\sin x}{\cos x}$.
Useremo le formule di addizione:
\begin{align*}
 \sin(x+y) &= \sin x\cos y + \cos x \sin y,\\
 \cos(x+y) &= \cos x \cos y - \sin x \sin y  
\end{align*}
da cui, facendo il rapporto e dividendo numeratore 
e denominatore per $\cos x \cos y$ si ottiene:
\[
  \tg(x+y) = \frac{\tg x + \tg y}{1-\tg x \tg y}.
\]
Useremo anche il fatto che sull'intervallo 
$\closeinterval{0}{\frac \tau 4}$
\mynote{ricordiamo che $\tau$ è il periodo (scelto arbitrariamente)
delle funzioni $\sin$ e $\cos$} 
la funzione $\sin$ è crescente, la funzione $\cos $
è decrescente ed entrambe hanno valori compresi 
tra $0$ e $1$.
Tutte queste proprietà sono garantite 
dal teorema~\ref{th:proprieta_trigonometriche}.

\emph{Passo 1:}
vogliamo dimostrare che se $n$ è un intero positivo 
e $x>0$ è tale che $0\le nx <\frac \tau 4$ allora si ha
\begin{equation}\label{eq:4813509}
  \sin n x \le n\sin x\le \tg nx.
\end{equation}
Possiamo dimostrare per induzione l'implicazione 
$nx\le \frac \tau 4 \implies$~\eqref{eq:4813509}.
Se $n=1$ è ovvio.
Supponiamo allora che \eqref{eq:4813509} 
sia valida per un certo $n$ e che  
sia $(n+1)x<\frac \tau 4$. 
Allora da un lato si ha
\begin{align*}
  \sin (n+1)x 
  &= \sin nx \cdot \cos x + \cos nx\sin x
  \le \sin nx + \sin x
\end{align*}
e usando l'ipotesi induttiva $\sin nx\le n\sin x$ 
si ottiene 
\[
 \sin(n+1)x \le n\sin x+\sin x = (n+1)\sin x  
\]
che è la prima disuguaglianza che dovevamo dimostrare.
Per l'altra disuguaglianza osserviamo che si ha 
\begin{align*}
  \tg(n+1)x 
  &= \frac{\tg nx + \tg x}{1-\tg nx \tg x}
  \ge \tg nx + \tg x
  \ge \tg nx + \sin x
\end{align*}
e applicando l'ipotesi induttiva 
$\tg nx\ge n\sin x$ si ottiene 
\[
 \tg(n+1)x 
 \ge n\sin x +\sin x 
 =   (n+1)\sin x
\]
come volevamo dimostrare.

\emph{Passo 2:}
dimostriamo che se $x>0$,
posto
\[
  a_n = \frac{\sin \frac x n}{\frac x n} = \frac{n\sin \frac x n}{x}
\]
si ha $a_{n+1}\ge a_n$ per ogni $n \ge \frac{4x}{\tau}$
e dunque, essendo definitivamente monotona, 
la successione ammette limite 
(grazie al teorema~\ref{th:limite_monotona}):
$a_n \to \ell$ per $n\to +\infty$.
Posto $y=\frac{x}{n(n+1)}$ basta mostrare che 
se $\frac{x}{n} \le \frac{\tau}{4}$, si ha
\[
  (n+1) \sin ny \ge n \sin (n+1)y.  
\]
Ma usando $n\sin y\le \tg ny$ da~\eqref{eq:4813509} si ha 
\begin{align*}
  n \sin(n+1)y
  &=n(\sin ny\cos y + \cos ny \sin y) \\
  &\le n\sin ny + n\sin y\cos ny\\
  &\le n\sin ny + \tg ny\cos ny\\
  &= (n+1)\sin ny
\end{align*}
che è quanto volevamo dimostrare.

\emph{Passo 3.}
vogliamo mostrare che il limite $\ell=\lim a_n$ è positivo e 
finito.
Basta osservare che se $x>0$ e $\frac x m <\frac \tau 4$
per $m$ intero sufficientemente grande, 
usando~\eqref{eq:4813509} con 
con $\frac x {mn}$ al posto di $x$,
si ha $\sin \frac x m \le n\sin\frac x {m n} \le \tg \frac{x}{m}$ 
e quindi
\[
  \frac{\sin \frac x m}{\frac x m} 
  \le \frac{\sin \frac x {mn}}{\frac x {mn}} 
  \le \frac{\tg \frac x m}{\frac x m}.
  \]
Sappiamo che la sottosuccessione $a_{mn}\to \ell$ e, dunque,
dovrà essere 
\[
  0 <
  \frac{\sin \frac x m}{\frac x m} 
  \le \ell
  \le \frac{\tg \frac x m}{\frac x m} < +\infty.
\]

\emph{Conclusione.}
Abbiamo dimostrato il teorema per ogni $x>0$.
Se $x<0$ il risultato si ottiene per simmetria usando: 
$\sin(-x)=-\sin x$.
\end{proof}

Se applichiamo il teorema precedente 
con $\tau=1$ e $x=1$ otteniamo che la successione 
$a_n = n\cdot \sin_1\enclose{\frac 1 n}$ converge 
ad una costante universale.
In particolare avendo posto la misura dell'angolo giro pari a 
$\tau=1$, l'angolo di misura $\frac 1 n$ 
è l'angolo formato dal lato di un $n$-agono 
regolare inscritto nella circonferenza unitaria.
Dunque $a_n$ non è altro che il perimetro di tale 
$n$-agono regolare e il limite a cui tende deve essere,
geometricamente, la lunghezza della circonferenza unitaria.

Questo dà significato geometrico alla seguente definizione.

\begin{definition}[$\pi$ costante fondamentale della trigonometria]%
  \label{def:pi}%
Definiamo
\[
 \pi 
  \defeq \frac 1 2 \lim_{n\to +\infty} n\cdot \sin_1 \enclose{\frac 1 n}.
\]
dove $\sin_1$ è la funzione $\sin$ costruita nel 
teorema~\ref{def:sin_cos} con periodo $\tau=1$.
\end{definition}

\begin{theorem}[limite notevole $\sin$]
  \label{th:limite_notevole_sin}%
Sia $\sin_\tau$ la funzione seno definita 
dal teorema~\ref{def:sin_cos} con periodo $\tau>0$.
Per ogni $x\in\RR$, $x\neq 0$ si ha 
\[
\lim_{x\to 0}\frac{\sin_{\tau} x}{x}
= \frac{2\pi}{\tau}.
\]
\end{theorem}
%
\begin{proof}
Risulta ovviamente $\sin_\tau(\tau x) = \sin_1 x$ in quanto 
la funzione $\sin_\tau(\tau x)$ ha periodo $1$ e soddisfa tutte le proprietà 
enunciate nel teorema~\ref{def:sin_cos}.
Ora per ogni $x>0$ esiste $n\in \NN$ tale che 
$\frac \tau {n+1} \le x \le \frac \tau n$ 
e se $nx<\frac \tau 4$ usando la monotonia della funzione $\sin_\tau$ 
si ottiene:
\begin{align*}
  n \sin_1 \frac 1 {n+1}
  = n \sin_\tau \frac \tau {(n+1)}
  \le n \sin_\tau x 
  = n \sin_1 \frac x \tau 
  \le n \sin_1 \frac 1 n.
\end{align*}
Ovviamente se $x\to 0^+$ si ha $n=n(x)\to +\infty$.
Per come abbiamo definito $\pi$ 
sappiamo che $n \sin_1 \frac 1 n\to 2\pi$ per $n\to +\infty$
e visto che $n\sim n+1$ entrambi i lati della precedente equazione 
tendono allo stesso limite $2\pi$ e dunque, per confronto, 
\[
  \lim_{x\to 0^+} \tau \cdot \frac{\sin_\tau x}{x} = 2\pi.  
\]
Per simmetria lo stesso limite vale quanto $x\to 0^-$
e si ottiene dunque il risultato voluto.
\end{proof}

D'ora in avanti sceglieremo $\tau=2\pi$ come periodo 
delle funzioni trigonometriche.
E d'ora in avanti si intenderà $\sin = \sin_{2\pi}$, 
$\cos = \cos_{2\pi}$. Si avrà quindi il limite notevole 
\[
   \lim_{x\to 0} \frac{\sin x}{x} = 1.  
\]

Quando introdurremo le derivate potremo anche osservare che 
questa scelta del periodo $\tau=2\pi$ 
fa sì che il punto di coordinate
$(\cos t,\sin t)$ si muova con velocità unitaria lungo 
la circonferenza unitaria. 
Dunque tale punto percorre un arco di lunghezza $t$ nel tempo $t$.
In particolare in un periodo $\tau=2\pi$ il punto percorre l'intera 
circonferenza e dunque risulta che $2\pi$ è la lunghezza 
della circonferenza unitaria (ovvero $2\pi r$ è la lunghezza della circonferenza 
di raggio $r$).
Al tempo $t=1$ il punto $(\cos t,\sin t)$ individua un angolo che 
viene chiamato \emph{radiante} in quanto corrisponde ad un arco di lunghezza 
pari al raggio (unitario). 
Dunque il \emph{radiante} è l'unità di misura naturale per misurare gli angoli 
e le funzioni $\sin$ e $\cos$ d'ora in poi saranno fissate con tale unità di misura.

\newsavebox{\qrfigtrigo}\sbox{\qrfigtrigo}{\myurlhere{figtrigo}{funzioni trigonometriche}}%
\begin{figure}
  \centering%
  \begin{tikzpicture}[scale=0.75]
  \draw[->] (-6,0) -- (6,0) node[right] {$x$};
  \draw[->] (0,-3) -- (0,3) node[above] {$y$};
  \foreach \x/\xtext in
    {{pi/2}/{\frac \pi 2}, {pi}/{\pi}, {3*pi/2}/{\frac{3}{2}\pi},
    {-pi/2}/{-\frac \pi 2}, {-pi}/{-\pi}, {-3*pi/2}/{-\frac{3}{2}\pi}} {
    \draw[shift={(\x,0)},lightgray] (0,-3) -- (0,3);
    \draw[shift={(\x,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\xtext$};
  }
  \foreach \y in {1, -1} {
    \draw[shift={(0,\y)},lightgray] (-6,0) -- (6,0);
  }
  \draw (0,1) node [above right] {1};
  \draw (0,-1) node [right] {-1};
  \draw[domain=-rad(atan(3)):rad(atan(3)),smooth,variable=\x,brown,thick] plot ({\x},{tan(deg(\x))});
  \draw[domain=pi-rad(atan(3)):pi+rad(atan(3)),smooth,variable=\x,brown,thick] plot ({\x},{tan(deg(\x))});
  \draw[domain=-pi-rad(atan(3)):-pi+rad(atan(3)),smooth,variable=\x,brown,thick] plot ({\x},{tan(deg(\x))});
  \draw[domain=-6:-2*pi+rad(atan(3)),smooth,variable=\x,brown,thick] plot ({\x},{tan(deg(\x))});
  \draw[domain=2*pi-rad(atan(3)):6,smooth,variable=\x,brown,thick] plot ({\x},{tan(deg(\x))});
  \draw[domain=-6:6,smooth,variable=\x,blue,thick] plot ({\x},{cos(deg(\x))});
  \draw[domain=-6:6,smooth,variable=\x,red,thick] plot ({\x},{sin(deg(\x))});
  \draw (3.7,-1) node[blue,below] {$y=\cos x$};
  \draw (2,0.9)  node[red,above] {$y=\sin x$};
  \draw (1.3,2.5) node[brown,right] {$y=\tg x$};
  \end{tikzpicture}
  \caption{%
  I grafici delle funzioni $\sin$, $\cos$ e $\tg$.
  \ifwidemargin\\\\\fi%
  \usebox{\qrfigtrigo}}
\end{figure}

\subsection{funzioni trigonometriche inverse}

La funzione $\sin\colon[-\pi/2,\pi/2]\to [-1,1]$ 
risulta essere strettamente crescente e bigettiva. 
Dunque restringendo il dominio all'intervallo $[-\pi/2, \pi/2]$
e il codominio all'intervallo $[-1,1]$ la funzione risulta invertibile.
La funzione inversa
\[
  \arcsin\colon[-1,1]\to [-\pi/2, \pi/2]
\]
si chiama \emph{arco seno}. 
Per definizione di funzione inversa si ha
\[
  \arcsin(\sin x) = x, \qquad \forall x \in [-\pi/2, \pi/2]
\]
e
\[
  \sin(\arcsin x) = x, \qquad \forall x \in [-1, 1].
\]

La funzione $\cos \colon[0,\pi] \to [-1,1]$ risulta essere strettamente
decrescente e bigettiva.
La funzione inversa
\[
  \arccos\colon[-1,1] \to [0,\pi]
\]
si chiama \emph{arco coseno}. Per definizione si ha
\[
  \arccos(\cos x) = x, \qquad \forall x \in [0,\pi]
\]
e
\[
    \cos(\arccos x) = x, \qquad \forall x \in [-1,1].
\]

La funzione
\index{tangente!funzione trigonometrica}
\mymargin{$\tg x$}%
\index{$\tg x$}
\[
\tg x = \frac{\sin x}{\cos x}
\]
è definita quando $\cos x\neq 0$ ovvero:
\[
  \tg \colon \RR \setminus\ENCLOSE{\frac \pi 2+ k\pi\colon k\in \ZZ} \to \RR.
\]
Se restringiamo la funzione all'intervallo $\enclose{-\pi/2, \pi/2}$ possiamo
facilmente osservare che la funzione $\tg\colon(-\pi/2,\pi/2)\to \RR$ è strettamente crescente. Inoltre se $a_n \to \pi/2$, $a_n<\pi/2$ si ha $\cos(a_n)\to 0$ (per continuità del coseno) e $\sin(a_n)\to 1$ dunque $\tg a_n\to +\infty$. Analogamente per $a_n \to -\pi/2$ si trova $\tg a_n \to -\infty$. Dunque per il teorema dei valori intermedi possiamo affermare che la funzione $\tg\colon(-\pi/2,\pi/2)\to \RR$ è suriettiva. E' quindi invertibile
e la funzione inversa
\[
  \arctg \colon \RR \to (-\pi/2,\pi/2)
\]
si chiama \emph{arco tangente}. Per definizione si ha
\[
  \arctg \tg x = x, \qquad \forall x \in (-\pi/2, \pi/2)
\]
e
\[
  \tg\arctg x = x, \qquad \forall x \in \RR.
\]

Grazie al teorema~\ref{th:monotona_continua}
visto che queste funzioni sono monotone e bigettive
possiamo affermare che
le funzioni $\arcsin$, $\arccos$ e $\arctg$ 
sono tutte funzioni continue.

\begin{exercise}[funzioni misteriose]
  Si disegni il grafico delle seguenti funzioni
  \[
    f(x) = \arcsin \sin x, \qquad 
    g(x) = \arccos \cos x, \qquad 
    h(x) = \arctg \tg x.
  \]
  Si osservi che:
  \begin{enumerate} 
    \item $f$ e $g$ sono definite su tutto $\RR$,
  mentre $h$ è definita su $\RR\setminus\ENCLOSE{\frac{\pi}2+k\pi\colon k\in \ZZ}$;
    \item $f$ e $h$ hanno valori 
  in $\closeinterval{-\frac \pi 2}{\frac \pi 2}$
  mentre $g$ ha valori in $\closeinterval{0}{\pi}$;
    \item $f$ e $g$ hanno periodo $2\pi$,
  $h$ ha periodo $\pi$;
    \item tutte e tre sono funzioni continue (sul loro dominio).
  \end{enumerate}
\end{exercise}

\begin{exercise}
Dimostrare che per ogni $x>0$ si ha
\[
  \arctg \frac 1 x = \frac \pi 2 - \arctg x.
\]
\end{exercise}

\begin{exercise}[lunghezza della circonferenza]
Si osservi che un $n$-agono regolare iscritto a una circonferenza 
di raggio $r$ ha lati di lunghezza $l_n = 2r\sin \frac{\pi}{n}$
e quindi perimetro $p_n = n\cdot l_n$.
Si verifichi che 
\[
  \lim_{n\to +\infty} p_n = 2\pi r.
\]
\end{exercise}

\section{funzioni iperboliche}

\begin{definition}[funzioni iperboliche]
Le funzioni
\emph{coseno iperbolico} e \emph{seno iperbolico}
sono definite, per ogni $x\in \RR$,
come segue:
\mymargin{$\sinh$, $\cosh$}%
\index{$\sinh$, $\cosh$}%
\index{funzioni!iperboliche}%
\index{seno!iperbolico}%
\index{coseno!iperbolico}%
\index{$\sinh$}%
\index{$\cosh$}%
\begin{equation}
\label{eq:sinh_cosh}
  \cosh x = \frac{e^x + e^{-x}}{2},
  \qquad
  \sinh x = \frac{e^x - e^{-x}}{2}.
\end{equation}
\end{definition}

\begin{theorem}[proprietà delle funzioni iperboliche]
Valgono le seguenti proprietà.
\begin{enumerate}
\item
la funzione $\sinh$ è dispari, $\cosh$ è pari:
\[
\sinh(-x) = -\sinh(x),
\qquad
\cosh(-x) = \cosh(x);
\]

\item
i punti del piano con coordinate $(\cosh x, \sinh x)$
per $x\in \RR$
sono disposti su un ramo di iperbole in quanto vale:
\[
  \cosh^2 x - \sinh^2 x = 1;
\]

\item formule di addizione:
\begin{align*}
  \cosh(\alpha+\beta) &= \cosh \alpha \cosh \beta + \sinh \alpha \sinh \beta,\\
  \sinh(\alpha+\beta) &= \sinh \alpha \cosh \beta + \cosh \alpha \sinh \beta;
\end{align*}

% \item si ha
% \begin{align*}
%   \cosh x
%   &= \sum_{k=0}^{+\infty} \frac{x^{2k}}{(2k)!}
%   = 1 + \frac{x^2}{2} + \frac{x^4}{4!} + \frac{x^6}{6!} + \dots \\
%   \sinh x
%   &= \sum_{k=0}^{+\infty} \frac{x^{2k+1}}{(2k+1)!}
%   = x + \frac{x^3}{6} + \frac{x^5}{5!} + \frac{x^7}{7!} + \dots
% \end{align*}

\item
la funzione $\sinh$ è strettamente crescente su tutto $\RR$,
la funzione $\cosh$
è strettamente crescente sull'intervallo
$[0,+\infty)$ e strettamente decrescente
nell'intervallo $(-\infty,0]$;

\item per $x\to +\infty$ si ha $\sinh x \to +\infty$, $\cosh x \to +\infty$, 
per $x\to -\infty$ si ha $\sinh x \to -\infty$, $\cosh x \to +\infty$.

\end{enumerate}
\end{theorem}

\newsavebox{\qrfigiperb}\sbox{\qrfigiperb}{\myurlhere{figiperb}{funzioni iperboliche}}%
\begin{figure}
  \centering%
  \begin{tikzpicture}[scale=0.75]
  \draw[->] (-6,0) -- (6,0) node[right] {$x$};
  \draw[->] (0,-3) -- (0,3) node[above] {$y$};
  \foreach \y in {1, -1} {
    \draw[shift={(0,\y)},lightgray] (-6,0) -- (6,0);
  }
  \draw (0,1) node [above right] {$1$};
  \draw (0,-1) node [below right] {$-1$};
  \draw[domain=-6:6,smooth,variable=\x,brown,thick] plot ({\x},{tanh(\x)});
  \draw[domain=-1.75:1.75,smooth,variable=\x,blue,thick] plot ({\x},{cosh(\x)});
  \draw[domain=-1.75:1.75,smooth,variable=\x,red,thick] plot ({\x},{sinh(\x)});
  \draw (-2.5,2) node[blue,below] {$y=\cosh x$};
  \draw (2.7,1.5)  node[red,above] {$y=\sinh x$};
  \draw (5,1) node[brown,above] {$y=\tgh x$};
  \end{tikzpicture}
  \caption{%
    I grafici delle funzioni $\sinh$, $\cosh$ e $\tgh$.
    \ifwidemargin\\\\\fi%
    \usebox{\qrfigiperb}%
  }
\end{figure}

\begin{proof}
I primi tre punti si dimostrano facilmente per verifica diretta,
utilizzando la definizione~\eqref{eq:sinh_cosh}.

% Gli sviluppi in serie si ottengono anch'essi sostituendo
% gli sviluppi dell'esponenziale nella definizione.
% Nel $\cosh$ i termini di grado dispari si cancellano, nel $\sinh$ si cancellano
% i termini di grado pari.

Per quanto riguarda la monotonia si osserva che se $x\ge 0$ ogni
addendo delle due serie esposte nel punto 4 è strettamente crescente
(in quanto i coefficienti sono tutti positivi) e dunque le somme delle serie,
cioè la funzione $\cosh$ e la funzione $\sinh$ sono strettamente crescenti
sull'intervallo $[0,+\infty)$. La funzione $\sinh$, essendo dispari,
risulta inoltre crescente anche sull'intervallo $(-\infty,0]$ e quindi
è crescente su tutto $\RR$.

Per l'ultima proprietà basterà usare la definizione~\eqref{eq:sinh_cosh}
e ricordare che (teorema~\ref{th:ordine_infinito})
se $x\to +\infty$ allora
$e^x\to +\infty$ ed $e^{-x}=\frac{1}{e^{x}} \to 0$.
\end{proof}

Osserviamo che $\cosh 0 = 1$ e, per le proprietà di monotonia viste nel teorema
precedente si ha $\cosh x \ge \cosh 0 = 1 > 0$. Dunque $\cosh x$ non si annulla
mai e si può definire per ogni $x\in \RR$ la \emph{tangente iperbolica}
\index{tangente!iperbolica}%
\mymargin{$\tgh$}%
\index{$\tgh$}%
\[
    \tgh x = \frac{\sinh x}{\cosh x}.
\]

La funzione $\sinh\colon \RR\to\RR$ è iniettiva in quanto strettamente crescente ed
è surgettiva in quanto è continua e quindi assume tutti i valori compresi tra
$\lim_{x\to+\infty} \sinh(x) = +\infty$ e $\lim_{x\to -\infty} \sinh(x) = -\infty$. 
Dunque $\sinh\colon \RR \to \RR$
è invertibile e la funzione inversa si chiama \emph{settore di seno iperbolico}
e si denota con
\mymargin{$\settsinh$}%
\index{$\settsinh$}
\index{settore!di seno iperbolico}
\[
    \settsinh \colon \RR \to \RR.
\]
Analogamente la funzione ristretta $\cosh\colon [0,+\infty)\to [1,+\infty)$ è
iniettiva in quanto strettamente crescente ed è surgettiva in quanto
è continua e assume su $[0,+\infty)$ tutti i valori compresi tra $\cosh(0)=1$ e
$\lim_{x\to +\infty} \cosh x = +\infty$.
Dunque la funzione $\cosh x$ ristretta a $[0,+\infty)\to [1,+\infty)$
è invertibile e la funzione inversa si chiama \emph{settore di coseno iperbolico}
\mymargin{$\settcosh$}%
\index{$\settcosh$}
\index{settore!di coseno iperbolico}
\[
    \settcosh \colon [1,+\infty)\to [0,+\infty).
\]

La funzione $\tgh x$ è strettamente crescente su tutto $\RR$ e assume tutti i valori strettamente compresi tra $-1$ e $1$.
La funzione inversa si chiama $\setttgh$.

\begin{exercise}
Fissato $y\in \RR$ si risolva l'equazione
\[
    \frac{e^x - e^{-x}}{2} = y
\]
riconducendola ad una equazione di secondo grado nella variabile $t=e^x$.
Si dimostri quindi che vale
\[
    \settsinh x = \ln\enclose{x + \sqrt{x^2 + 1}}.
\]
In modo analogo si dimostri che vale
\[
    \settcosh x = \ln\enclose{x + \sqrt{x^2 - 1}}
\]
e
\[
    \setttgh x = \ln \sqrt{\frac{1+x}{1-x}}.
\]
\end{exercise}

\section{l'esponenziale complesso}
\label{sec:esponenziale_complesso}%

L'esponenziale reale e le funzioni trigonometriche possono essere pensate 
come strumenti intermedi per definire un isomorfismo naturale 
da $\CC$ come gruppo additivo in $\CC$ come gruppo moltiplicativo.

Possiamo infatti definire la funzione $\exp \colon \CC \to \CC$ mediante 
la \emph{formula di Eulero}
\[
 \exp(x+iy) = e^x \cdot (\cos y + i \sin y).
\]
Questa funzione ha le seguenti proprietà:
\begin{enumerate}
  \item $\exp(z+w) = \exp z \cdot \exp w$;
  \item $\exp\bar z = \overline{\exp z}$;
  \item $\abs{\exp z} = e^{\Re z}$;
  \item $\exp x = e^x$ se $x\in \RR$.
\end{enumerate}
Visto che $\exp$ estende la funzione esponenziale reale $e^x$
sarà anche naturale usare la stessa notazione ponendo:
\mynote{%
La notazione $e^z$ non ci deve far pensare che abbiamo definito 
una operazione di elevamento a potenza tra numeri complessi. 
In effetti non è possibile definire in maniera sensata e univoca 
la potenza $z^w$ se la base $z$ non è un numero reale positivo.
Questo è legato al fatto che la funzione esponenziale $e^z$
non è univocamente invertibile e quindi non si può definire il 
logaritmo $\ln z$ se non come funzione \emph{multivoca}.
}%
\[
  e^z = \exp z = e^x\cdot (\cos y + i\sin y), \qquad \text{se $z=x+iy$}.  
\]

Si noti che la funzione esponenziale complessa è $2\pi i$ periodica, infatti 
se $z=x+iy$ si ha 
\[
\exp(z+2\pi i) 
= e^x\cdot (\cos(y+2\pi) + i\sin(y+2\pi)) 
= e^x\cdot (\cos y + i \sin y) 
= \exp(z).
\]

% Nel capitolo precedente abbiamo introdotto l'esponenziale complesso ed
% abbiamo osservato che la funzione $f\colon \RR \to \CC$ definita da
% $f(t) = e^{it}$ ha valori sulla circonferenza unitaria in quanto
% $\abs{e^{it}}=1$. Tramite la definizione~\ref{def:sincos}
% abbiamo introdotto le funzioni seno e coseno in
% modo che risulti $f(t) = \cos t + i \sin t$.
% Sappiamo che $f(0) = e^0 = 1$ e, per come abbiamo definito $\pi$,
% sappiamo che $f(\pi/2) = i$.

\subsection{rappresentazione polare dei numeri complessi}

Per come li abbiamo definiti i numeri complessi $z\in \CC$ si possono 
rappresentare nella forma:
\[
  z = x + i y.
\]
Questa rappresentazione dei numeri complessi viene chiamata \emph{cartesiana}
perché fa corrispondere ogni numero $z$ alle sue coordinate $(x,y)$ nel
piano complesso (piano di Gauss). 

Grazie alla definizione di esponenziale complesso possiamo anche 
dare una rappresentazione \emph{polare} dei numeri complessi.
Se $z=x+iy$ è un qualunque numero complesso possiamo definire 
$\rho = \abs{z} = \sqrt{x^2+y^2}$ il suo \emph{modulo} 
ovvero la distanza geometrica tra il punto $z$ del piano complesso 
e l'origine $0\in \CC$.
Se $z\neq 0$ possiamo definire la misura dell'angolo individuato 
da $z$ con l'asse delle $x$ come quell'unico 
$\theta \in \closeopeninterval{0}{2\pi}$ tale che
\[
  \begin{cases}
    x = \rho \cos \theta,\\
    y = \rho \sin \theta.
  \end{cases}
\]
Si ha quindi 
\[
  z = \rho \cdot (\cos \theta + i \sin \theta). 
\]
La coppia di numeri $(\theta,\rho)$ con $\rho>0$ e $\theta\in\closeopeninterval{0}{2\pi}$ 
si chiamano \emph{coordinate polari} del numero complesso $z$ 
e identificano univocamente $z$. 
Per la periodicità delle funzioni $\sin$ e $\cos$ risulta chiaro 
che l'angolo $\theta$ può essere sostitutito con $\theta +2k\pi$ 
per qualunque $k\in \ZZ$ lasciando invariato il punto $z$.
Se $z=0$ allora $\rho=\abs{z}=0$ e la coordinata $\theta$ è irrilevante.

La rappresentazione \emph{esponenziale} di un numero complesso 
è sostanzialmente identica alla rappresentazione polare 
ma utilizza l'esponenziale complesso invece che 
le funzioni trigonometriche. 
Essendo $e^{i\theta} = \cos \theta + i\sin \theta$
se $z=\rho\cdot (\cos \theta + i \sin \theta)$ potremo scrivere:
\[
  z = \rho \cdot e^{i\theta}.  
\]

Se $z=\rho e^{i\theta}$
il numero $\theta$ viene usualmente chiamato \emph{argomento}
del numero complesso $z$ e si denota a volte 
in questo modo:
\[
  \theta = \arg z.  
\]
La definizione di argomento è intrinsecamente ambigua 
in quanto $\theta$ non è univocamente determinato
(al posto di $\theta$ possiamo scegliere $\theta+2k\pi)$ 
con qualunque $k\in \ZZ$).
Per avere una definizione univoca si può imporre 
la condizione $\theta\in\closeopeninterval{0}{2\pi}$.
\mynote{Ma la condizione 
$\theta\in\closeinterval{-\pi}{\pi}$ 
andrebbe ugualmente bene.}
Se $z=0$ possiamo definire, arbitrariamente, 
$\arg z = 0$. 
In formule si ha:
\[
  \arg z =
  \begin{cases}
%   \arctg \frac y x & \text{se $x>0$,} \\
   \frac \pi 2 - \arctg \frac x y & \text{se $y>0$,} \\
   \frac 3 2 \pi- \arctg \frac x y & \text{se $y<0$,} \\
   \pi & \text{se $y=0$ e $x<0$,} \\
   0 & \text{se $y=0$ e $x\ge 0$.}
   \end{cases}
\]

\subsection{radici complesse $n$-esime}

Sia $c\in \CC$ un numero
complesso $c\neq 0$.
Ci poniamo il problema di determinare le soluzioni complesse
dell'equazione
\[
  z^n = c.
\]
Tali soluzioni saranno chiamate \emph{radici $n$-esime}%
\mymargin{radici $n$-esime}%
\index{radice!$n$-esima} di $c$.

Scriviamo $c$ e $z$ in forma esponenziale:
\[
  c = r e^{i\alpha}, \qquad
  z = \rho e^{i\theta}.
\]
Si avrà allora
\[
  z^n = \rho^n (e^{i\theta})^n = \rho^n e^{i n \theta}.
\]
Affinche sia $z^n = c$ si dovrà avere l'uguaglianza dei moduli, cioè $\rho^n = r$ e l'uguaglianza a meno di multipli interi di $2\pi$ degli argomenti:
$n \theta = \alpha + 2 k \pi$ con $k\in \ZZ$.
Dunque si trova
\[
  \theta = \frac{\alpha}{n} + k\frac{2\pi}{n}
\qquad k \in \ZZ.
\]
Osserviamo ora che per $k=0,\dots, n-1$ il secondo addendo
$k 2\pi /n$ assume $n$ valori distinti compresi in $[0,2\pi)$.
Per gli altri valori di $k$ si ottengono degli angoli che differiscono
da questi di un multiplo di $2\pi$ e quindi non si trovano
altre soluzioni.

Dunque l'equazione $z^n = c$ per $c\neq 0$ ha $n$ soluzioni distinte date
da
\[
z_k = \sqrt[n]{r} \cdot e^{i\alpha/n + 2k\pi i /n},
\qquad k=0,1, \dots, n-1
\]
dove $\alpha = \arg(c)$ e $r = \abs{c}$.
Dal punto di vista geometrico si osserva che
$z_0$ è il numero complesso con modulo la radice $n$-esima del numero
dato $c$ e argomento pari ad un $n$-esimo dell'argomento di $c$.
Tutte le altre soluzioni si trovano sulla circonferenza centrata in $0$
e passante per $z_0$ e risultano essere, insieme ad $z_0$, i vertici
di un $n$-agono regolare.

In particolare nel caso $c=1$ si osserva che le radici $n$-esime dell'unità
si rappresentano geometricamente come i vertici dell'$n$-agono regolare iscritto
nella circonferenza unitaria e con un vertice in $z_0=1$.

\begin{exercise}
Si trovino le soluzioni $z \in \CC$ delle seguenti equazioni.
Scrivere le soluzioni in forma polare e cartesiana.
\begin{gather*}
   z^4 = -4 \\
   z^6 = i\\
   z^3 = -8i \\
   z^4 = z\\
   z^2 + 1 = i\sqrt{3} \\
   (z-i)^4 = 1\\
   1 + z + z^2 + z^3 = 0\\
   z^{14} - z^6 - z^8 + 1 = 0
\end{gather*}
\end{exercise}

\section{polinomi complessi}
\label{ch:ancora_polinomi}

\subsection{il teorema fondamentale dell'algebra}

Il teorema fondamentale dell'algebra afferma che ogni polinomio non costante 
si annulla in almeno un punto del piano complesso.
\mynote{si vedano le note storiche a fine capitolo}
Per dimostrare il teorema dobbiamo estendere il teorema 
di Weierstrass alle funzioni di una variabile complessa.
Nel teorema di Weierstrass reale la funzione per ipotesi è definita su un intervallo
chiuso e limitato. 
Nel piano complesso non esiste il concetto di \emph{intervallo} in quanto non abbiamo 
un ordinamento ma vedremo che comunque il teorema di Weierstrass rimane valido per 
le funzioni continue definite su insiemi chiusi e limitati secondo le seguenti definizioni.

\begin{definition}[chiusura sequenziale]
Un insieme $A\subset \CC$ si dice
essere \emph{sequenzialmente chiuso}
\mymargin{sequenzialmente chiuso}%
\index{sequenzialmente!chiuso}%
se presa una qualunque successione
di punti $a_n\in A$ se $a_n \to a$ per qualche $a\in \CC$
allora $a\in A$.
\end{definition}

\begin{definition}[limitatezza]
Un insieme $A\subset \CC$ si dice essere \emph{limitato}%
\mymargin{limitato}%
\index{limitato}
se
\[
  \sup \ENCLOSE{ \abs{z}\colon z \in A} < +\infty.
\]
\end{definition}

Si noti che una successione $a_n\in \CC$ 
è limitata (si veda capitolo~\ref{sec:successione_limitata})
se e solo se la sua immagine $\ENCLOSE{a_n\colon n\in \NN}\subset \CC$
è un insieme limitato.

% \begin{theorem}[Bolzano-Weierstrass complesso]
% Se $z_n\in \CC$ è una successione limitata allora
% è possibile estrarre una sottosuccessione $z_{n_k}$ convergente:
% $z_{n_k} \to z$ con $z\in \CC$.
% \end{theorem}
% %
% \begin{proof}
% Siano $x_n$ e $y_n$ la parte reale ed immaginaria di $z_n$: $z_n = x_n + i y_n$. Visto che $\abs{x_n} =\sqrt{x_n^2}\le \sqrt{x_n^2+y_n^2} = \abs{z_n}$ e, allo stesso modo $\abs{y_n} \le \abs{z_n}$,
% possiamo affermare che entrambe le successioni $x_n$ e $y_n$ sono limitate (ma stavolta in $\RR$).
% Dunque possiamo applicare il teorema di Bolzano-Weierstrass (reale) alla successione $x_n$ per trovare una sottosuccessione $x_{n_j}\to x$ convergente. E possiamo applicare di nuovo il teorema di Bolzano-Weierstrass alla sottosuccessione $y_{n_j}$ per trovare una sotto-sottosuccessione $y_{n_{j_k}}\to y$ anch'essa convergente.
% Posto $n_k = n_{j_k}$ avremo dunque trovato una sottosuccessione $z_{n_k} = x_{n_k} + i y_{n_k} \to x+iy$ convergente.
% \end{proof}

\begin{theorem}[Weierstrass complesso]
Sia $A\subset \CC$ un insieme non vuoto, sequenzialmente chiuso e limitato e sia $f\colon A \to \RR$ una funzione continua.
Allora $f$ ha massimo e minimo su $A$.
\end{theorem}
%
\begin{proof}
Dimostriamo l'esistenza del minimo: per il massimo la dimostrazione è perfettamente analoga.
Sia $m=\inf f(A)$.
Essendo $A$ non vuoto, per il lemma sull'esistenza delle successioni minimizzanti sappiamo esistere una successione $z_n \in A$ tale che $f(z_n) \to m$.
Essendo $A$ limitato possiamo applicare il teorema di Bolzano-Weierstrass per trovare $z\in \CC$ e una sottosuccessione $z_{n_k} \to z$. Essendo $A$ sequenzialmente chiuso possiamo quindi affermare che $z\in A$. Essendo $f$ continua concludiamo che
\[
f(z) = \lim_{k\to+\infty} f(z_{n_k}) = m
\]
e dunque $z$ è un punto di minimo per $f$.
\end{proof}

\begin{theorem}[esistenza del minimo per funzioni coercive]
Sia $f\colon \CC \to \RR$ una funzione continua tale che per ogni
successione $z_n \to \infty$ (ovvero $\abs{z_n}\to +\infty$)
si abbia $f(z_n) \to +\infty$.
Allora $f$ ha minimo.
\end{theorem}
%
\begin{proof}
Consideriamo l'insieme
\[
  A = \ENCLOSE{z \in \CC \colon f(z) \le f(0)}.
\]
Chiaramente $0\in A$ e quindi $A$ non è vuoto.
L'insieme $A$ è anche sequenzialmente chiuso in quanto se $z_k\in A$ allora $f(0) - f(z_k)\ge 0$,
per continuità $f(0)-f(z_k)\to f(0)-f(z)$
e per il teorema della permanenza del segno si ottiene $f(0)-f(z) \ge 0$ cioè $z \in A$.
Dimostriamo ora che $A$ è anche limitato. 
Se non lo fosse esisterebbe, per assurdo, una successione $z_n \in A$ tale che $\abs{z_n}\to +\infty$ cioè $z_n \to \infty$. 
Ma allora, per ipotesi su $f$, si avrebbe $f(z_n)\to +\infty$ che contraddice la condizione $f(z_n) \le f(0)$. 
Essendo $A$ non vuoto, sequenzialmente chiuso e limitato ed essendo $f\colon A \to \RR$ continua, 
possiamo applicare il teorema di Weierstrass complesso per dedurre che $f$ ha minimo su $A$ in un punto $w \in A$. 
Ma essendo $0\in A$ si avrà sicuramente $f(w)\le f(0)$ e per ogni $z\in \CC \setminus A$ si ha invece $f(z) > f(0)$ per come è stato definito $A$. 
Dunque $w$ è minimo di $f$ su tutto $\CC$, non solo su $A$.
\end{proof}

\begin{theorem}[teorema fondamentale dell'algebra]
\label{th:fondamentale_algebra}
\mymargin{teorema fondamentale dell'algebra}%
\index{teorema!fondamentale dell'algebra}%
Sia $f(z)$ un polinomio di grado $N\ge 1$ a coefficienti complessi:
\[
  f(z) = \sum_{j=0}^N a_j \cdot z^j
\]
con $a_j\in \CC$ per $j=0,\dots,N$ e $a_N \neq 0$.
Allora esiste $w\in \CC$ tale che $f(w) = 0$.
\end{theorem}
%
\begin{proof}
  Osserviamo innanzitutto che $\abs{f(z)}$ è coerciva cioè che
  se $z_n \to \infty$ allora $\abs{f(z_n)}\to +\infty$.
  Infatti si ha
  \begin{align*}
    \abs{f(z_n)}
    &= \abs{\sum_{j=0}^N a_j z_n^j}
    = \abs{a_N z_n^N  + \sum_{j=0}^{N-1} a_j z_n^j}\\
    &= \abs{z_n}^N \cdot \abs{a_N + \sum_{j=0}^{N-1} \frac{a_j}{z_n^{N-j}}}
    \to +\infty
  \end{align*}
  se $z_n \to \infty$.
  
  Sappiamo che tutti i polinomi sono funzioni continue in quanto somme di 
  prodotti di funzioni continue e il modulo è anch'esso una funzione continua 
  dunque $\abs{f(z)}$ è certamente una funzione continua.
  
  Dunque possiamo applicare il teorema di esistenza del minimo per le funzioni 
  coercive: esiste $w\in \CC$ tale che $\abs{f(w)}$ è minimo.
  
  Per concludere il teorema basterà dimostrare che $f(w)=0$.
  L'idea che vogliamo sviluppare è che i polinomi complessi se assumono un valore
  $f(w)$ in un punto $w\in \CC$ allora assumono anche tutti i valori vicini
  ad esso in quanto \emph{localmente} il polinomio assomiglia ad una potenza $z^n$
  e l'equazione $z^n=c$ ha sempre soluzione, come abbiamo già visto.
  Dunque vicino a $w$ ci saranno dei punti in cui $f$ assume valori che in modulo 
  sono minori a $f(w)$: a meno che non sia proprio $f(w)=0$, nel qual caso 
  ovviamente non è possibile avere numeri con modulo inferiore a $0$.
  
  Possiamo scrivere il polinomio $f(z)$ nella forma
  \[
    f(z) = \sum_{j=0}^N b_j (z-w)^j
  \]
  in quanto la traslazione di un polinomio è ancora un polinomio dello stesso 
  grado.
  Dimostrare che $f(w)=0$ è quindi equivalente a dimostrare che $b_0=0$.
  Supponiamo allora per assurdo che sia $b_0\neq 0$. 
  L'andamento del polinomio vicino al punto $w$ è dominato dai termini di grado 
  più basso: alcuni di questi potrebbero essere nulli, ma possiamo considerare 
  il primo indice $k>0$ per cui si ha $b_k\neq 0$. Allora potremo scrivere:
  \[
      f(z) = b_0 + b_k(z-w)^k + \sum_{j=k+1}^N b_j (z-w)^j.
  \]
Ora scriviamo $z-w$, $b_0$ e $b_k$ in forma esponenziale:
$z - w = \rho e^{i\theta}$, $b_0 = r e^{i \alpha_0}$,
$b_k = r_k e^{i\alpha_k}$ 
e applichiamo la disuguaglianza triangolare
  \begin{align*}
    \abs{f(z)} 
    &= \abs{r e^{i\alpha} + r_k \rho^k e^{i(\theta k+\alpha_k)} 
    + \sum_{j=k+1}^N b_j \rho^j e^{i\theta j}} \\
    &\le \abs{r e^{i\alpha} + r_k \rho^k e^{i(\theta k + \alpha_k )}} 
    + \sum_{j=k+1}^N \abs{b_j} \rho^j.
  \end{align*}
Per raggiungere un assurdo vogliamo dimostrare che esiste $z$ (cioè esistono $\rho$ e $\theta$)
per cui il valore della funzione risulti in modulo minore di $r = \abs{b_0} = \abs{f(w)}$.
Innanzitutto se $\rho$ è sufficientemente piccolo possiamo rendere arbitrariamente piccole 
le potenze $\rho^j$ con $j>k$: basta scegliere $\rho\le 1$ 
e $\rho \le r_k/(2\sum \abs{b_j})$
cosicché si avrà 
\[
  \sum_{j=k+1}^N \abs{b_j} \rho^j
  \le \rho^{k+1} \sum_{j=k+1}^N \abs{b_j} \le r_k\frac{\rho^{k}}{2}.
\]
Per quanto riguarda il termine
$r e^{i\alpha} + r_k \rho^k e^{i(\theta k + \alpha_k)}$ 
sarà sufficiente scegliere $\theta = (\pi + \alpha - \alpha_k) /k$ 
in modo che i due addendi 
abbiano fase opposta e la somma sia distruttiva:
\[
  \abs{r e^{i\alpha} + r_k \rho^k e^{i(\theta k + \alpha_k)}}
  = \abs{e^{i\alpha}(r + r_k \rho^k e^{i\pi})}
  = r - r_k\rho^k.
\]
In definitiva abbiamo
\[
\abs{f(z)} = \abs{f(w+\rho e^{i\theta})} 
\le r - r_k\rho^k + r_k\frac{\rho^k}{2} 
< r = \abs{f(w)}
\]
che è assurdo in quanto $\abs{f(w)}$ doveva essere il valore minimo.
\end{proof}
  
\subsection{fattorizzazione dei polinomi}

\begin{theorem}[fattorizzazione dei polinomi complessi]
\index{decomposizione!dei polinomi complessi}%
\index{fattorizzazione!dei polinomi complessi}%
\index{polinomio!fattorizzazione complessa}%
Sia $p(z)$ un polinomio non nullo. Allora posto $n=\deg p$ esistono dei numeri complessi $z_1, z_2, \dots, z_n$ ed un numero complesso $c\neq 0$ tali che
\begin{equation}\label{eq:34985}
  p(z) = c \prod_{k=1}^n (z-z_k).
\end{equation}
Gli $z_k$ sono unici a meno dell'ordine e $c$ pure è univocamente determinato.
\end{theorem}
%
\begin{proof}
Dimostriamo il teorema per induzione su $n=\deg p$. Se $n=0$ il polinomio $p$ è costante: $p(z) = c$. Ricordando che un prodotto di $n=0$ fattori è uguale a $1$ si ottiene quindi il risultato voluto.

Sia ora $p(z)$ un qualunque polinomio di grado $n>0$. Per il teorema fondamentale dell'algebra sappiamo che esiste un numero complesso $z_n$ tale che $p(z_n)=0$. Per il teorema di Ruffini si ha allora
\[
  p(z) = (z-z_n) q(z)
\]
con $q$ un qualche polinomio di grado $n-1$. Per ipotesi induttiva possiamo dunque supporre che esistano $z_1, \dots, z_{n-1}$ e $c$ numeri complessi tali che
\[
   q(z) = c \prod_{k=1}^{n-1} (z-z_k)
\]
e la tesi segue.
\end{proof}

Nella fattorizzazione~\eqref{eq:34985} le \emph{radici} $z_k$ possono
anche ripetersi. Se mettiamo insieme i fattori corrispondenti alla stessa radice
si ottiene una decomposizione della forma
\begin{equation}\label{eq:358925}
P(z) = c \prod_{k=1}^m (z-z_k)^{p_k}
\end{equation}
con $z_1, \dots, z_m$ numeri complessi distinti (le radici del polinomio $P$)
e $p_k$ interi positivi.
L'esponente $p_k$ si chiama
\emph{molteplicità}%
\mymargin{molteplicità}%
\index{molteplicità} della radice $z_k$ e risulta
\[
  p_1 + \dots + p_m = n.
\]
Questa uguaglianza si esprime dicendo che un polinomio $P\in \CC[z]$
di grado $n$ ha sempre $n$ radici contate con la loro molteplicità.
Le radici distinte sono invece $m\le n$.

Se invece $P\in \RR[x]$ è un polinomio a coefficienti reali
non è detto che $P$ abbia radici: ad esempio il
polinomio $x^2+1$ non ha radici reali in quanto $x^2+1>0$
come succede in ogni campo ordinato.
Potrà allora essere utile pensare a $P$ come ad un polinomio
in $\CC[x]$ con coefficienti reali.

Se $P\in \RR[x]$ è un polinomio a coefficienti reali
\[
  P = \sum_{k=0}^n a_k x^k, \qquad a_k\in \RR
\]
possiamo pensare a $P$ anche come un polinomio in
$\CC[x]$, visto che $a_k\in \RR\subset \CC$.
Il seguente teorema ci dà un criterio per distinguere
i polinomi a coefficienti reali dentro a $\CC[x]$.

\begin{theorem}
\label{th:caratterizzazione_polinomi_reali}%
Se $P\in \CC[x]$ è un polinomio a coefficienti complessi
\[
  P = \sum_{k=0}^n a_k x^k,\qquad a_k\in \CC
\]
e se esiste un insieme infinito $A\subset \RR$
tale che per ogni $x\in A$ si abbia $P(x)\in \RR$
allora $a_k\in\RR$ per ogni $k=0,\dots,n$ e dunque $P\in \RR[x]$.

In particolare se la funzione polinomiale associata a
$P\in\CC[x]$ manda $\RR$ in $\RR$ allora $P$ è un polinomio
a coefficienti reali.
\end{theorem}
%
\begin{proof}
Consideriamo il polinomio:
\[
  Q = \sum_{k=0}^n (a_k-\bar a_k) x^k.
\]
Allora per ogni $x\in A$ si ha
\[
  Q(x) = \sum_{k=0}^n a_k x^k - \sum_{k=0}^n \bar a_k x^k
     = P(x) - \overline{P(x)} = P(x) - P(x) = 0
\]
in quanto se $x\in \RR$ risulta
$\overline{x^k} = {\bar x}^k = x^k$.
Visto che $A$ è infinito,
per il principio di annullamento dei polinomi
(teorema~\ref{th:annullamento_polinomi})
deduciamo che $Q=0$.
Ma allora tutti i coefficienti di $Q$ devono
essere nulli e cioè $\bar a_k = a_k$.
Ne consegue che $a_k\in \RR$ per ogni $k=0,\dots,n$.
\end{proof}

Rifacendoci alla fattorizzazione dei polinomi a coefficienti
complessi possiamo fattorizzare anche i polinomi a coefficienti
reali se ci accontentiamo di avere fattori quadratici
invece che lineari.

\begin{theorem}[fattorizzazione dei polinomi reali]
  \label{th:fattorizzazione_polinomio_reale}%
Se $P\in \RR[x]$ è un polinomio a coefficienti reali
potremo scrivere
\begin{equation}\label{eq:35549}
  P = a \cdot \prod_{k=1}^n (x-x_k)^{p_k} \cdot \prod_{j=1}^m (x^2 + \alpha_j x + \beta_j)^{q_j}
\end{equation}
dove $a\in \RR$, $x_k\in \RR$, $p_k\in \NN\setminus\ENCLOSE{0}$,
$\alpha_j,\beta_j\in \RR$, $q_j\in \NN\setminus\ENCLOSE{0}$
con $\alpha_j^2 - 4 \beta_j < 0$
e
\[
  \sum_{k=1}^n p_k + 2 \sum_{j=1}^m q_j = \deg P.
\]

La fattorizzazione~\eqref{eq:35549} è unica a meno
dell'ordine dei fattori.

I numeri $x_1,\dots,x_n$ sono tutte le radici reali distinte
del polinomio $P$ con rispettive molteplicità
$p_1,\dots,p_n$ mentre tutte le radici complesse (non reali)
distinte saranno $\mu_1,\dots, \mu_m$
e $\bar \mu_1, \dots, \bar \mu_m$ con
\[
  x^2 + \alpha_j x + \beta_j = (x-\mu)\cdot(x-\bar \mu)
\]
da cui
\[
  \alpha_j = -2\Re \mu_j, \qquad \beta_j=\abs{\mu_j}^2
\]
e $q_j$ saranno le molteplicità delle radici $\mu_j$
 e $\bar \mu_j$.
\end{theorem}
%
\begin{proof}
Osserviamo innanzitutto che se $P$ è a coefficienti reali
si ha
\[
  \overline{P(z)} = P(\bar z), \qquad \forall z\in \CC
\]
dunque se $\mu$ è una radice di $P$ anche $\bar \mu$
è una radice di $P$.
Ora se $\mu$ è una radice non reale di $P$ sappiamo
che in campo complesso $P$ risulta divisibile
per $x-\mu$ (teorema~\ref{th:Ruffini} di Ruffini):
\[
  P = (x-\mu) \cdot P_1.
\]
Ma anche $\bar \mu$ è radice di $P$ ed essendo
$\bar \mu \neq \mu$ si dovrà avere
\[
Q(\bar \mu) = \frac{P(\bar \mu)}{\bar \mu - \mu} = 0
\]
e dunque applicando nuovamente il teorema di Ruffini
\[
 P = (x-\mu)\cdot (x-\bar \mu)\cdot P_2.
\]
Ora osserviamo che
\[
(x-\mu)\cdot(x-\bar \mu) = x^2 - (\mu + \bar \mu) x + \mu \bar \mu
 = x^2 - 2 (\Re \mu)\cdot x + \abs{\mu}^2
\]
è un polinomio a coefficienti reali e
visto che $P_2$ si ottiene dividendo $P$ per tale polinomio,
anche $P_2$ è un polinomio a coefficienti reali.

Ripetendo lo stesso procedimento sul polinomio $P_2$
potremo fattorizzare $P$ diminuendo il grado a passi
di $2$ finché non si esauriscono tutte le radici complesse
non reali accoppiandole a due a due.
Dunque se $\mu$ è una radice complessa
del polinomio reale $P$ la molteplicità di $\mu$ è
uguale alla molteplicità di $\bar \mu$.

Dopodiché
si potrà completare la fattorizzazione dividendo
per i fattori lineari $x-x_k$ corrispondenti
alle radici reali del polinomio $P$.
Si otterrà quindi la fattorizzazione desiderata.
\end{proof}


\section{note storiche}

\subsection{il numero $e$}

\begin{figure}
  \begin{center}
  \includegraphics[width=10cm]{napier_tables.jpg}
  \end{center}
  \caption{Una pagina delle tavole calcolate da John Napier
  con i valori della funzione $\sin$ (Sinus) e del suo logaritmo
  (Logarithmi).
  In questa pagina ci sono i valori 
  per gli angoli dai 9 gradi (Gr.) ai 9 gradi e mezzo (i gradi 
  sessagesimali sono suddivisi in 60 minuti) e 
  dei loro complementari dagli 80 gradi e mezzo agli 81 gradi.
  Il codice scritto a pag.~\pageref{code:napier} permette
  di calcolare in pochi centesimi di secondo gli stessi valori
  mettendo anche in evidenza alcuni errori sulle ultime cifre decimali.
  Napier ci mise 20 anni a completare la stesura 
  delle tavole da 0 a 90 gradi.
  Se ad esempio volessimo calcolare il valore della tangente di $\alpha=9$ gradi 
  potremmo osservare che il logaritmo di $\tg \alpha$ 
  è la differenza tra il logaritmo di $\sin \alpha$ e il 
  logaritmo di $\cos \alpha$.
  Essendo il $\cos$ uguale al seno dell'angolo complementare 
  troviamo questo valore nella tabella in figura, 
  riga 0, colonna 
  \emph{Differenti\ae}: $1.8427293$ 
  (tutti i valori sono moltiplicati per $10^7$).
  Il valore cercato è l'esponenziale di questo 
  logaritmo e possiamo quindi calcolarlo cercando 
  lo stesso valore nella colonna \emph{Logarithmi}
  e prendendo il corrispondente valore nella colonna 
  \emph{Sinus}. Il valore è compreso tra i valori 
  della riga 6 e della riga 7. Più precisamente 
  differisce dal valore nella riga 7 
  $\frac{3842}{18143}$ volte quanto differisce il valore 
  della riga 6 dal valore della riga 7. 
  Applicando lo stesso rapporto ai valori trovati 
  nella colonna \emph{Sinus} si ottiene
  per interpolazione che al valore 
  della riga 7 (pari a 1.584453) và 
  sottratto 608 ottenendo quindi $\tg \alpha \approx 0.1583845$
  che differisce dal valore 
  esatto per meno di $10^{-7}$.
  }
  \label{fig:napier}
\end{figure}

\label{nota:Nepero}%
\index{Napier!John}%
\index{Nepero}%
\label{Euler!Leonhard}%
\label{Eulero}%
Nepero è l'italianizzazione del nome del
matematico scozzese \emph{John Napier} (1550-1617)
che per compilare le tavole della funzione seno
con una precisione di 7 cifre decimali ha introdotto 
per primo la funzione logaritmo (si veda la figura~\ref{fig:napier}).
E' interessante notare che Napier ha definito direttamente 
il logaritmo naturale senza introdurre il numero $e$ 
e senza fare alcun collegamento con la funzione esponenziale.
% https://archive.org/details/johnnapierinvent00hobsiala/page/18/mode/2up

\label{note:Bernoulli}%
\index{Bernoulli!Jacob}%
L'individuazione della costante $e$
è dovuta a \emph{Jacob Bernoulli} (1655--1705) nel 1683.
Bernoulli si chiedeva qual è l'interesse annuo effettivo
che si ottiene da un capitale che dia una rendita
giornaliera.
Se investo un capitale $c$ ad un tasso di interesse annuo 
pari a $r$, alla fine dell'anno mi viene restituito 
il capitale $c$ più un interesse $rc$.
Se divido il guadagno $rc$ per il numero di giorni che ci sono in 
un anno, posso considerare di aver avuto un guadagno giornaliero
pari a $\frac{r}{365} c$.
Se il guadagno giornaliero $\frac{r}{365} c$ mi venisse restituito 
immediatamente ogni giorno dell'anno, potrei reinvestire immediatamente 
il guadagno facendo aumentare il capitale durante l'anno.
In tal modo se parto con un capitale $c$ ogni giorno il mio capitale 
aumenterebbe di un fattore $1+\frac{r}{365}$ e
alla fine dell'anno avrei quindi un guadagno
pari a $\enclose{1+\frac{r}{365}}^{365} \approx e^r$ 
volte il capitale iniziale (interesse composto).

Il nome $e$ è stato introdotto da Eulero (Leonhard Euler 1707-1783).
%http://eulerarchive.maa.org//docs/originals/E853.pdf

\subsection{il teorema fondamentale dell'algebra}

La formula risolutiva per determinare le radici di un polinomio di secondo grado 
era già nota ai Babilonesi e sebbene i numeri complessi non erano noti 
(e neanche i numeri negativi) la stessa formula si applica 
nel caso generale e fornisce le radici complesse.

Lo studio delle equazioni di grado superiore al secondo si sviluppa invece 
nel 1500 ad opera dei matematici italiani Scipione del Ferro, 
Gerolamo Cardano, Niccolò Tartaglia e Lodovico Ferrari.
Essi determinano le formule risolutive per determinare le radici 
dei polinomi di terzo e quarto grado. 
Nell'applicare la formula risolutiva per l'equazione di terzo grado 
può capitare di dover calcolare la radice quadrata di un numero negativo
anche in situazioni in cui tutte le soluzioni alla fine risultano reali.
Ed è proprio in questo contesto che nascono i numeri complessi, come 
mero artificio matematico utilizzato per portare a termine il conto.

Successivamente Paolo Ruffini (1765-1822) e Niels Abel (1802-1829) dimostrarono che le equazioni 
di grado maggiore del quarto non ammettono una formula risolutiva 
esprimibile mediante radicali. 
Il criterio per determinare se un polinomio
ammette o meno formule risolutive è dovuto al matematico francese Évariste Galois
(1811-1832) che è considerato il fondatore della teoria dei gruppi.

Il teorema fondamentale dell'algebra, e cioè l'esistenza di radici 
complesse per polinomi di grado qualunque, viene dimostrato dal 
matematico tedesco Carl Friedrich Gauss (1777--1855). 
Questo teorema opera una svolta nel pensiero matematico in quanto 
per la prima volta si dà rilevanza ad un risultato astratto di esistenza 
slegato da una formula risolutiva. 
Il teorema non era affatto scontato, basti pensare che sia Leibniz 
che Nikolas Bernoulli erano convinti di aver trovato dei polinomi 
di quarto grado che non possono essere fattorizzati in contrasto 
con il teorema~\ref{th:fattorizzazione_polinomio_reale}.

\subsection{il problema isoperimetrico}

\label{note:isoperimetrico}%
\index{problema!isoperimetrico}%
Probabilmente già dal IX secolo a.C.\ era noto ai greci che 
la circonferenza, tra tutte le linee piane di lunghezza prefissata, 
è quella che racchiude la maggiore area (proprietà isoperimetrica).
Nell'Eneide Virgilio racconta che Didone si trovò ad affrontare 
un problema simile nella fondazione di Cartagine.
\index{Didone}%
\index{isoperimetrico!problema}%
\index{problema!isoperimetrico}%
\index{problema!di Didone}%
Salendo alla dimensione $n=3$ è naturale immaginare che 
la superficie che racchiude il volume maggiore con area fissata 
sia la sfera. 
Questo spiega il motivo per cui una goccia d'acqua, in assenza di gravità,
dovrebbe assumere una forma sferica: a causa della tensione superficiale, 
infatti, la superficie della goccia tenderà ad avere l'area minima.
Eulero (\emph{Leonhard Euler} 1707--1783)
\index{Euler!Leonhard}%
\index{Eulero}%
pensò di aver
trovato una dimostrazione
che si fondava su questo risultato:
presa una qualunque superficie chiusa nello spazio,
se questa non è una sfera è possibile
farne una piccola modifica in modo da ottenere una nuova superficie
che racchiude lo stesso volume ma che ha area strettamente inferiore.
Fu proprio Karl Weiestrass (1815--1897)
\index{Weiestrass!Karl}%
ad accorgersi che quanto dimostrato da Eulero 
(e poi successivamente da Steiner) 
non è sufficiente a garantire la minimalità della sfera. 
Infatti Eulero dimostra che non ci può essere un minimo che non sia la sfera, 
ma non dimostra che il minimo esiste e quindi non è detto che la sfera sia il minimo: 
potrebbero esserci infinite superfici $S_1, S_2, \dots, S_n, \dots$ 
ognuna con area minore di quella della sfera e ognuna con area maggiore della successiva: 
$A(S_{n+1})< A(S_n)$. 
Per concludere il ragionamento di Eulero era necessario dimostrare 
che in una situazione del genere le superifici $S_n$ debbano, in qualche senso, 
tendere alla superficie sferica e che le loro aree debbano
tendere all'area della sfera. 
In astratto questo è quanto viene enunciato nel teorema di Weierstrass 
che così completò la dimostrazione della proprietà isoperimetrica
in dimensione $n=2$ (in realtà il risultato è comunque attribuito a Steiner che,
pur non avendo colto il problema obiettato da Weierstrass, aveva in effetti 
dimostrato tutte le proprietà necessarie per giungere alla conclusione).
La prima dimostrazione formale per $n\ge 3$ 
è dovuta al matematico italiano Ennio De Giorgi (1928--1996)
\index{De Giorgi!Ennio}%
che formalizzò il concetto di perimetro introdotto
da Renato Caccioppoli (1904--1959).%
\index{Caccioppoli!Renato}%
\index{Caccioppoli!perimetro}%
