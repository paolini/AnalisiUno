\section{operazioni con i simboli di Landau}
\label{sec:landau}

Le
\index{simboli di Landau}%
\index{Landau!simboli di}%
\index{$o$ piccolo}%
\index{o piccolo}%
\index{$O$ grande}%
\index{O grande}%
notazioni di Landau $o$-piccolo e $O$-grande sono comodissime per
l'elaborazione di stime asintotiche. Bisogna però fare molta attenzione a come queste notazioni vengono usate, perché altrimenti si rischia di fare degli errori grossolani. Alcuni risultati controintuitivi sono ad esempio:
\begin{enumerate}
\item $o(x) - o(x) = o(x)$ (e non $0$),
\item $o(x^2) = o(x)$ ma non $o(x) = o(x^2)$.
\end{enumerate}

Il secondo esempio, in particolare, ci dice che il simbolo di uguaglianza in realtà non è utilizzato in modo appropriato in questo contesto, perché non gode della proprietà simmetrica. In questa sezione proponiamo una definizione formalmente precisa dell'oggetto $o$-piccolo (e $O$-grande) e un modo rigoroso per manipolarlo e confrontarlo.

\begin{definition}[$o$-piccolo, $O$-grande]
Sia $A\subset \RR$, $x_0$ punto di accumulazione di $A$
e sia $g\colon A \to \RR$ una funzione positiva su $A$.
Definiamo allora gli insiemi di funzioni\mynote{%
ricordiamo che $A^B$ denota l'insieme delle funzioni $f\colon B \to A$}:
\begin{align*}
  o(g) &= \ENCLOSE{f\in \RR^A \colon \lim_{x\to x_0}\frac{f(x)}{g(x)} = 0};\\
  O(g) &= \ENCLOSE{f\in \RR^A \colon \limsup_{x\to x_0}\abs{\frac{f(x)}{g(x)}} < + \infty}\\
       &= \ENCLOSE{f\in \RR^A \colon \exists U\in \U_{x_0}, C>0 \colon \forall x \in U\colon \abs{\frac{f(x)}{g(x)}}\le C}.
\end{align*}
\end{definition}

Espressioni come ad esempio:
\[
  \sin x - x = o(x^2), \qquad \text{per $x\to 0$}
\]
vanno quindi interpretate come
\[
  f \in o(g)
\]
dove $f(x) = \sin x -x $ e $g(x) = x^2$.
In questa sezione scriveremo:
\begin{equation}\label{eq:39523}
  \sin x - x \in o(x^2)
\end{equation}
per dare risalto a questa interpretazione (e mettere in evidenza il fatto che la relazione non è affatto simmetrica).

Possiamo ora procedere ad interpretare le operazioni tra insiemi. In generale se $A$ e $B$ sono insiemi di oggetti su cui è definita una operazione $*$ (che potrebbe essere la somma, il prodotto, il rapporto...) definiamo:
\[
  A * B = \ENCLOSE{a*b \colon a \in A, b\in B}.
\]
Analogamente se $A$ è un insieme sui cui elementi è definita una operazione $*$ con un oggetto $b$, definiremo:
\[
  A * b = \ENCLOSE{a*b\colon a \in A}, \qquad
  b * A = \ENCLOSE{b*a\colon a \in A}.
\]
Ad esempio l'espressione
\[
  \sin x = x + o(x^2)
\]
andrebbe formalmente intesa come
\[
  \sin x  \in x + o(x^2)
\]
dove l'insieme $x+ o(x^2)$ è l'insieme di tutte le funzioni
$f$ che possono essere scritte nella forma $f(x) = x+h(x)$ con $h\in o(x^2)$ cioè $h$ tale che $h(x)/x^2 \to 0$. Risulta quindi che tale espressione è equivalente alla \eqref{eq:39523} in quanto se $\sin x = x + h(x)$ con $h\in o(x^2)$ significa che $\sin x- x \in o(x^2)$.

Possiamo allora enunciare le regole algebriche di manipolazione dei simboli di Landau.

\begin{theorem}[operazioni con i simboli di Landau]
Sia $A\subset \RR$, $x_0\in [-\infty, +\infty]$
punto di accumulazione per $A$.
Siano $f,g \colon A \to \RR$ funzioni positive, $c\in \RR$, $c\neq 0$, $n\in \NN$, $n\neq 0$.
Allora, per $x\to x_0$ si ha:
\begin{align*}
0 \in o(f) &\subset O(f) & f&\in O(f)& \\
c \cdot o(f) &= o(f) & c \cdot O(f) &= O(f)\\
o(f)+o(f) &= o(f) & O(f)+O(f) &= O(f)\\
o(f)-o(f) &= o(f) & O(f)-O(f) &= O(f)\\
o(f\cdot g) &= f \cdot o(g) & O(f\cdot g) &= f\cdot O(g)\\
o(g/f) &= o(g) / f & O(g/f) &= O(g) / f\\
o(f)\cdot o(g) &\subset o(f\cdot g) & O(f)\cdot O(g) &\subset O(f\cdot g) \\
o(f)\cdot O(g) & \subset o(f\cdot g)&  & \\
(o(f))^n &\subset o(f^n) & (O(f))^n &\subset O(f^n)\\
o(o(f)) &\subset o(f) & O(O(f)) &\subset O(f)\\
o(O(f)) &\subset o(f) & O(o(f)) &\subset o(f)
.
\end{align*}
Si osserva, in particolare, che $o(f)$ e $O(f)$ sono sottospazi vettoriali di $\RR^A$.

E' anche possibile applicare i cambi di variabile.
Se $f\in o(g)$ per $x\to x_0$ e $h(t) \to x_0$ per $t\to t_0$ allora
\[
  f \circ h \in o(g\circ h) \qquad \text{per $t\to t_0$}.
\]
\end{theorem}
%
\begin{proof}
Visto che $0/f = 0$ è ovvio che $0\in o(f)$.
L'inclusione $o(f) \subset O(f)$ discende dal fatto che se $h\in o(f)$ significa che $h/f\to 0$ per $x\to x_0$. Ma allora esiste un intorno di $x_0$ in cui $\abs{h/f}<1$ e dunque $h\in O(f)$. Ovviamente $f\in O(f)$ in quanto $f/f=1$ è una funzione limitata.

Se $h\in c \cdot o(f)$ significa che $h = c \cdot (h/c)$ e $h/c \in o(f)$ ovvero $(h/c)/f \to 0$. Ma questo è equivalente a $h/f\to 0$ visto che $c$ è una costante non nulla. Il caso degli $O$ grande si svolge in modo simile.

L'insieme $o(f)+o(f)$ è formato da funzione della forma $h+k$ con $h,k \in o(f)$. Ma si ha
\[
  \frac{h+k}{f} = \frac{h}{f} + \frac{k}{f} \to 0 + 0 = 0.
\]
Dunque $o(f)+o(f) \subset o(f)$. Viceversa osserviamo che se $h\in o(f)$ si può scrivere $h = h/2 + h/2$ e per quanto visto prima sappiamo che $h/2 \in o(f)$. Dunque $o(f) \subset o(f) + o(f)$.
Ragionamento simile si può fare per $O(f)$: la somma di due funzioni localmente limitate è anch'essa localmente limitata.

Osserviamo che $o(f)-o(f) = o(f) + (-1)\cdot o(f) = o(f) + o(f) = o(f)$
per quanto già visto. Lo stesso vale per $O(f)-O(f)$.

Se $h\in o(fg)$ significa che $h/(fg)\to 0$. Ma allora $h = f\cdot (h/f)$ con $h/f \in o(g)$ in quanto $(h/f)/g = h/(fg)\to 0$. Dunque $h \in fo(g)$ e di conseguenza $o(fg)\subset f \cdot o(g)$. Viceversa se $h \in f\cdot o(g)$ significa che $h = f \cdot(h/f)$ con $h/f \in o(g)$ ovvero $(h/f)/g \to 0$. Dunque $h/(fg) \to 0$ che significa $h\in o(fg)$.
Ragionamento analogo si può fare con gli $O$ grande.

I risultati per la divisione si riconducono a quelli della moltiplicazione osservando che la divisione per $f$ è uguale alla moltiplicazione per $1/f$.

Se $h\in o(f)$ e $k\in o(g)$ vogliamo mostrare che $hk\in o(fg)$.
Ma questo è ovvio essendo $(hk)/(fg) = (h/f)\cdot(k/g) \to 0\cdot 0 = 0$. Abbiamo mostrato che $o(f)o(g)\subset o(fg)$. Risultato analogo si ha negli altri due casi $O(f)O(g)\subset O(fg)$ e $o(f)O(g)\subset o(fg)$, osservando che il prodotto di due funzioni limitate è limitata e il prodotto di una limitata per una infinitesima è infinitesima.

Per quanto riguarda la potenza $(o(f))^n$ osserviamo che si ha:
\begin{align*}
  (o(f))^n &= \ENCLOSE{h^n \colon h\in o(f)}
      \subset \ENCLOSE{h_1 \cdots h_n \colon h_1, \dots, h_n \in o(f)}\\
      &= o(f) \cdots o(f) \subset o(f^n).
\end{align*}

Se $h\in o(o(f))$ significa che esiste $k\in o(f)$ e $h\in o(k)$. Dunque $k/f\to 0 $ e $h/k\to 0$. Ma allora $h/f = (h/k)\cdot (k/f) \to 0\cdot 0 = 0$ dunque $h \in o(f)$. Abbiamo quindi mostrato che $o(o(f)) \subset o(f)$. Dimostrazione analoga si può fare per gli $O$ grande. Anche le inclusioni $o(O(f))\subset o(f)$ e $O(o(f))\subset o(f)$ si dimostrano in modo analogo osservando che il prodotto di una funzione limitata per una infinitesima è infinitesima.

Per quanto riguarda il cambio di variabile, dobbiamo verificare che
\[
  \frac{f(h(t))}{g(h(t))} \to 0
  \qquad\text{per $t\to t_0$}
\]
se $f\in o(g)$ e se $h(t)\to x_0$ per $t \to t_0$. Ma questo non è altro che il cambio di variabile $x=h(t)$ nel limite $f(x)/g(x)\to 0$ per $x\to x_0$.
\end{proof}

\begin{example}
Sapendo che per $x\to 0$ si ha
\[
\sin x \in x + o(x^2), \qquad \cos x \in 1 - \frac {x^2}{2} + o(x^3)
\]
e ricordando che $x^3 \in o (x^2)$ possiamo dedurre, utilizzando le proprietà del teorema precedente:
\begin{align*}
2\cos x  - \sin x
&\in 2 - x^2 + 2o(x^3) - x - o(x^2)\\
&= 2- x - x^2 + o(x^3) + o(x^2)\\
&= 2- x - x^2 + o(o(x^2)) + o(x^2)\\
 &\subset 2 - x - x^2 + o(x^2) + o(x^2)\\
 &= 2-x-x^2 + o(x^2).
\end{align*}
Usualmente tutti questi passaggi vengono sottointesi, si utilizza il simbolo $=$ al posto di $\in$ e $\subset$ e spesso si preferisce scrivere sempre un solo $o(\cdot)$ alla fine di ogni espressione.
\end{example}

\begin{example}
Con gli stessi presupposti dell'esempio precedente potremo
scrivere:
\begin{align*}
(\sin^2 x)\cdot(2-2\cos x)^3
&\in (x+o(x^2))^2 \cdot (2 - (2- x^2 - 2o(x^3))^3 \\
&= (x+o(x^2))^2 \cdot (x^2+o(x^3))^3 \\
&= (x^2 + 2 x o(x^2) + (o(x^2))^2) \\
&\quad \cdot (x^6 + 3 x^4 o(x^3) + 3 x^2(o(x^3))^2 + (o(x^3))^3)\\
&\subset (x^2 + o(x^3) + o(x^4))\cdot(x^6 + o(x^7) + o(x^8) + o(x^9)) \\
&= (x^2 + o(x^3)) \cdot(x^6+o(x^7)) \\
&= x^8 + x^2o(x^7) + o(x^3) x^6 + o(x^3)o(x^7)\\
&= x^8 + o(x^9) + o(x^9) + o(x^{10})
= x^8 + o(x^9).
\end{align*}
\end{example}

\begin{example}
Possiamo anche fare un esercizio con il cambio di variabile.
Osservando che $y=1-\cos x\to 0$ per $x\to 0$
sapendo che $\sin y = y + o(y^2)$ per $y\to 0$
e che $2-2\cos x = x^2 + o(x^2)$ per $x\to 0$
possiamo scrivere
che per $x\to 0$ si ha:
\begin{align*}
\sin(2-2\cos x)
& \in (2-2\cos x) + o((2-2\cos x)^2) \\
& \subset x^2 + o(x^2) + o((x^2+o(x^2))^2) \\
& \subset x^2 + o(x^2) + o(O(x^4)) \\
& \subset x^2 + o(x^2) + o(x^4) \\
& = x^2 + o(x^2).
\end{align*}
\end{example}

\begin{exercise}
Dimostrare (per semplice curiosità) che valgono anche le inclusioni inverse 
a quelle enunciate nel teorema:
\begin{gather*}
o(f\cdot g) \subset o(f) \cdot o(g), \qquad
o(f\cdot g) \subset O(f) \cdot o(g), \\
o(f\cdot g) \subset o(f) \cdot O(g), \\
o(f) \subset o(o(f)),  \qquad
O(f) \subset O(O(f)).
\end{gather*}
Osservare invece che $(o(f))^2 \neq o(f)\cdot o(f)$.
\end{exercise}

La formula di Taylor può risultare molto utile per determinare il carattere di una serie, come nel seguente.
\begin{exercise}
Determinare i valori di $\alpha \in \RR$ per i quali la serie
\[
  \sum_{k=1}^{+\infty}(-1)^k \enclose{\frac 1 k - \sin \frac 1 k}^\alpha
\]
converge assolutamente e quelli per cui converge.
\end{exercise}
\begin{proof}[Soluzione.]
Posto $f(x) = x - \sin x$,
tramite sviluppo di Taylor sappiamo che si ha,
per $x\to 0$:
\begin{align*}
   f^\alpha(x) &= \enclose{x - \sin x}^\alpha
   =  \enclose{\frac{x^3}{6} + o(x^3)}^\alpha
   = \frac{x^{3\alpha}}{6^\alpha}\enclose{1+o(1)}^\alpha\\
   & = \frac{x^{3\alpha}}{6^\alpha}\enclose{1 + \alpha \cdot o(1) + o(o(1))}
   = \frac{x^{3\alpha}}{6^\alpha}\enclose{1 + o(1)}.
\end{align*}
Visto che per $k\to +\infty$ si ha $x=1/k \to 0$, possiamo
scrivere:
\[
  a_k = \enclose{f(1/k)}^\alpha = \enclose{\frac 1 k - \sin \frac 1 k}^\alpha
  = \frac{1}{6^\alpha \cdot k^{3\alpha}} \enclose{1+o(1)}
  \sim \frac{1}{6^\alpha \cdot k^{3\alpha}}.
\]
Osserviamo che la serie data è $\sum (-1)^k a_k$ e che $a_k>0$. Dunque per
il criterio di confronto asintotico se $3\alpha > 1$, cioè se $\alpha >1/3$,
la serie data converge assolutamente, se invece $\alpha \le 1/3$ la serie non
converge assolutamente (ma potrebbe convergere).
Osserviamo inoltre che se $\alpha \le 0$ il termine $a_k$ non è neanche
infinitesimo e quindi la serie non può convergere.

Per $\alpha \in (0,1/3]$ possiamo provare ad utilizzare il criterio di Leibniz:
la successione $a_k$ è infinitesima, dobbiamo verificare che sia anche
definitivamente decrescente.
Avendo posto $a_k = \enclose{f(1/k)}^\alpha$ sarà sufficiente dimostrare che
la funzione $f(x)$ è crescente in un intorno destro di $0$.
Per le proprietà del polinomio di Taylor sappiamo che il polinomio di Taylor
di ordine $2$ di $f'(x)$ è uguale alla derivata del polinomio di Taylor di
$f(x)$ di ordine $3$. Dunque possiamo affermare immediatamente (ma sarebbe
stato ugualmente veloce calcolare la derivata e poi svilupparla) che
\[
  f'(x)
  = \enclose{\frac{x^3}{6}}'  + o(x^2)
  = \frac{x^2}{2} + o(x^2) = x^2 \enclose{\frac 1 2 + o(1)}
\]
dunque, per la permanenza del segno, deve esistere un intorno di $0$ in cui
$1/2 + o(1)$ è positivo e quindi in tale intorno risulta che $f'(x)\ge 0$
cioè $f$ è crescente.
Dunque anche $f^\alpha$ è crescente e, per $k$ abbastanza grande,
$a_k$ è decrescente. Si può quindi applicare il criterio di Leibniz e
concludere che la serie è convergente per ogni $\alpha >0$.
\end{proof}

\begin{exercise}
  Dimostrare che la seguente serie è convergente:
  \[
    \sum_k \sqrt{k} \enclose{k\tg{\frac 1 k} - \cos \frac 1 k}.
  \]
\end{exercise}
\begin{proof}[Soluzione]
In questo esercizio utilizziamo la nozione di $O$-grande (ma l'esercizio potrebbe essere risolto anche utilizzando gli $o$-piccolo, come al solito).
Per $x\to 0$ si ha: %
\mynote{%
qui sfruttiamo il fatto che lo sviluppo di Taylor del terzo ordine esiste 
e usando la notazione degli $O$-grande evitiamo di doverci ricordare qual è 
il coefficiente $c=\frac 1 3$ che compare nella formula}
\[
  \tg x = x + c x^3 + o(x^3) = x + O(x^3)
\]
e analogamente
\[
  \cos x = 1 + O(x^2)
\]
da cui
\[
  \frac{\tg x}{x} - \cos x = O(x^2).
\]
Dunque per $k\to +\infty$ si ha
\[
  a_k = \sqrt{k} \enclose{k\tan{\frac 1 k} - \cos \frac 1 k}
   = \sqrt{k} \cdot O\enclose{\frac 1 {k^2}} = O\enclose{\frac 1 {k^{\frac 3 2}}}.
\]
Significa che per $k$ sufficientemente grande esiste una costante $C$
per cui
\[
  a_k \le \frac{C}{k^{\frac 3 2}}.
\]
Siccome sappiamo che la serie $\sum \frac{1}{k^p}$ è convergente
se $p>1$ per il criterio del confronto $\sum a_k$ (che è una serie a termini positivi) è anch'essa convergente.
\end{proof}

