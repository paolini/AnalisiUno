\chapter{calcolo integrale}

\begin{definition}[integrale di Riemann]
Siano $a,b\in \RR$, $a \le b$.

Un insieme $P\subset [a,b]$ si dice essere una \myemph{partizione di Riemann}
\index{Riemann!partizione di}
dell'intervallo $[a,b]$ se $P$ è un insieme finito tale che $a,b\in P$. In particolare se ha $N+1$ elementi $P$ si
potrà scrivere
\[
 P = \{ x_0, x_1, \dots, x_N\}
\]
con
\[
  a = x_0 < x_1 < \dots < x_{N-1} < x_N = b.
\]

Sia $f\colon [a,b] \to \RR$ una funzione limitata. Data una qualunque partizione $P$ di $[a,b]$ definiamo
rispettivamente le \myemph{somme superiori} e le \myemph{somme inferiori}
\index{Riemann!somme superiori}
\index{Riemann!somme inferiori}
come
\begin{align*}
S^*(f,P)
&= \sum_{k=1}^N (x_k - x_{k-1}) \cdot \sup \{f(x)\colon x \in [x_k - x_{k-1}]\} \\
S_*(f,P)
&= \sum_{k=1}^N (x_k - x_{k-1}) \cdot \inf \{f(x)\colon x \in [x_k - x_{k-1}]\}.
\end{align*}
Definiamo infine
\begin{align*}
  I^*(f) &= \inf \{S^*(f,P) \colon \text{$P$ partizione di $[a,b]$}\}
  \\
  I_*(f) &= \sup \{S_*(f,P) \colon \text{$P$ partizione di $[a,b]$}\}.
\end{align*}

Se $I^*(f) = I_*(f)$ diremo che $f$ è
\mynote{Riemann-integrabile}
\index{Riemann!integrabile}
\index{integrabilità}
\index{integrale}
\index{integrale!definizione}
e diremo che l'\myemph{integrale} di $f$ su $[a,b]$ è
il valore comune $I^*(f)=I_*(f)$ che verrà denotato con
\[
  \int_a^b f
  \qquad{\text{oppure con}} \qquad
  \int_a^b f(x)\, dx.
\]

Se $b<a$ e se $f$ è Riemann integrabile su $[b,a]$
definiamo per convenzione:
\[
  \int_a^b f = -\int_b^a f.
\]
\end{definition}

\begin{theorem}[criteri di integrabilità]
\mymargin{criteri di integrabilità}
Sia $f\colon[a,b]\to \RR$ una funzione limitata.
\begin{enumerate}
\item
Se $P$ e $Q$ sono due partizioni qualunque dell'intervallo
$[a,b]$ si ha
\[
  S_*(f,P) \le S^*(f,Q).
\]
Di conseguenza $I_*(f) \le I^*(f)$.

\item
La funzione $f$ è Riemann-integrabile se e solo se
per ogni $\eps>0$ esiste una partizione $P$
tale che
\[
  S^*(f,P) - S_*(f,P) < \eps.
\]

\item
Se $f$ è Riemann-integrabile su $[a,b]$ allora
esiste una successione $P_n$ di partizioni tali che
\begin{equation}\label{eq:93765}
  \lim_{n\to +\infty} S^*(f,P_n)
  = \lim_{n\to+\infty} S_*(f,P_n)
\end{equation}
e il valore dei limiti coincide con $\int_a^b f$.
Viceversa se esiste una successione $P_n$ di partizioni di $[a,b]$
per cui vale
~\eqref{eq:93765}
allora la funzione $f$ è Riemann-integrabile
e il suo integrale coincide con il valore dei limiti.
\end{enumerate}
\end{theorem}
%
\begin{proof}
Sia $P$ una qualunque partizione di $[a,b]$ e sia $y\in [a,b]$ un punto qualunque. Posto $P' = P \cup \{y\}$ vogliamo mostrare
che si ha
\begin{equation}\label{eq:39543}
  S_*(f,P) \le S_*(f,P') \le S^*(f,P') \le S^*(f,P).
\end{equation}
Se $y\in P$ non c'è niente da dimostrare in quanto
risulterebbe $P'=P$ e la disuguaglianza $S_*(f,P') \le S^*(f,P')$ è sempre verificata in quanto ogni estremo superiore che compare nella definizione di $S^*$ è maggiore o uguale al corrispondente
estremo inferiore che compare nella definizione di $S_*$.
Supponiamo allora che $y \not \in P$ e dunque che $y$ sia compreso tra due punti consecutivi $x_{k-1}, x_k$ della partizione $P$:
\[
  a= x_0 < x_1 < \dots < x_{k-1} < y < x_k < \dots < x_N=b.
\]
Allora le somme che definiscono $S_*(f,P)$ e $S_*(f,P')$ differiscono solo sull'intervallo $[x_{k-1},x_k]$ e si ha
\begin{align*}
  S_*(f,P') - S_*(f,P)
  &= (y-x_{k-1})\cdot \!\!\inf_{[x_{k-1},y]}\!\!\! f
  + (x_k - y)\cdot\! \inf_{[y,x_k]}\! f\\
  &\quad - (x_k - x_{k-1})\cdot \!\!\inf_{[x_{k-1}, x_k]}\!\!\!f
\end{align*}
ma osservando che
\[
\inf_{[x_{k-1}, x_k]}\!\!f
\le\inf_{[x_{k-1},y]}\!\! f
\qquad \text{e} \qquad
\inf_{[x_{k-1}, x_k]}\!\!f
\le\inf_{[y,x_k]}\!\! f
\]
si ottiene $S_*(f,P) \le S_*(f,P')$.
In maniera analoga si ottiene $S^*(f,P) \ge S^*(f,P')$.
Dunque \eqref{eq:39543} è dimostrata.
Ma allora se $P$ e $Q$ sono partizioni qualunque osserviamo che $P\cup Q$ si può ottenere da $P$ aggiungendo uno alla volta i punti di $Q$. Iterando la \eqref{eq:39543} si può dunque concludere che
\[
 S_*(f,P) \le S_*(f,P\cup Q) \le S^*(f,P\cup Q) \le S^*(f,Q)
\]
da cui discende il primo punto del teorema: $S_*(f,P) \le S^*(f,Q)$.
Facendo l'estremo inferiore al variare di $Q$
si ottiene $S_*(f,P) \le I^*(f)$ e facendo l'estremo superiore al variare di $P$ si ottiene $I_*(f) \le I^*(f)$.

Dimostriamo il secondo punto.
Se esiste una partizione $P$ tale che $S^*(f,P)-S_*(f,P) < \eps$ possiamo immediatamente concludere che
\[
I^*(f) - I_*(f) \le S^*(f,P) - S_*(f,P) < \eps.
\]
Se questo è vero per ogni $\eps >0$ deduciamo che $I^*(f) - I_*(f) = 0$ e dunque che $f$ è Riemann-integrabile.

Viceversa qualunque sia $f$, per le proprietà di
di $\sup$ e $\inf$
esistono $Q$ e $R$ partizioni tali che
\[
  I^*(f) \ge S^*(f,Q) - \frac\eps 2
  \qquad\text{e}\qquad
  I_*(f) \le S_*(f,R) + \frac\eps 2
\]
da cui, per il punto precedente, ponendo $P=Q\cup R$
se $f$ è Riemann integrabile
si ottiene
\begin{align*}
S^*(f,P)-S_*(f,P) &\le S^*(f,Q) - S_*(f,R) \\
&\le I^*(f) + \frac\eps 2 - \enclose{I_*(f) - \frac \eps 2} = \eps.
\end{align*}

Per il terzo punto del teorema
supponiamo dapprima che $f$ sia Riemann-integrabile su $[a,b]$.
Allora per il punto precedente per ogni $n\in \NN$ ponendo $\eps=1/n$ possiamo trovare una partizione $P_n$ tale che
\[
  S^*(f,P_n) - S_*(f,P_n) < \frac 1 n
\]
da cui
\[
  I^*(f) \le S^*(f,P_n) \le S_*(f,P_n) + \frac 1 n
   \le I_*(f) + \frac 1 n
\]
perciò passando al limite per $n\to +\infty$,
essendo $I^*(f) = I_*(f) = \int_a^b f$ deve valere
\[
  \lim S^*(f,P_n) = \lim S_*(f,P_n) = \int_a^b f.
\]

Viceversa se i limiti in \eqref{eq:93765} sono uguali allora
\[
 \lim_{n\to +\infty} S^*(f,P_n) - S_*(f,P_n) = 0
\]
dunque per ogni $\eps>0$ esiste $n$ tale che
\[
  S^*(f,P_n) - S_*(f,P_n) < \eps.
\]
Per il punto precedente concludiamo che $f$ è Riemann-integrabile.
D'altra parte sappiamo che
\[
  S_*(f,P_n) \le I_*(f) = I^*(f) \le S_*(f,P_n)
\]
e, per il teorema dei due carabinieri concludiamo quindi che $I_*(f)$ e $I^*(f)$ coincidono con i limiti in \eqref{eq:93765}.
\end{proof}

\begin{example}[calcolo dell'integrale tramite le partizioni]
Mostriamo che per ogni $b>0$ la funzione $f(x)=x^2$ è Riemann-integrabile sull'intervallo $[0,b]$ e si ha
\[
 \int_0^b x^2\, dx = \frac{b^3}{3}.
\]
\end{example}
\begin{proof}
Consideriamo le partizioni \emph{equispaziate} dell'intervallo $[0,b]$, cioè dividiamo $[0,b]$ in $N$ intervalli ognuno di ampiezza $b/N$:
\[
P_N = \left\{\frac{kb}{N}\colon k \in 0, 1, \dots, N\right\}.
\]
Si ha
\[
  S^*(f,P_N) = \sum_{k=1}^N \sup_{[(k-1)b/N,kb/N]}f \cdot \frac b N
   = \frac{b}{N} \sum_{k=1}^N \frac{k^2b^2}{N^2}
   = \frac{b^3}{N^3} \sum_{k=1^N} k^2.
\]
Ricordiamo ora che vale
\[
  \sum_{k=1}^n k^2 = \frac{n(n+1)(2n+1)}{6} = \frac{2n^3+3n^2+n}{6}
\]
(tale formula può essere facilmente verificata per induzione, si vedano gli appunti di logica). Dunque si ha
\[
  S^*(f,P_N) = \frac{b^3}{N^3} \frac{2N^3+3N^2+N}{6}
       = \frac{b^3}{6}\enclose{2 + \frac{3}{N}+\frac 1 N^2}
       \to \frac{b^3}{3}
\]
per $N\to +\infty$.
Analogamente si trova
\[
  S_*(f,P_N) = \sum_{k=1}^N \inf_{[(k-1)b/N,kb/N]} f \cdot \frac{b}{N}
  = \frac{b}{N}\sum_{k=1}^N \frac{(k-1)^2b^2}{N^2}
  = \frac{b^3}{N^3} \sum_{k=0}^{N-1} k^2
\]
e osservando che si ha
\[
 \sum_{k=0}^{N-1} k^2 = \sum_{k=1}^{N-1} k^2 = \frac{2(N-1)^3+3(N-2)^2+(N-1)}{6}
\]
otteniamo
\[
 S_*\ge \sup_N S_*(f,P_N) \ge \lim_{N\to+\infty} S_*(f,P_N) = \frac{b^3}{3} \to \frac{b^3}{3}.
\]
La dimostrazione si conclude quindi applicando
il criterio \eqref{eq:93765} del teorema precedente.
\end{proof}

\begin{theorem}[integrale di una costante]
Se $f\colon[a,b]\to \RR$ è costante: $f(x) = c$ allora
$f$ è Riemann-integrabile e si ha
\[
  \int_a^b f = c\cdot (b-a).
\]
\end{theorem}
%
\begin{proof}
Visto che su ogni $A\subset [a,b]$ si ha
\[
  \sup_A f = \inf_A f = c
\]
è facile verificare che si ha
\[
  S^*(f,P) = S_*(f,P) = c\cdot (b-a)
\]
qualunque sia la partizione $P$ di $[a,b]$. Il risultato segue immediatamente.
\end{proof}

\begin{theorem}[monotonia dell'integrale]
Sia $a\le b$ e siano
$f,g\colon [a,b]\to \RR$ due funzioni Riemann-integrabili.
Se per ogni $x\in [a,b]$ si ha $f(x) \le g(x)$ allora
\[
  \int_a^b f(x) \le \int_a^b g(x).
\]

In particolare se $f\ge 0$ allora $\int_a^b f \ge 0$.
\end{theorem}
%
\begin{proof}
Chiaramente se $f \le g$ si avrà che il $\sup$ di $f$ su qualunque intervallo sarà minore o uguale al $\sup$ di $g$ sullo stesso intervallo. Dunque su ogni partizione $P$ di $[a,b]$ si avrà:
\[
  S^*(f,P) \le S^*(g,P)
\]
da cui si ottiene immediatamente $I^*(f) \le I^*(g)$ e il risultato segue.
\end{proof}

\begin{theorem}[linearità dell'integrale]
Siano $f,g\colon [a,b]\to \RR$ due funzioni Riemann-integrabili
e siano $\lambda, \mu \in \RR$. Allora $\lambda f + \mu g$
è Riemann integrabile e si ha
\[
  \int_a^b (\lambda f + \mu g) = \lambda \int_a^b f + \mu \int_a^b g.
\]

In particolare l'insieme delle funzioni Riemann-integrabili su $[a,b]$ risulta essere uno spazio vettoriale reale e l'integrale è una
applicazione lineare su tale spazio, a valori in $\RR$.
\end{theorem}
%
\begin{proof}
Mostriamo innanzitutto che
\begin{equation}\label{eq:20043}
  \int_a^b (-f) = -\int_a^b f.
\end{equation}
Questo deriva dal fatto che su qualunque insieme $A$ si ha
$\sup_A (-f) = -\inf_A f$ e dunque per una qualunque partizione $P$
si ha
\[
  S^*(-f,P) = -S_*(f,P).
\]
Se ne deduce che $I^*(-f) = -I_*(f)$ e, analogamente, $I_*(-f) = -I^*(F)$. Dunque se $f$ è Riemann-integrabile anche $-f$ lo è e vale la proprietà \eqref{eq:20043}.

Ora se $\lambda \ge 0$ vogliamo mostrare che vale
\begin{equation}\label{eq:10032}
  \int_a^b \lambda f = \lambda \int_a^b f.
\end{equation}
Semplicemente si osserva che $\sup_I \lambda f = \lambda \sup_I f$ e dunque $S^*(\lambda f,P) = \lambda S^*(f,P)$ per ogni partizione $P$. Ne consegue che $I^*(\lambda f) = \lambda I^*(f)$. In maniera analoga si può mostrare che $I_*(\lambda f) = \lambda I_*(f)$. Dunque se $f$ è Riemann-integrabile anche $\lambda f$ (con $\lambda \ge 0$) lo è e vale \eqref{eq:10032}.

Mettendo assieme \eqref{eq:20043} e $\eqref{eq:10032}$ si ottiene
che $\eqref{eq:10032}$ vale per ogni $\lambda \in \RR$.
Lo stesso sarà vero se mettiamo $g$ al posto di $f$ e $\mu$ al posto di $\lambda$. Per concludere la dimostrazione sarà dunque sufficiente
mostrare che vale anche
\begin{equation*}\label{eq:80003}
\int_a^b (f+g) = \int_a^b f + \int_a^b g.
\end{equation*}
Osserviamo che su qualunque insieme $A$ si ha
\[
  \sup_A (f+g) \le \sup_A f + \sup_A g.
\]
Infatti per le proprietà dell'estremo superiore per ogni $\eps>0$ esiste $x\in A$ tale che
\[
  \sup_A (f+g) \le f(x) + g(x) + \eps.
\]
Ma chiaramente $f(x) \le \sup_A f$ e $g(x)\le \sup_A g$ dunque si ottiene
\[
  \sup_A (f+g) \le \sup_A f + \sup_A g + \eps.
\]
Passando al limite per $\eps \to 0^+$ si ottiene la disuguaglianza voluta. Questo significa che
\[
  S^*(f+g) \le S^*(f) + S^*(g).
\]
analogamente si potrà dimostrare che
\[
  S_*(f+g) \ge S_*(f) + S_*(g).
\]
Si ottiene dunque
\[
  I^*(f+g) \le I^*f(f) + I^*(g)
  \qquad\text{e}\qquad
  I_*(f+g) \ge I_*(f) + I_*(g)
\]
e dunque se $f$ e $g$ sono integrabili anche $f+g$ risulta integrabile
e vale la \eqref{eq:80003}.

Per concludere che l'insieme delle funzioni integrali sia uno spazio vettoriale è sufficiente osservare che la funzione $0$ (come ogni costante) risulta integrabile. Infatti se $f(x)=c$ si trova facilmente che $S^*(f,P) = S_*(f,P) = c(b-a)$ qualunque sia la partizione $P$ e dunque $I^*(f) = I_*(f) = c(b-a)$.
\end{proof}

\begin{theorem}[additività dell'integrale]
\mymargin{additività dell'integrale}
\index{integrale!additività}
Sia $f\colon [a,b]\to \RR$ una funzione limitata e sia $c\in [a,b]$.
Allora $f$ è Riemann-integrabile su $[a,b]$ se e solo se
$f$ è Riemann-integrabile su $[a,c]$ e su $[c,b]$.
E in tal caso risulta
\begin{equation}\label{eq:36645}
 \int_a^b f = \int_a^c f + \int_c^b f.
\end{equation}

In base alla convenzione
\[
   \int_b^a f = -\int_a^b f
\]
la formula \eqref{eq:36645} è valida non solo se $a\le c\le b$ ma anche se $a,b,c$ sono in qualunque ordine, purché la funzione $f$ sia integrabile sull'intervallo che contiene tutti e tre i punti $a,b,c$.

\end{theorem}
%
\begin{proof}
Supponiamo che $f$ sia integrabile su $[a,c]$ e su $[c,b]$.
Allora, in base ai criteri di integrabilità, per ogni $\eps>0$ esisteranno una partizione $P$ di $[a,c]$ e una partizione $Q$ di $[c,b]$ tali che
\[
  S^*(f,P) - S_*(f,P) < \frac \eps 2,
  \qquad
  S^*(f,Q) - S_*(f,Q) < \frac \eps 2.
\]
L'insieme $R=P\cup Q$ risulta essere una partizione di $[a,b]$ su cui si avrà
\begin{equation}\label{eq:56632}
S^*(f,R) = S^*(f,P) + S^*(f,Q), \qquad
S_*(f,R) = S_*(f,P) + S_*(f,Q)
\end{equation}
e dunque
\[
S^*(f,R) - S_*(f,R) \le \frac \eps 2 + \frac \eps 2 = \eps.
\]
Applicando nuovamente il criterio di integrabilità in senso invertito otteniamo dunque l'integrabilità di $f$ su $[a,b]$ e le equazioni
\eqref{eq:56632} garantiscono l'additività dell'integrale rispetto al dominio.

Viceversa se $f$ è integrabile su $[a,b]$ il criterio di integrabilità
ci garantisce che per ogni $\eps>0$ esiste una partizione $R$ di $[a,b]$ tale che
\[
S^*(f,R) - S_*(f,R) < \eps.
\]
Se ora consideriamo $R' = R \cup \{c\}$ sappiamo che $S^*(f,R') \le S^*(f,R)$ e $S_*(f,R') \ge S_*(f,R)$ dunque anche $R'$ soddisfa la proprietà
\[
S^*(f,R') - S_*(f,R') < \eps.
\]
Ma ora è chiaro che posto $P=R \cap[a,c]$ e $Q=R\cap[c,b]$ risulta che $P$ e $Q$ siano partizioni di $[a,c]$ e $[c,b]$ rispettivamente e che
\begin{align*}
  S^*f(f,R') &= S^*f(f,P) + S^*(f,Q), \\
  S_*f(f,R') &= S_*f(f,P) + S_*(f,Q).
\end{align*}
Dunque si ha
\begin{align*}
(S^*(f,P) - S_*(f,P)) + (S^*(f,Q) - S_*(f,Q))
&= S^*(f,R') - S_*(f,R) \\
&< \eps.
\end{align*}
Visto che entrambi gli addendi $S^*-S_*$ sono non negativi
risulta che valgono separatamente le disuguaglianze
\[
S^*(f,P) - S_*(f,P) < \eps, \qquad
S^*(f,Q) - S_*(f,Q) < \eps.
\]
Dunque $f$ è integrabile sia su $[a,c]$ che su $[c,b]$.
E nuovamente possiamo osservare che l'integrale è additivo sul dominio.
\end{proof}

\begin{theorem}[integrabilità delle funzioni continue]
\mynote{integrabilità delle funzioni continue}
\index{integrabilità!funzioni continue}
Sia $f\colon [a,b]\to \RR$ una funzione continua.
Allora $f$ è Riemann-integrabile.
\end{theorem}
%
\begin{proof}
Per il teorema di Weierstrass sappiamo che $f$ è limitata,
condizione a priori per verificare se $f$ è integrabile.
Per il teorema di Heine-Cantor sappiamo che $f$ è uniformemente continua, dunque per ogni $\eps>0$ esiste un $\delta>0$ tale che
\[
 \abs{x-y} < \delta \implies \abs{f(x)-f(y)} < \eps.
\]
Possiamo allora considerare una partizione $P_\delta$ con la proprietà che gli intervalli individuati dalla partizione abbiano tutti ampiezza minore di $\delta$ (ad esempio potremmo prendere la partizione formata da $(b-a)/\delta+2$ punti equispaziati in $[a,b]$). Su ogni intervallo $I$ di tale partizione si avrà che se $x,y\in I$ allora $\abs{f(x)-f(y)} < \eps$ da cui si deduce $\sup_I f - \inf_I f \le \eps$.
In particolare, sommando su tutti gli intervalli, si avrà
\begin{align*}
  S^*(f,P_\delta) - S_*(f,P_\delta)
  &= \sum_{k=1}^N (x_k-x_{k-1})\enclose{\sup_{[x_{k-1},x_k]} f - \inf_{[x_{k-1},x_k]} f} \\
  &\le \eps \sum_{k=1}^N (x_k - x_{k-1})
   = \eps (b-a).
\end{align*}
Visto che questa quantità può essere resa arbitrariamente piccola per $\eps \to 0$, in base ai criteri di integrabilità possiamo concludere che la funzione $f$ è integrabile.
\end{proof}

Non tutte le funzioni sono Riemann-integrabili come ci mostra il seguente esempio.
\begin{example}[funzione di Dirichlet]
\mynote{funzione di Dirichlet}
\index{funzione!di Dirichlet}
\index{integrabilità!controesempio}
Sia $a<b$ e sia $f\colon[a,b]\to \RR$ la funzione definita da
\[
 f(x) =
 \begin{cases}
   1 & \text{se $x\in \QQ$}\\
   0 & \text{se $x\not \in \QQ$}.
 \end{cases}
\]
Allora $f$ non è Riemann-integrabile.
\end{example}
%
\begin{proof}
Sia $P=\{x_0, x_1, \dots, x_N\}$ con $a=x_0 < x_1 < \dots < x_N = b$
una qualunque partizione di $[a,b]$.
Allora basta osservare che, per la densità dei razionali, in qualunque intervallino $I=[x_{k-1}, x_k]$ sono presenti infiniti punti razionali e infiniti punti irrazionali. Dunque $\sup f(I)=1$ e $\inf f(I)=0$ e di conseguenza
\begin{align*}
  S^*(f,P) &= \sum_{k=1}^N (x_k - x_{k-1})\cdot 1 = b-a \\
  S_*(f,P) &= \sum_{k=1}^N (x_k - x_{k-1})\cdot 0 = 0
\end{align*}
da cui $I^*(f) = b-a \neq 0 = I_*(f)$.
\end{proof}

\begin{theorem}[integrabilità di funzioni che differiscono su un numero finito di punti]
\mynote{funzioni che differiscono in un numero finito di punti}
\index{integrabilità!funzioni che differiscono in un numero finito di punti}
Sia $f\colon [a,b]\to \RR$ una funzione limitata.
Se $g\colon [a,b] \to \RR$ è una funzione Riemann-integrabile e $f$ differisce da $g$ solamente in un numero finito di punti, allora anche $f$ è Riemann-integrabile e vale
\[
\int_a^b f = \int_a^b g
\]

\end{theorem}
%
\begin{proof}
Supponiamo in prima istanza che $g$ differisca da $f$ solamente in un punto $x_0 \in [a,b]$. Se $g$ è integrabile e $I=\int_a^b g$
deve esistere una successione $P_n$ di partizioni di $[a,b]$ tali che $S^*(f,P_n) \to I$ e $S_*(f,P_n)\to I$.
Per ogni $n$ possiamo definire la partizione
$P'_n = (P_n \cup \{x_0-1/n,x_0+1/n\})\cap [a,b]$.
Essendo $P'_n \supset P_n$ si avrà
\[
  S_*(g,P_n) \le S_*(g,P'_n) \le S^*(g,P'_n) \le S^*(g,P_n)
\]
e quindi avremo ancora $S_*(g,P'_n)\to I$ e $S^*(g,P'_n) \to I$ per $n\to +\infty$.
Ma le funzioni $f$ e $g$ differiscono solamente all'interno dell'intervallo $I_n = [x_0-1/n, x_0+1/n]$
di ampiezza $2/n$
e su tale intervallo,
essendo $f-g$ limitata (diciamo $\abs{f-g}\le M$) si avrà:
\[
 \sup_{I_n} \abs{f-g} \le M
\]
da cui somme superiori e inferiori di $f$ e $g$ differiranno al più di $2M/n$:
\begin{gather*}
S_*(g,P'_n) - \frac{2M}n
\le
S_*(f,P'_n)
\le
S^*(f,P'_n)
\le
S^*(g,P'_n) + \frac{2M}n\\
\end{gather*}
e per il teorema dei due carabinieri,
passando al limite per $n\to +\infty$, si ottiene
\[
S_*(f,P'_n) \to I,
\qquad
S^*(f,P'n) \to I.
\]
Questo dimostra che $f$ è integrabile e che $\int_a^b f = \int_a^b g$.

Possiamo ora dimostrare per induzione il caso in cui $f$ e $g$ differiscono su un insieme di $n$ punti. Il passo base dell'induzione $n=1$ lo abbiamo già dimostrato.
Se ora $f$ e $g$ differiscono su un insieme di $n+1$ punti consideriamo uno di questi punti e chiamiamolo $x_0$. Consideriamo la funzione $h$ che coincide con $f$ in $x_0$ e con $g$ in tutti gli altri punti: chiaramente $h$ differisce in un solo punto con $g$ quindi, per il passo base, è integrabile e vale $\int_a^b h = \int_a^b g$. Ma $f$ differisce con $h$ in un insieme di $n$ punti e quindi, per ipotesi induttiva possiamo dedurre che $f$ è integrabile e $\int_a^b f = \int_a^b h = \int_a^b g$, come volevamo dimostrare.
\end{proof}

\begin{example}[funzione di Heaviside]
\mynote{funzione di Heaviside}
\index{funzione!di Heaviside}
Sia $a<0<b$.
La funzione $H\colon [a,b] \to \RR$ definita da
\[
H(x) =
\begin{cases}
1 & \text{se $x\ge 0$}\\
0 & \text{se $x< 0$}
\end{cases}
\]
è integrabile.
\end{example}
\begin{proof}
La funzione $H$ coincide con la funzione costante $1$ sull'intervallo $[0,b]$, dunque è integrabile su tale intervallo.
Sull'intervallo $[a,0]$ la funzione $H$ differisce dalla funzione costante $0$ solamente in un punto. Dunque anche su $[a,0]$ la funzione $H$ è integrabile. Ma allora, per additività rispetto al dominio, la funzione $H$ è integrabile su tutto $[a,b]$. Inoltre si ha
\[
  \int_a^b H = \int_a^0 H + \int_0^b H = \int_a^0 0 + \int_0^b 1 = 0 + b = b.
\]
\end{proof}

\begin{theorem}[del valor medio]
Siano $a,b\in \RR$, $a<b$ e sia
$f\colon [a,b] \to \RR$ una funzione continua.
Allora esiste un punto $y \in (a,b)$
tale che
\[
\frac{\int_a^b f}{b-a} = f(y).
\]
\end{theorem}
%
La quantità
\[
  \frac{\int_a^b}{b-a} f
\]
si chiama \emph{valor medio integrale} di $f$ su $[a,b]$ e spesso
si indica con il simbolo
\[
  -\!\!\!\!\!\!\int_a^b f.
\]
%
\begin{proof}
Per il teorema di Weierstrass la funzione $f$ ha massimo $M$ e minimo $m$ sull'intervallo $[a,b]$ cosicché
per ogni $x\in [a,b]$ si avrà:
\[
  m \le f(x) \le M.
\]
Risulta quindi, per la monotonia dell'integrale:
\[
  (b-a) m = \int_a^b m \le \int_a^b f \le \int_a^b M = (b-a) M
\]
ovvero
\[
  m \le \frac{\int_a^b f}{b-a} \le M.
\]
Dunque la media integrale è un valore intermedio tra il minimo e il massimo della funzione e quindi, per il teorema dei valori intermedi, dovrà esistere un punto $y\in [a,b]$ dove la funzione assume tale valore.
\end{proof}

\begin{theorem}[fondamentale del calcolo integrale]
\mynote{teorema fondamentale del calcolo integrale}
\index{teorema!fondamentale del calcolo integrale}
Sia $I\subset \RR$ un intervallo, sia $x_0 \in I$
 e sia $f\colon I\to \RR$ una funzione continua.
Allora la \myemph{funzione integrale} $F\colon I \to \RR$
\[
  F(x) = \int_{x_0}^x f
\]
è ben definita, è derivabile e si ha per ogni $x\in I$
\[
  F'(x) = f(x).
\]
In particolare essendo $f\in C^0(I)$ si ha $F\in C^1(I)$.

Inoltre se $G\colon I \to \RR$ è una qualunque funzione tale che $G'(x) = f(x)$ per ogni $x\in I$, allora per ogni $a,b \in I$ si ha
\mymargin{formula fondamentale del calcolo integrale}
\[
  \int_a^b f = G(b) - G(a).
\]
\end{theorem}
%
\begin{proof}
Osserviamo innanzitutto che la funzione $f$, essendo continua, è integrabile su ogni intervallo chiuso e limitato contenuto in $I$. Dunque l'integrale $\int_{x_0}^x f$ è ben definito.

Per ogni $h\neq 0$, se $x+h \in I$ per l'additività dell'integrale
si ha
\[
\frac{F(x+h) - F(x)}{h} = \frac{\int_{x_0}^{x+h} f - \int_{x_0}^x f}{h}
 = \frac{\int_x^{x+h} f}{h}.
\]
Applicando ora il teorema del valor medio possiamo
affermare che esiste un punto $\xi(h)$ nell'intervallo di estremi $x$ e $x+h$ tale che
\[
  \frac{\int_x^{x+h} f}{h} = f(\xi(h)).
\]
Per $h\to 0$, si ha $\xi(h) \to x$ e, per continuità di $f$, $f(\xi(h)) \to f(x)$. Dunque abbiamo mostrato che $F$ è derivabile in $x$:
\[
 \lim_{h\to 0}\frac{F(x+h)-f(x)}{h} = f(x)
\]
e $F'(x) = f(x)$.

Dunque se $a,b\in I$ sono punti qualunque si ha:
\[
\int_a^b f = \int_{x_0}^b f - \int_{x_0}^a f = F(b) - F(a).
\]
E se $G\colon I \to \RR$ è una qualunque  funzione tale che $G'(x)=f(x)$ si avrà $G'(x) = F'(x)$ per ogni $x\in I$ e dunque $(G-F)' = 0$ su $I$. Per i criteri di monotonia possiamo concludere che $G-F$ è costante su $I$: $G-F = c$. Dunque si ha
\[
 \int_a^b f = F(b) - F(a) = (G(b) - c) - (G(a) - c) = G(b) - G(a).
\]
\end{proof}

\begin{definition}[primitiva]
Sia $A \subset \RR$ e sia $f\colon A \to \RR$ una funzione qualunque. Una funzione $F\colon A \to \RR$ si dice essere una \myemph{primitiva}
(o \myemph{antiderivata})
di $f$ se $F$ è derivabile e $F'(x)=f(x)$ per ogni $x\in A$.
\end{definition}

Il teorema fondamentale del calcolo integrale può dunque essere espresso nel modo seguente: ogni funzione $f$ continua, definita su un intervallo, ammette almeno una primitiva e se $F$ è una qualunque primitiva di $f$ si ha
\[
  \int_a^b f = F(b) - F(a).
\]
Per indicare la differenza $F(b)-F(a)$ si usano
talvolta le seguenti notazioni:
\[
  \Enclose{F(x)}_{x=a}^b = \Enclose F_a^b
  = F(x) \vert_{x=a}^b
  = F \vert_a^b = F(b) - F(a).
\]

Il calcolo degli integrali si riduce quindi alla determinazione delle primitive ovvero ad invertire l'operatore di derivata.
Risulterà quindi importante avere degli strumenti per determinare le primitive di una funzione.

\begin{definition}[integrale indefinito]
L'insieme di tutte le primitive di una funzione $f\colon A \to \RR$
si indica con il simbolo
\[
  \int f
  \qquad\text{oppure}\qquad
  \int f(x) \, dx
\]

e si chiama \emph{integrale indefinito}.
Il motivo di questa notazione (e del nome) deriva dal teorema fondamentale del calcolo integrale, in
base al quale se $f\colon[a,b]\to \RR$
è continua si ha
\[
  \int_a^b f = \Enclose{\int f}_a^b.
\]
\end{definition}

Se pensiamo all'operatore lineare $D$ definito sull'insieme delle funzioni derivabili $Df = f'$
si può pensare a $\int f$ come all'insieme delle controimmagini di $f$ tramite $D$ ovvero:
\[
  \int f = D^{-1}(\{f\}) = \{F \colon DF =f \}.
\]

\begin{theorem}[proprietà delle primitive]
Sia $f\colon I \to \RR$
una funzione continua definita su un intervallo $I\subset \RR$. Allora
\begin{enumerate}
\item esiste almeno una primitiva $F$ di $f$;
\item data una primitiva $F$ di $f$ ogni altra
primitiva $G$ differisce da $F$ per una costante: $G= F+c$.
\end{enumerate}

Detto in altri termini $\int f$ non è vuoto e se  $F\in \int f$ allora
\[
  \int f = \{F+c \colon c \in \RR\}.
\]
\end{theorem}

Osserviamo che l'insieme delle funzioni costanti
su un intervallo
non è altro che $\ker D$ ovvero lo spazio di annullamento dell'operatore derivata. Stiamo dunque semplicemente osservando che le controimmagini di un operatore lineare sono spazi affini paralleli al nucleo dell'operatore.

\begin{proof}
Scelto un punto $x_0\in I$ possiamo
considerare la funzione integrale
\[
  F(x) = \int_{x_0}^x f(t)\, dt.
\]
Il teorema fondamentale del calcolo integrale
ci assicura che $F$ è una primitiva di $f$.

Viceversa se $F$ e $G$ sono due primitive di $f$ allora si ha:
\[
  F' = G' = f.
\]
Posto $H=G-F$ avremo quindi $H'=0$ sull'intervallo $I$. Per i criteri di monotonia sappiamo quindi che $H$ è costante, ovvero esiste $c\in \RR$ tale che $H(x)=c$ per ogni $x\in I$. Dunque si ottiene, come voluto: $G=F+H=F+c$.
\end{proof}

\section{calcolo delle primitive}

In generale quello che ci interessa è trovare una singola primitiva in quanto in genere tutte le altre si otterranno di conseguenza molto facilmente. In base alle proprietà delle primitive, infatti, sappiamo che su ogni intervallo le primitive differiscono per una costante. Osserviamo però che se la funzione è definita sull'unione di più intervalli allora ogni intervallo può avere una costante diversa, come si vede nel seguente.

\begin{example}[primitive sugli insiemi non connessi]
Consideriamo la funzione $f(x) = 1/x$. Osserviamo che $f\colon (-\infty, 0) \cup (0,+\infty)\to \RR$ è definita sull'unione di due intervalli. Per verifica diretta possiamo osservare che la funzione $F(x) = \ln \abs{x}$ è una primitiva di $f$. Per ottenere l'insieme di tutte le primitive possiamo aggiungere ad $F$ una qualunque funzione con derivata nulla sul dominio di $f$. Le funzioni con derivata nulla sono costanti su ogni intervallo e quindi troviamo che per ogni $c_1, c_2\in \RR$ la funzione
\[
G(x) =
\begin{cases}
  \ln (x) + c_1 &\text{se $x>0$},\\
  \ln (-x) + c_2 & \text{se $x<0$}
\end{cases}
\]
è una primitiva di $f$ e non ci sono altre primitive.

In questo caso lo spazio delle primitive ha dimensione $2$ in quanto il nucleo dell'operatore derivata sullo spazio delle funzioni definite sull'unione di due intervalli ha dimensione $2$.
Questo è l'esempio più semplice di un fenomeno piuttosto generale per cui gli operatori differenziali su uno spazio risultano strettamente legati alla topologia dello spazio stesso. In questo caso la dimensione del nucleo dell'operatore differenziale $D$ è uguale al numero di componenti connesse del dominio delle funzioni nel dominio di $D$.
\end{example}

Come già detto utilizzeremo la notazione $\int f$ per indicare le primitive della funzione $f$. Ma invece di scrivere $F\in \int f$
per indicare che $F$ è una primitiva di $f$ scriveremo, più semplicemente ma con abuso di notazione $\int f = F$
ricordando (come facevamo con la notazione degli $o$-piccolo) che tale relazione non è affatto simmetrica.
Eviteremo invece di scrivere $\int f = F+c$ come invece si trova in molti testi in quanto nel caso in cui il dominio della funzione non sia connesso risulta molto più complicato scrivere l'insieme di tutte le primitive. Nell'esempio precedente abbiamo infatti osservato che:
\[
  \int \frac{1}{x}\, dx \supsetneq \{\ln \abs{x}+c\colon c \in \RR\}.
\]

\begin{theorem}[integrali di alcune funzioni elementari]
Si ha
per ogni $\alpha \in \RR$, $\alpha\neq -1$
\begin{gather*}
\int x^\alpha\, dx = \frac{x^{\alpha+1}}{\alpha+1},
\qquad
\int \frac{1}{x}\, dx = \ln\abs{x}
\\
\int e^x \, dx = e^x,
\qquad
\int \cos x\, dx = \sin x,
\qquad
\int \sin x\, dx = -\cos x
\\
\int \cosh x \, dx = \sinh x,\qquad
\int \sinh x \, dx = \cosh x, \\
\int \frac{1}{1+x^2}\, dx = \arctg x, \qquad
\int \frac{1}{\sqrt{1-x^2}}\, dx = \arcsin x.
\end{gather*}
\end{theorem}
%
\begin{proof}
E' sufficiente fare riferimento alla corrispondente tabella
delle derivate delle funzioni elementari.
\end{proof}

\begin{theorem}[linearità dell'integrale indefinito]
Per ogni $\lambda,\mu \in \RR$ e se $f$, $g$ sono funzioni qualunque si ha:
\[
  \int \enclose{\lambda f + \mu g} \supset \lambda \int f + \mu \int g
\]
\end{theorem}
%
\begin{proof}
Ogni elemento dell'insieme che si trova sul lato destro
si scrive nella forma $\lambda F + \mu G$ con $F\in \int f$ e $G\in \int g$. Dunque si ha $F'=f$ e $G'=g$ da cui
\[
  (\lambda F + \mu G)' = \lambda f + \mu g
\]
e quindi
\[
  \lambda F + \mu G \in \int (\lambda f + \mu g)
\]
come dovevamo dimostrare.
\end{proof}
%
\begin{proof}
Dobbiamo dimostrare che se $F$ è una primitiva di $f$ allora $F(g(x))$ è una primitiva di
$f(g(x)) g'(x)$.
E' sufficiente applicare la regola di derivazione della funzione
composta: $(F(g(x)))' = F'(g(x)) g'(x) = f(g(x))g'(x)$.
\end{proof}

\begin{theorem}[cambio di variabile negli integrali]
Valgono le seguenti proprietà:
\begin{enumerate}
\item
se $g\colon A \to \RR$ è derivabile e $f\colon g(A) \to \RR$
allora
\[
  \int f(g(x)) g'(x)\, dx \supset
  \Enclose{\int f(y) \, dy}_{y=g(x)}
\]
dove si intende
\[
 \Enclose{F(y)}_{y=g(x)} = F(g(x));
\]

\item
se $g\in C^1([a,b])$ e $f\in C^0(g([a,b]))$ allora
\[
 \int_{g(a)}^{g(b)} f(x)\, dx = \int_a^b f(g(t))\, g'(t)\, dt;
\]

\item
se $g\in C^1([a,b])$ è iniettiva, $f\in C^0(g([a,b]))$
allora $g^{-1}$ è definita su $g([a,b])$
e si ha
\[
  \int f(x)\, dx \supset \Enclose{\int f(g(t)) g'(t)\, dt}_{t=g^{-1}(x)}
\]
\end{enumerate}
\end{theorem}
%
\begin{proof}
Per la prima parte prendiamo una qualunque funzione
$H$ appartenente all'insieme sul lato destro.
Essa sarà della forma $H(x) = F(g(x))$ con $F\in \int f$ ovvero con $F'=f$.
Facciamo la derivata:
\[
  H'(x) = (F(g(x)))' = F'(g(x)) g'(x) = f(g(x)) g'(x).
\]
Abbiamo quindi mostrato che $H$ è una primitiva di $f(g(x))g'(x)$ e quindi è elemento anche dell'insieme sul lato sinistro:
era quanto dovevamo dimostrare

Per la seconda parte sappiamo che $f$, essendo continua, ammette almeno una primitiva $F(x)$. Per il punto precedente sappiamo che $F(g(t))$ è una primitiva di $f(g(t))g'(t)$ (basta farne la derivata per verificarlo). Dunque, utilizzando la formula fondamentale del calcolo, si ottiene:
\[
\int_{g(a)}^{g(b)} f(x) \, dx
= \Enclose{F(x)}_{g(a)}^{g(b)}
= F(g(b)) - F(g(a))
\]
e
\[
\int_a^b f(g(t))g'(t)\, dt
= \Enclose{F(g(t))}_a^b
= F(g(b)) - F(g(a)).
\]
Le due espressioni sono uguali, come volevamo dimostrare.

Per la terza parte
sia $F$ una qualunque funzione elemento dell'insieme sul lato destro della relazione che vogliamo dimostrare.
Si avrà $F(x) = H(g^{-1}(x))$ con $H(t)$ primitiva
di $f(g(t))g'(t)$. Ma allora, per la formula fondamentale del calcolo integrale, si ha
\[
  H(t)-H(a) = \int_a^t f(g(s)) g'(s)\, ds
\]
da cui
\[
  F(x) - F(g(a))
  = H(g^{-1}(x)) - H(a)
  = \int_a^{g^{-1}(x)} f(g(t)) g'(t)\, dt
\]
utilizzando il punto precedente sappiamo però che vale
\[
F(x) - F(g(a)) =
\int_a^{g^{-1}(x)} f(g(t)) g'(t)\, dt
= \int_{g(a)} x f(t)\, dt.
\]
Dunque derivando ambo i membri, grazie ancora al teorema
fondamentale otteniamo:
\[
  F'(x) = f(x)
\]
cioè $F\in \int f$, come dovevamo dimostrare.
\end{proof}

Le formule del teorema precedente si scrivono usualmente nella forma
\[
  \int f(g(x) g'(x)\, dx = \int f(y) \, dy
\]
dove si intende che le variabili $x$ e $y$ devono soddisfare la relazione $y=g(x)$ (o, viceversa, $x=g^{-1}(y)$).
Per memorizzare tale formula si usa normalmente definire il
\emph{differenziale} di una funzione $g$ come $dg(x) = g'(x)\, dx$
(coerentemente con la notazione $g' = dg / dx$)
cosicche se $y=g(x)$ si ha $dy = g'(x)\, dx$.
Non daremo qui una definizione formale di cosa sia un differenziale
ma senz'altro utilizzeremo questa comoda notazione, pensandola
semplicemente come una facilitazione tipografica.

\begin{exercise}
Vogliamo calcolare
\[
  \int \cos^2(x)\, dx.
\]

Ricordando che $\cos(2t) = \cos^2 t - \sin^2 t = 2\cos^2 t - 1$ si
ha $\cos^2 t = (1+\cos(2t))/2$ (formula di bisezione).
Dunque
\[
\int \cos^2(t)\, dt
= \int\frac{1+\cos(2t)}{2}\, dt
= \int \frac 1 2 \, dt + \int \frac{\cos(2t)}{2}\, dt.
\]
Chiaramente $\int \frac 1 2 \, dt  = t/2$.
Nel secondo integrale
possiamo fare un cambio di variabile, ponendo
$2t=s$ da cui $2dt = ds$:
\begin{align*}
\int \frac{\cos(2t)}{2}\, dt
&= \frac 1 4 \int \cos(2t)\, 2dt
= \frac 1 4 \Enclose{\int \cos s \, ds}_{s=2t}
= \frac 1 4 \Enclose{\sin s}_{s=2t}\\
&= \frac 1 4 \sin(2t)
= \frac{1}{1}\sin t \cos t.
\end{align*}
In definitiva otteniamo
\[
  \int \cos^2(x)\, dx = \frac{t+\sin t \cos t}{2}.
\]
\end{exercise}


\begin{example}
Vogliamo calcolare
\[
 \int \sqrt{1-x^2}\, dx.
\]
La funzione integranda è definita per $x\in [-1,1]$.
Ci viene in mente di operare la sostituzione $x=\sin t$
con $t\in [-\pi/2, \pi/2]$.
Osserviamo che su $[-\pi/2,\pi/2]$ la funzione $\sin t$ è derivabile, invertibile e la sua inversa è $t = \arcsin x$.
Informalmente si ha
\[
 x= \sin t, \qquad dx = \cos t \, dt
\]
da cui si ottiene la formula
\[
 \int \sqrt{1-x^2}\, dx = \Enclose{\int \sqrt{1-\sin^2(t)} \cos t\, dt}_{t=\arcsin x}.
\]
Osserviamo ora che per $t\in [-\pi/2, \pi/2]$ risulta $\sqrt{1-\sin^2(t)}=\cos t$ e dunque l'integrale
diventa
\[
 \int \sqrt{1-\sin^2(t)}\cos t\, dt = \int \cos^2(t)\, dt.
\]
Quest'ultimo integrale lo abbiamo calcolato nell'esercizio precedente. Dunque otteniamo:
\begin{align*}
 \int \sqrt{1-x^2}\, dx
 &\stackrel{(x=\sin t)}= \int \cos^2(t)\, dt
 = \frac{t + \sin t \cos t}{2} \\
 &= \frac{t + (\sin t) \sqrt{1-\sin^2 t}}{2} \\
 &\stackrel{(t=\arcsin x)}= \frac{\arcsin x + x \sqrt{1-x^2}}{2}.
\end{align*}
\end{example}

\begin{theorem}[integrazione per parti]
Sia $f\colon A\subset \RR \to \RR$ una funzione qualunque, sia $g\colon A \to\RR$ una funzione derivabile
e sia $F \in \int f$.
Allora
\[
  \int f\cdot g \supset F \cdot g - \int F \cdot g'.
\]

In particolare se $f\in C^0([a,b])$ e $g\in C^1([a,b])$
e $F \in \int f$, si ha
\[
  \int_a^b f\cdot g = \Enclose{F\cdot g}_a^b - \int_a^b F \cdot g'.
\]
\end{theorem}
%
\begin{proof}
Ogni funzione dell'insieme di destra si scrive nella forma
$F\cdot g - H$ con $H \in \int F \cdot g'$.
Dunque $H' = F \cdot g'$ e, per ipotesi, $F'=f$ da cui
\[
(F\cdot g - H)' = F' \cdot g + F \cdot g' - H' = F' \cdot g
= f\cdot g
\]
che è quanto dovevamo dimostrare.

La seconda parte del teorema
deriva direttamente dalla formula fondamentale del calcolo integrale (valida in quanto sia $f\cdot g$ che $F \cdot g'$ sono funzioni continue), osservando che
\[
\Enclose{F\cdot g - \int F \cdot g'}_a^b
= \Enclose{F\cdot g}_a^b - \int_a^b F \cdot g'.
\]
\end{proof}

\begin{example}
Si voglia calcolare
\[
  \int x \cos x\, dx.
\]
Il metodo di integrazione per parti ci permette
di ricondurre l'integrale di un prodotto ad un integrale
di un prodotto in cui uno dei fattori viene integrato e l'altro derivato. In questo caso sarà conveniente derivare il fattore $x$
e integrare il fattore $\cos x$ in modo da ricondursi all'integrale di $1\cdot \sin x$, che sappiamo svolgere.
Precisamente si ha
\[
 \int x \cos x\, dx = x \sin x - \int 1 \cdot \sin x \, dx
  = x \sin x + \cos x.
\]
\end{example}

\begin{example}
Si voglia calcolare
\[
 \int e^x \cos x\, dx.
\]
In questo caso se utilizziamo l'integrazione per parti possiamo ricondurre questo integrale a $\int e^x \sin x$. Integrando ancora per parti ci si ricondurrà nuovamente ad $\int e^x \cos x$. Se però in questi passaggi si riottiene la quantità originale con un segno cambiato, si potrà risolvere l'equazione ottenuta per trovare il risultato cercato.

Precisamente:
\begin{align*}
\int e^x \cos x\, dx
&= e^x \sin x - \int e^x \sin x\, dx\\
 &= e^x \sin x - \Enclose{e^x(-\cos x) - \int e^x(-\cos x)\, dx} \\
 &= e^x \sin x + e^x \cos x - \int e^x \cos x \, dx
\end{align*}
da cui:
\[
 2 \cdot \int e^x \cos x\, dx  = e^x \sin x + e^x \cos x
\]
ovvero
\[
  \int e^x \cos x\, dx = \frac{e^x(\sin x + \cos x)}{2}.
\]
\end{example}

\begin{theorem}[ancora integrali di funzioni elementari]
Si ha
\begin{align*}
  \int \ln x\, dx  &= x \ln x - x, \\
  \int \arctg x\, dx &= x \arctg x - \ln \sqrt{1+x^2}.\\
\end{align*}
\end{theorem}
%
\begin{proof}
In entrambi i casi l'idea è che la derivata della funzione integranda trasforma la funzione trascendente in una funzione
razionale. Può quindi risultare utile applicare l'integrazione
per parti nella forma:
\[
  \int f(x)\, dx = \int 1\cdot f(x)\, dx = x f(x) - \int x f'(x)\, dx.
\]
Nel primo caso si ha:
\[
\int \ln x\, dx = x \ln x - \int x \frac{1}{x}\, dx
 = x \ln x - \int 1 dx = x \ln x - x.
\]
Nel secondo caso:
\[
\int \arctg x\, dx = x \arctg x - \int \frac{x}{1+x^2}\, dx.
\]
Operiamo quindi un cambio di variabile $y=1+x^2$:
\begin{align*}
\int \frac{x}{1+x^2}\, dx
&= \frac{1}{2}\int \frac{1}{1+x^2} 2x \, dx
\stackrel{y=1+x^2} = \frac{1}{2}\int \frac 1 y\, dy \\
&= \frac{\ln y}{2} = \frac{1}{2}\ln\enclose{1+x^2}
\end{align*}
da cui, in conclusione:
\[
 \int \arctg x\, dx = x \arctg x - \frac 1 2 \ln\enclose{1+x^2}.
\]
\end{proof}

\begin{theorem}[irrazionalità di $\pi$]
\mymargin{$\pi$ è irrazionale}
\index{irrazionalità!di $\pi$}
Il numero $\pi$ è irrazionale.
\end{theorem}
%
\begin{proof}
Posto
\[
 f_n(x) = x^n(\pi-x)^n
\]
si ha
\[
f_n'(x) = n x^{n-1}(\pi-x)^n - n x^n (\pi-x)^{n-1}
\]
e
\begin{align*}
f_n''(x)
&= n(n-1) x^{n-2}(\pi-x)^n
  - 2n^2 x^{n-1}(\pi-x)^{n-1} \\
  &\quad + n(n-1) x^n(\pi-x)^{n-2} \\
&= (n^2-n) [(\pi-x)^2 +x^2] x^{n-2}(\pi-x)^{n-2} \\
  &\quad  - 2n^2 x^{n-1}(\pi-x)^{n-1}
\end{align*}
Osservando ora che
\[
 (\pi-x)^2 + x^2 = \pi^2 -2\pi x + 2x^2
  = \pi^2 - 2x(\pi-x)
\]
si ottiene
\begin{align*}
f_n''(x)
&= (n^2-n)\pi^2 x^{n-2}(\pi-x)^{n-2} \\
  &\quad - 2(n^2 - n + n^2) x^{n-1}(\pi-x)^{n-1} \\
&= (n^2-n)\pi^2 f_{n-2}(x)
-  (4n^2-2n) f_{n-1}(x).
\end{align*}

Poniamo ora
\[
  I_n = \int_0^\pi f_n(x) \sin(x)\, dx.
\]
Per $n>0$ osserviamo che $f_n(0) = f_n(\pi)=0$
e dunque integrando per parti due volte si ottiene:
\[
  I_n = \int_0^\pi f_n'(x) \cos x\, dx
   = -\int_0^\pi f_n''(x)\sin x\, dx
\]
da cui
\begin{align*}
   I_n = -(n^2-n)\pi^2 I_{n-2} + (4n^2-2n)I_{n-1}
\end{align*}
Supponiamo ora per assurdo che sia $\pi = p/q$ con $p,q\in \NN$ e consideriamo la successione
\[
   a_n = \frac{q^{2n}}{n!} I_n.
\]
Possiamo calcolare i primi due termini della successione $a_n$:
\begin{align*}
  a_0 &= \frac{q^0}{0!}\int_0^\pi \sin x\, dx
    = 2 \in \ZZ, \\
  a_1 &= \frac{q^2}{1!}\int_0^\pi x(\pi -x)\sin x\, dx \\
   &= q^2 \int_0^\pi (2x - \pi)\cos x\, dx \\
   &= 2q^2 \int_0^\pi \sin x\, dx
   = 4q^2 \in \ZZ.
\end{align*}
Inoltre la relazione di ricorrenza che abbiamo trovato per $I_n$ si traduce in:
\begin{align*}
  a_n &= \frac{q^{2n}}{n!}\enclose{-(n^2-n)\frac{p^2}{q^2} \frac{(n-2)!}{q^{2n-4}}a_{n-2}
  + (4n^2-2n) \frac{(n-1)!}{q^{2n-2}}a_{n-1}} \\
  &= - q^2 p^2 a_{n-2} + (4n-2)q^2 a_{n-1}.
\end{align*}
Per induzione si trova quindi che $a_n \in \ZZ$ per ogni $n\in \NN$.

D'altra parte osservando che per $x\in [0,\pi]$ si ha
\[
  0 \le f_n(x) \sin(x) \le x^n (\pi-x)^n \le \pi^n \pi^n = \pi^{2n}
\]
dunque
\[
  0\le I_n = \int_0^\pi f_n(x) \sin x\, dx \le \pi^{2n+1}
\]
cioè
\[
  0 \le a_n \le \frac{q^{2n}}{n!}\pi^{2n+1} \to 0.
\]
Dunque abbiamo scoperto che $a_n\to 0$. D'altra parte abbiamo visto che $a_n \in \ZZ$ e certamente $a_n > 0$ in quanto $I_n \neq 0$ visto che $f_n$ è una funzione continua, non negativa e non identicamente nulla. Ma non è possibile che una successione di numeri interi positivi converga a zero: abbiamo quindi ottenuto l'assurdo.
\end{proof}

\section{integrale di una funzione razionale}

\begin{definition}[funzione razionale]
\mynote{funzione razionale}
\index{funzione!razionale}
Una funzione $f$ si dice essere \emph{razionale}
se si può scrivere
\[
  f(x) = \frac{P(x)}{Q(x)}
\]
con $P$ e $Q$ funzioni polinomiali a coefficienti reali.
\end{definition}

In questa sezione cercheremo di trovare un metodo per
calcolare esplicitamente l'integrale $\int P(x)/Q(x)\, dx$ di una qualunque funzione razionale.
Per fare ciò vogliamo scrivere il rapporto $P(x)/Q(x)$ come combinazione lineare di funzioni più semplici, di cui saremo in grado di calcolare l'integrale.

\begin{theorem}[decomposizione complessa in fratti semplici]
Siano $u_1, \dots, u_n$ funzioni complesse della forma
\[
  u_k(z) = \frac{1}{(z-\lambda_k)^{p_k}}
\]
con $\lambda_k\in \CC$, $p_k\in \NN$, $p_k>0$.
Supponiamo che le $u_k$ siano tra loro distinte (cioè se $\lambda_k=\lambda_j$ allora $p_k \neq p_j$).
Sia $\Omega = \CC \setminus\{\lambda_1, \dots, \lambda_k\}$ cosicché tutte le funzioni $u_k$ sono elementi dello spazio vettoriale complesso $V=\CC^\Omega$ cioè sono funzioni complesse definite su tutto $\Omega$.

Allora le funzioni $u_k$ sono linearmente indipendenti come vettori di $V$ ovvero
se esistono dei coefficienti $\alpha_1,\dots, \alpha_n \in \CC$ tali che
\[
\forall z \in \Omega\colon  \sum_{k=1}^n \alpha_k u_k(z) = 0
\]
allora ogni $\alpha_k=0$ per $k=1,\dots,n$.

Di conseguenza se $Q(z) = (z-\lambda_1)^{p_1} \cdots (z-\lambda_n)^{p_n}$ con $\lambda_k\in \CC$ valori distinti
e $p_k\in \NN$, $p_k>0$,
per $k=1,\dots, n$
posto $N=\deg Q = p_1 + \dots + p_n$
per ogni polinomio complesso $P$ di grado inferiore ad $N$
esistono dei coefficienti $A_{kj}\in \CC$
per $k=1,\dots,n$ e  $j=1,\dots, p_k$ tali che
\[
  \frac{P(z)}{Q(z)} = \sum_{k=1}^n \sum_{j=1}^{p_k} \frac{A_{kj}}{(z-\lambda_k)^j}.
\]
\end{theorem}
%
\begin{proof}
Procediamo per induzione su $n$. Se $n=1$ abbiamo una unica funzione che non può essere identicamente nulla (anzi: non si annulla mai). Dunque è un insieme linearmente indipendente.

Supponiamo allora di avere un insieme di $n$ funzioni $u_1, \dots, u_n$ e supponiamo di avere una combinazione lineare identicamente nulla: $\alpha_1 u_1 + \dots + \alpha_n u_n = 0$.
Sia $\lambda = \lambda_n$ e sia $p$ il massimo esponente
$p_k$ nelle funzioni che hanno $\lambda_k=\lambda$ come
punto singolare:
\[
 p = \max\{p_k\colon k=1,\dots, n, p_k = p \}.
\]

Consideriamo la funzione $f\colon \Omega \to \CC$
definita da
\[
  f(z) = (z-\lambda)^p\sum_{k=1}^n \frac{\alpha_k}{(z-\lambda_k)^{p_k}}.
\]
Questa funzione per ipotesi è identicamente nulla (in quanto ottenuta moltiplicando la combinazione lineare identicamente nulla per il fattore $(z-\lambda)^p$).
Ma si osserva che si ha
\[
  \lim_{z\to \lambda} \frac{(z-\lambda)^p}{(z-\lambda_k)^{p_k}}
  =
  \begin{cases}
    0 &\text{se $\lambda_k \neq \lambda$}\\
    0 &\text{se $\lambda_k = \lambda$ ma $p_k < p$}\\
    1 &\text{se $\lambda_k = \lambda$ e $p_k = p$}
  \end{cases}
\]
e dunque, supponendo senza perdita di generalità che sia $p_n=p$,
\[
 0 = \lim_{z\to \lambda} f(z)
 = \sum_{k=1}^{n-1} \alpha_k \cdot 0 + \alpha_n \cdot 1.
\]
Dunque $\alpha_n = 0$ e risulta allora che
\[
  0 = \sum_{k=1}^n \alpha_k u_k = \sum_{k=1}^{n-1} \alpha_k u_k.
\]
Ci siamo quindi ricondotti ad una combinazione lineare di $n-1$ vettori $u_1,\dots, u_{n-1}$ e per induzione possiamo supporre quindi che anche $\alpha_1= \dots = \alpha_{n-1}=0$ concludendo la dimostrazione della prima parte del teorema.

Per la seconda parte osserviamo che
\begin{equation}\label{eq:43775}
\sum_{k=1}^n \sum_{j=1}^{p_k} \frac{A_{kj}}{(z-\lambda_k)^j}
= \frac{\displaystyle\sum_{k=1}^n \sum_{j=1}^{p_k} A_{kj} S_{kj}(z)}{Q(z)}
\end{equation}
dove
\[
  S_{kj}(z) = \frac{Q(z)}{(z-\lambda_k)^j}
\]
è un polinomio di grado inferiore al grado di $Q$ (visto che $(z-\lambda_k)^j$ divide $Q$).

Guardando il lato sinistro dell'uguaglianza \eqref{eq:43775} vediamo una combinazione lineare con coefficienti $A_{kj}$ di fratti semplici e per la prima parte del teorema sappiamo che lo spazio $V$ di tutte le funzioni che
si possono ottenere mediante tali combinazioni è un
sottospazio vettoriale di dimensione $N$ di $\RR^\Omega$.

Guardando il lato destro vediamo che al "numeratore" c'è
invece una combinazione di polinomi $S_{kj}$ ognuno dei quali ha grado inferiore ad $N$. Quello che si ottiene è dunque un polinomio di grado inferiore ad $N$. Al denominatore c'è il polinomio fissato $Q$. Dunque al variare dei coefficienti $A_{kj}$ il lato destro è un sottospazio dello spazio dei polinomi di grado inferiore ad $N$ che vengono poi divisi per $Q$. Anche questo spazio ha dimensione $N$ (in quanto di polinomi di grado $N-1$ sono combinazione lineare dei monomi $1, z, z^2, \dots, z^{N-1}$) e contiene lo spazio $V$ che pure abbiamo verificato avere dimensione $N$. Dunque i due spazi coincidono e questo significa che il polinomio $P$, avendo grado inferiore ad $N$ è combinazione lineare dei polinomi $S_{kj}$ per una opportuna (unica) scelta dei coefficienti $A_{kj}$.
\end{proof}

\begin{theorem}[fattorizzazione dei polinomi a coefficienti reali]
Sia $Q(x)$ un polinomio a coefficienti reali. Allora
\begin{equation}\label{eq:35549}
  Q(x) = a \cdot (x-\lambda_1) \cdots (x-\lambda_k)
  \cdot Q_1(x) \cdots Q_m(x)
\end{equation}
dove $a\in \CC$,
$\lambda_1, \dots, \lambda_k$ sono le radici reali di $Q$
(eventualmente ripetute con la loro molteplicità)
e
\[
  Q_k(x) = x^2 + \alpha_k x + \beta_k
\]
sono polinomi monici di grado due con coefficienti $\alpha_k$ e $\beta_k$ reali e  con discriminante
$\Delta = \alpha^2 - 4 \beta_k$ negativo i cui zeri (complessi) sono le radici non reali di $Q$.
\end{theorem}
%
\begin{proof}
Per il teorema fondamentale dell'algebra sappiamo che
\begin{equation}\label{eq:45549}
  Q(x) = a \cdot (x - \lambda_1) \cdots (x- \lambda_k)
  \cdot (x-\lambda_{k+1}) \cdots (x-\lambda_n)
\end{equation}
dove $\lambda_1, \dots, \lambda_k$ sono le radici reali
del polinomio $Q$ mentre $\lambda_{k+1}, \dots, \lambda_d$
sono le radici non reali.

Osserviamo che avendo $Q$ coefficienti reali, per ogni $z\in \CC$  si ha $\overline{Q(z)} = Q(\overline z)$ in quanto il coniugio lascia invariati i coefficienti del polinomio $Q$.
In particolare se $\lambda$ è una radice complessa di $Q$ allora $Q(\bar \lambda) = \overline{Q(\lambda)} = \overline 0 = 0$ cioè anche $\bar \lambda$ è radice di $Q$.
Dunque se $\lambda_{k+1}$ è una radice non reale,
anche $\bar \lambda_{k+1} \neq \lambda_{k+1}$
deve essere una radice di $Q$ e senza perdita di generalità possiamo supporre che sia $\lambda_{k+2} = \bar\lambda_{k+1}$.
Osserviamo allora che si ha
\begin{align*}
(x-\lambda_{k+1})(x-\lambda_{k+2})
&=(x-\lambda_{k+1})(x-\bar\lambda_{k+1})\\
&= x^2 - (\lambda_{k+1}+ \bar \lambda_{k+1}) x + \lambda_{k+1} \bar \lambda_{k+1} \\
&= x^2 - 2(\Re \lambda_{k+1}) x + \abs{\lambda_{k+1}}^2\\
&= Q_1(x)
\end{align*}
se poniamo $\alpha_1 = -2\Re \lambda_{k+1}$ e $\beta_1=\abs{\lambda_{k+1}}^2$.
Si osservi che $\alpha_1$ e $\beta_1$ sono reali.
Si itera quindi il procedimento finché non si esauriscono
tutte le radici e si completa quindi la decomposizione.
\end{proof}

\begin{theorem}[decomposizione reale in fratti semplici]
Sia $Q$ un polinomio monico a coefficienti reali che
si fattorizzi nella forma:
\begin{align*}
  Q(x) &= (x-\lambda_1)^{p_1} \cdots (x-\lambda_n)^{p_n} \\
  &\quad \cdot
   (x^2+\alpha_1 x + \beta_1)^{q_1} \cdots (x^2+\alpha_m x + \beta_m)^{q_m}
\end{align*}
con $\lambda_1, \dots, \lambda_n$ le radici reali distinte di $Q$ di molteplicità rispettivamente
$p_1,\dots, p_n$ e $(x^2+\alpha_k x + \beta_k)$ polinomi monici distinti di grado $2$
con discriminante negativo $\alpha_k^2<4\beta_k$ con molteplicità $q_k$ per $k=1, \dots, m$.

Se $P$ è un polinomio a coefficienti reali di grado inferiore
al grado di $Q$
allora esistono dei coefficienti reali $A_{kj}$ con $k=1,\dots,n $ e $j=1,\dots, p_k$ e coefficienti reali $B_{kj}$, $C_{kj}$ con $k=1,\dots, m$ e $j=1,\dots, q_k$
tali che
\begin{align*}
\frac{P(x)}{Q(x)}
&= \sum_{k=1}^n \sum_{j=1}^{p_k} \frac{A_{kj}}{(x-\lambda_k)^j}
  + \sum_{k=1}^m \sum_{j=1}^{q_k} \frac{B_{kj} + C_{kj}x}{(x^2+\alpha_k x + \beta_k)^j}.
\end{align*}
\end{theorem}
%
\begin{proof}
Diamo un nome alle funzioni coinvolte nell'enunciato del teorema:
\begin{align*}
 u_\lambda^j(z) &= \frac{1}{(z-\lambda)^j},\\
 v_\lambda^j(z) &= \frac{1}{(z-\lambda)^j(z-\bar\lambda)^j},\\
 w_\lambda^j(z) &= z\cdot v_\lambda^j(z).
\end{align*}
Osserviamo che
\[
 (z-\lambda)(z-\bar \lambda)
 = z^2 - 2(\Re\lambda) z + \abs{\lambda}^2
\]
è un polinomio a coefficienti reali con discriminante negativo se $\lambda \in \CC \setminus \RR$, dunque si ha
\[
  \frac{B + Cx}{(x^2 + \alpha x + \beta)^j}
  = B \cdot v_\lambda^j(x) + C \cdot w_\lambda^j(x)
\]
per un opportuna scelta del numero complesso $\lambda$ (per la cronaca: $\lambda = \alpha/2 + i \sqrt{\beta-\alpha^2/4}$).

Nella versione complessa di questo teorema abbiamo già mostrato che le funzioni $u_\lambda^j$ sono indipendenti. Vogliamo ora mostrare che anche le funzioni $u_\lambda^j$, $v_\lambda^j$, $w_\lambda^j$ sono indipendenti e per fare ciò cercheremo di dimostrare che per ogni $\lambda\in \CC\setminus \RR$ fissato, lo spazio generato dalle funzioni
\begin{equation}\label{eq:43841}
u_\lambda, u_{\bar \lambda}, u_\lambda^2, u_{\bar \lambda}^2, \dots, u_\lambda^p, u_{\bar \lambda}^p
\end{equation}
coincide con lo spazio generato dalle funzioni
\begin{equation}\label{eq:43842}
v_\lambda, w_\lambda, v_\lambda^2, w_\lambda^2, \dots, v_\lambda^p, w_\lambda^p.
\end{equation}
Visto che le funzioni in \eqref{eq:43841} abbiamo già dimostrato essere indipendenti, sarà sufficiente mostrare che ogni combinazione lineare delle funzioni in \eqref{eq:43841}
si può esprimere come combinazione lineare delle funzioni in
\eqref{eq:43842}.

La dimostrazione si può fare per induzione su $p$.
Nel caso $p=1$
si osserva che
\begin{align*}
  a u_\lambda^1(z) + b u_{\bar \lambda}^1(z)
  &= \frac{a}{z-\lambda} + \frac{b}{z-\bar \lambda}
  = \frac{az - a \bar \lambda + b z - b \lambda}{z^2 -(\lambda + \bar \lambda)z  + \lambda \bar \lambda} \\
  &= \frac{(a+b) z - a \bar \lambda - b \lambda}{z^2 -(\lambda + \bar \lambda)z  + \lambda \bar \lambda}\\
  &= (a+b)\cdot w_\lambda^1(z) + (a \bar \lambda + b \lambda) v_\lambda^1(z).
\end{align*}

Supponendo ora di aver fatto la dimostrazione fino a $p-1$, dimostriamo il caso generico $p$. Una qualunque combinazione lineare delle funzioni \eqref{eq:43841}
si scrive nella forma
\begin{align*}
\sum_{j=1}^p \frac{a_j}{(z-\lambda)^j} + \sum_{j=1}^p \frac{b_j}{(z-\bar\lambda)^j}
&=
\frac{R(Z)}{(z-\lambda)^p(z-\bar \lambda)^p}
\end{align*}
dove $R(Z)$ è un polinomio di grado al più $2p-1$.
Facendo la divisione tra polinomi possiamo scrivere
\[
R(z) = S(z) (z-\lambda)(z-\bar \lambda) + \alpha z + \beta
\]
con $S$ opportuno polinomio di grado al massimo $2p-3$.
Dunque
\begin{align*}
\sum_{j=1}^p \frac{a_j}{(z-\lambda)^j} + \sum_{j=1}^p \frac{b_j}{(z-\bar\lambda)^j}
&=
\frac{S(z)}{(z-\lambda)^{p-1}(z-\bar \lambda)^{p-1}}\\
&\quad + \frac{\alpha z + \beta}{(z-\lambda)^p(z-\bar\lambda)^p}.
\end{align*}
Il primo addendo con numeratore $S(z)$ è una funzione razionale che può essere quindi espressa come combinazione lineare delle funzioni in \eqref{eq:43841} con $p-1$ al posto di $p$. Dunque per ipotesi induttiva tale addendo è combinazione lineare delle funzioni in \eqref{eq:43842} con $p-1$ al posto di $p$. Il secondo addendo non è altro che $\alpha w_\lambda^p + \beta v_\lambda^p$. Abbiamo quindi mostrato che qualunque combinazione lineare delle \eqref{eq:43841} si scrive come combinazione lineare delle \eqref{eq:43842}, come ci eravamo ripromessi di fare.

Ora, per il caso complesso che abbiamo già dimostrato,
sappiamo che la funzione razionale $P/Q$ ammette una decomposizione in fratti semplici complessi cioè può essere scritta come combinazione lineare a coefficienti complessi delle funzioni $u_\lambda^j$ facendo variare $\lambda$ su tutte le radici, reali e complesse, del polinomio $Q$ e facendo variare $j$ fino alla molteplicità di ogni radice.
Ma sappiamo ora che è possibile rimpiazzare le funzioni $u_\lambda^j$ e $u_{\bar \lambda}^j$ quando $\lambda$ non è reale con le funzioni $v_\lambda^j$ e $w_\lambda^j$ in quanto lo spazio generato da tali funzioni è lo stesso.

Questo ci permette di concludere che la decomposizione cercata esiste, se ammettiamo di avere coefficienti $A_{kj}$, $B_{kj}$ e $C_{kj}$ nel campo complesso.

Per concludere ci basta verificare che in realtà tali coefficienti non possono che essere reali.
Questo dipende da un semplice fatto generale.

Supponiamo che $u_1, \dots, u_n$ siano funzioni reali indipendenti e sia
\[
 u = \alpha_1 u_1 + \dots + \alpha_n u_n.
\]
una loro combinazione lineare a coefficienti complessi  $\alpha_k$.
Se la combinazione $u$ è anch'essa una funzione reale allora possiamo concludere che necessariamente tutti i coefficienti $\alpha_k$ sono reali. Infatti se prendiamo la parte immaginaria della combinazione lineare precedente si avrà
\[
   0 = (\Im \alpha_1) u_1 + \dots + (\Im \alpha_n) u_n.
\]
Ma essendo le $u_1$ funzioni indipendenti, una combinazione lineare è nulla solamente quando tutti i coefficienti sono nulli: significa che la parte immaginaria di ogni $\alpha_k$ è nulla, cioè che gli $\alpha_k$ sono reali.

In base a questa osservazione comprendiamo che è sufficiente
mostrare che esistono i coefficienti $A_{kj}$, $B_{kj}$ e $C_{kj}$ nel campo complesso perché in tal caso necessariamente tali coefficienti dovranno essere reali, essendo
\end{proof}

In base ai teoremi precedenti, se $P(x)/Q(x)$ è una qualunque funzione razionale reale,
possiamo innanzitutto
eseguire la divisione tra polinomi e trovare quindi un
quozionte $S(x)$ e un resto $R(x)$ con $\deg R < \deg Q$
cosicché
\[
  \frac{P(x)}{Q(x)} = S(X) + \frac{R(x)}{Q(x)}.
\]
Dopodiché possiamo decomporre $R(x)/Q(x)$
in fratti semplici. L'integrale di $P/Q$ si potrà quindi ricondurre (tramite combinazione lineare) agli integrali di $S$ e di ognuno dei fratti semplici. L'integrale di $S$ è banale, in quanto $S$ è un polinomio e quindi è combinazione lineare di potenze di $x$.

Non ci resta quindi che trovare l'integrale dei fratti semplici, cosa che faremo nel seguente teorema.

\begin{theorem}[integrale dei fratti semplici]
Se $\lambda\in \RR$, $p\in \NN$, $p>1$, $\alpha,\beta \in \RR$, $\alpha^2-4\beta < 0$, si ha
\begin{align*}
  \int \frac{1}{x-\lambda}\, dx
  &= \ln \abs{x-\lambda} \\
  \int \frac{1}{(x-\lambda)^p}\, dx
  &=  -\frac{1}{(p-1)(x-\lambda)^{p-1}} \\
  \int \frac{1}{1+x^2}\, dx
  &= \arctg x \\
  \int \frac{1}{(1+x^2)^p}\, dx
   &= \frac{x}{2n(1+x^2)^{p-1}} + \frac{2p-3}{2p-2}\int \frac{1}{(1+x^2)^{p-1}}\, dx \\
  \int \frac{1}{x^2+\alpha x + \beta}\, dx
     &=
     \frac{2}{\sqrt{4\beta - \alpha^2}}
     \arctg \frac{2x+\alpha}{\sqrt{4\beta-\alpha^2}}
  \\
  \int \frac{1}{(x^2+\alpha x + \beta)^p}\, dx
    &=
    \enclose{\frac{4}{4\beta - \alpha^2}}^{p-\frac 1 2}
    \Enclose{\int \frac{1}{(1+y^2)^p}\, dy}_{y=\frac{2x+\alpha}{\sqrt{4\beta-\alpha^2}}}
 \\
  \int \frac{ax + b}{(x^2+\alpha x + \beta)^p}\, dx
   &= -\frac{a}{2(p-1)(x^2+\alpha x+ \beta)^{p-1}} \\
   &\quad + \frac{2b-a\alpha}{2}\int \frac{1}{(x^2+\alpha x+\beta)^p}\, dx \\
\end{align*}
\end{theorem}
%
\begin{proof}
I primi tre integrali sono immediati.
Per il quarto si ha:
\begin{align*}
\int \frac{1}{(1+x^2)^p}\, dx
&= \int \frac{1+x^2-x^2}{(1+x^2)^p}\, dx \\
&= \int \frac{1}{(1+x^2)^{p-1}}\, dx - \int\frac{x^2}{(1+x^2)^p}\, dx.
\end{align*}
Osservando che
\[
 \int \frac{2x}{(1+x^2)^p}\, dx
  = -\frac{1}{p-1}\frac{1}{(1+x^2)^{p-1}}.
\]
si ottiene, integrando per parti,
\begin{align*}
\int \frac{x^2}{(1+x^2)^p}\, dx
&=
\int \frac{2x}{(1+x^2)^p}\cdot \frac{x}{2}\, dx\\
&= -\frac{1}{p-1}\frac{1}{(1+x^2)^{p-1}} \frac{x}{2}
 + \frac{1}{2p-2}\int \frac{1}{(1+x^2)^{p-1}}\, dx
\end{align*}
da cui segue il risultato enunciato nel teorema.

Per quanto riguarda il quinto e il sesto integrale si opera il \emph{completamento del quadrato}:
\begin{align*}
  x^2 + \alpha x + \beta
  &= \enclose{x+\frac \alpha 2}^2 + \beta - \frac{\alpha^2}{4} \\
  &= \frac{4\beta-\alpha^2}{4}
  \enclose{\enclose{\frac{2x+\alpha}{\sqrt{4\beta-\alpha^2}}}^2+1}
\end{align*}
da cui, facendo il cambio di variabile
\begin{align*}
y  &=\frac{2x+\alpha}{\sqrt{4\beta -\alpha^2}}\\
dx &= \frac{\sqrt{4\beta-\alpha^2}}{2} dy
\end{align*}
si ottiene
\begin{align*}
\int \frac{1}{(x^2+\alpha x + \beta)^p}\, dx
&=
\frac{4^p}{\enclose{4\beta - \alpha^2}^p}
\int \frac{1}{\enclose{y^2 + 1}^p}\,  \frac{\sqrt{4\beta-\alpha^2}}{2} dy \\
&= \enclose{\frac{4}{4\beta - \alpha^2}}^{p-\frac 1 2}
\int \frac{1}{(1+y^2)^p}\, dy
\end{align*}
che per $p=1$ può essere calcolato immediatamente, e per $p>1$ si riconduce agli integrali già calcolati.

Nell'ultimo integrale dell'enunciato abbiamo semplicemente
utilizzato l'integrale immediato:
\[
  \int \frac{2x+\alpha}{(x^2+\alpha x+\beta)^p}\, dx
  = -\frac{1}{(p-1)(x^2+\alpha x + \beta)^{p-1}}
\]
\end{proof}
